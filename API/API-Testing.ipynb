{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e7704e5bed60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfdocument\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfpage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFPage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdfminer'"
     ]
    }
   ],
   "source": [
    "from pyzotero import zotero\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.error import HTTPError\n",
    "import requests\n",
    "import io\n",
    "import PyPDF2 \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from StringIO import StringIO\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import TextConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zotero_lib(library_id, library_type, api_key, n_articles):\n",
    "    zot = zotero.Zotero(library_id, library_type, api_key)\n",
    "    items = zot.top(limit=n_articles)\n",
    "    return items\n",
    "\n",
    "def scrape_item(item):\n",
    "    url = item['data']['url']\n",
    "    urllib_obj = urlopen(url)\n",
    "    html = BeautifulSoup(urllib_obj.read());\n",
    "    tags = {re.compile('h\\d') : True, \n",
    "            'p' : True, \n",
    "            'blockquote': True}\n",
    "    return '\\n'.join([p.get_text() for p in html.find_all(tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_id = 2269135\n",
    "library_type = 'group'\n",
    "api_key = 'bPraFnu08tmj8mtlAyuKnnNY'\n",
    "n_articles = 30\n",
    "items = get_zotero_lib(library_id, library_type, api_key, n_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 410: Gone\n",
      "https://www.nytimes.com/reuters/2018/07/13/business/13reuters-tech-rights.html\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1051)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1317\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0;32m-> 1392\u001b[0;31m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    852\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1051)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-95619b059bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article_body'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-33899dcba01e>\u001b[0m in \u001b[0;36mscrape_item\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0murllib_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     tags = {re.compile('h\\d') : True, \n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1051)>"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for idx, item in enumerate(items):\n",
    "    try:\n",
    "        text = scrape_item(item)\n",
    "        item['data']['article_body'] = text\n",
    "    except HTTPError as e:\n",
    "        print(e)\n",
    "        print(item['data']['url'])\n",
    "        item['data']['article_body'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to download pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from http://survivalengineer.blogspot.com/2014/04/parsing-pdfs-in-python.html\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "import io\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import TextConverter\n",
    "class MyParser(object):\n",
    "    def __init__(self, pdf):\n",
    "        ## Snipped adapted from Yusuke Shinyamas \n",
    "        #PDFMiner documentation\n",
    "        # Create the document model from the file\n",
    "        parser = PDFParser(pdf)\n",
    "        document = PDFDocument(parser)\n",
    "        # Try to parse the document\n",
    "        if not document.is_extractable:\n",
    "            raise PDFTextExtractionNotAllowed\n",
    "        # Create a PDF resource manager object \n",
    "        # that stores shared resources.\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        # Create a buffer for the parsed text\n",
    "        retstr = io.StringIO()\n",
    "        # Spacing parameters for parsing\n",
    "        laparams = LAParams()\n",
    "        codec = 'utf-8'\n",
    " \n",
    "        # Create a PDF device object\n",
    "        device = TextConverter(rsrcmgr, retstr, \n",
    "                               codec = codec, \n",
    "                               laparams = laparams)\n",
    "        # Create a PDF interpreter object\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        # Process each page contained in the document.\n",
    "        for page in PDFPage.create_pages(document):\n",
    "            interpreter.process_page(page)\n",
    "         \n",
    "        self.records            = []\n",
    "         \n",
    "        lines = retstr.getvalue().splitlines()\n",
    "        for line in lines:\n",
    "            self.handle_line(line)\n",
    "     \n",
    "    def handle_line(self, line):\n",
    "        # Customize your line-by-line parser here\n",
    "        self.records.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keys\n",
    "library_id = 2269135\n",
    "library_type = 'group'\n",
    "api_key = 'bPraFnu08tmj8mtlAyuKnnNY'\n",
    "collection_key = 'VFDISWVI' # key for api_testing collection\n",
    "\n",
    "#read items\n",
    "zot = zotero.Zotero(library_id, library_type, api_key)\n",
    "items = zot.collection_items(collection_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Statistics That Prove Men\n",
      "Dominate The Tech World\n",
      "\n",
      "Megan Rose Dickey\n",
      "\n",
      "The lack of women in technology\n",
      "conversation is nothing new. \n",
      "\n",
      "Over the last few months, the topic has\n",
      "been fueled by events like \"Donglegate\"\n",
      "and its backlash.\n",
      "\n",
      "It's since become common knowledge\n",
      "that women are underrepresented in tech\n",
      "jobs, but what about their representation\n",
      "in the tech world as a whole?\n",
      "\n",
      "Getty Images/Kevork Djansezian\n",
      "\n",
      "Here are statistics that shed some light on both:\n",
      "\n",
      "In the U.S., women are actually more likely to use social networking sites. In\n",
      "December 2012, 71% of women compared to 62% of men surveyed were using\n",
      "social networking sites, according to Pew Internet.\n",
      "Google, LinkedIn, and Reddit dominated by\n",
      "men\n",
      "\n",
      "Here's the breakdown of the actual user base make-up, according to a 2012\n",
      "report by marketing firm DigitalFlashNYC. Note: Women make up the\n",
      "majority of users on Twitter, Facebook, Zynga, and Pinterest.\n",
      "\n",
      "Stat 1: LinkedIn: 63% men and 37% women\n",
      "\n",
      "Stat 2: Google+: 71% men and 29% women\n",
      "\n",
      "\n",
      "Stat 3: Reddit: 84% men and 16% women\n",
      "\n",
      "Stat 4: Regarding Reddit, men are also twice as likely as women to be Reddit\n",
      "users, according to Pew\n",
      "Wikipedia is dominated by men\n",
      "\n",
      "In short, that means men mostly determine what and how information gets\n",
      "shared. Wikipedia has about 81,000 active editors per month who\n",
      "contribute the growing number of public available-made content, according\n",
      "to an April 2011 survey by the Wikimedia Foundation. But most of those\n",
      "editors are men.\n",
      "\n",
      "Stat 5: 8.5% of Wikipedia editors are women. The total percent of women\n",
      "editors has increased somewhat over the years, but Wikipedia recognizes that\n",
      "its editing community suffers from a lack of women editors.\n",
      "\n",
      "\n",
      "Mike Nudelman/Business Insider\n",
      "Underrepresentation in venture-backed tech\n",
      "companies\n",
      "\n",
      "Women are vastly underrepresented in high-level roles at U.S. venture-\n",
      "backed tech companies, but having more female executives \"makes a\n",
      "significant difference in pushing a company to success,\" according to a 2012\n",
      "report from Dow Jones VentureSource.\n",
      "\n",
      "Stat 6: 1.3% of venture-backed startups have a female founder.\n",
      "\n",
      "Stat 7: 6.5% of venture-backed startups have a female CEO.\n",
      "\n",
      "Stat 8: 20% of venture-backed startups have one or more female C-level\n",
      "executive.\n",
      "\n",
      "\n",
      "Men dominate venture capital and angel\n",
      "investment industries\n",
      "\n",
      "Stat 9: Women represent less than 10% of high-level venture capitalists in\n",
      "the U.S., according to the Kaufman foundation.\n",
      "\n",
      "Stat 10: Only 12% of angel investors in the U.S. were women in 2011,\n",
      "according to the Center for Venture Research.\n",
      "Lack of diversity at influential tech companies\n",
      "\n",
      "Earlier this year, CNNMoney released a report from its investigation into\n",
      "the 20 most influential tech companies in the U.S. They were only able to\n",
      "receive government reports of diversity data from five of them.\n",
      "\n",
      "Stat 11: Cisco: 44 out 225 officers or managers are women.\n",
      "\n",
      "Stat 12: Dell: 27 out of 125 officers or managers are women.\n",
      "\n",
      "Stat 13: eBay: 10 out of 55 officers or managers are women.\n",
      "\n",
      "Stat 14: Ingram Micro: 47 out of 236 officers or managers are women.\n",
      "\n",
      "Stat 15: Intel: 6 out of 41 officers or managers are women.\n",
      "Vast underrepresentation in gaming industry\n",
      "\n",
      "Even though 45% of all gamers are women, women are vastly\n",
      "underrepresented in the gaming industry.\n",
      "\n",
      "Stat 16: Women make up about 11.5% of all game developers, according to\n",
      "the International Game Developers Association.\n",
      "STEM and career placements\n",
      "\n",
      "Women who obtain a degree in STEM (science technology engineering\n",
      "\n",
      "\n",
      "math) are less likely than their male counterparts to work in a STEM\n",
      "occupation, according to the U.S. Department of Commerce Economics and\n",
      "Statistics Administration.\n",
      "\n",
      "Stat 17: As of 2009, there were 7,430,000 workers in STEM jobs in America.\n",
      "Male workers held 5,640,000 of those jobs.\n",
      "\n",
      "Stat 18: Women hold less than 25% of STEM jobs, according to the ESA.\n",
      "Among women in STEM jobs, 27% of them are in computer science and math\n",
      "jobs and just 14% are in engineering jobs, according to the ESA.\n",
      "Internet usage in developing world\n",
      "\n",
      "In the developing world, women's Internet usage is much less compared to\n",
      "men's.\n",
      "\n",
      "Stat 19: There about 600 million women online compared to 800 million\n",
      "men in developing countries, according to a 2012 report from Intel.\n",
      "\n",
      "Stat 20: On average, nearly 25% fewer women than men have access to the\n",
      "Internet, according to Intel.\n",
      "\n",
      "Stat 21: The gender gap jumps to nearly 45% in regions like sub-Saharan\n",
      "Africa.\n",
      "\n",
      "Stat 22: About 35% fewer women than men in South Asia, the Middle East,\n",
      "and North Africa have Internet success.\n",
      "\n",
      "Stat #23: Nearly 30% fewer women than men in parts of Europe and North\n",
      "Africa have Internet access.\n",
      "\n",
      "NOW WATCH: 14 things you didn't know your\n",
      "iPhone headphones could do\n",
      "\n",
      "\n",
      "https://www.businessinsider.\n",
      "com/statistics-prove-men-\n",
      "dominate-tech-world-2013-\n",
      "<iframe \n",
      "src=\"//content.jwplatform.co\n",
      "m/players/oY2ogjf0-\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "7\n",
      "1\n",
      "0\n",
      "2\n",
      "E\n",
      "R\n",
      "B\n",
      "M\n",
      "E\n",
      "C\n",
      "É\n",
      "D\n",
      "\n",
      "e\n",
      "\n",
      "l\n",
      "l\n",
      "\n",
      "i\n",
      "\n",
      "e\n",
      "c\n",
      "fi\n",
      "i\n",
      "t\n",
      "r\n",
      "a\n",
      "e\n",
      "c\n",
      "n\n",
      "e\n",
      "g\n",
      "\n",
      " \n",
      "\n",
      "i\n",
      "l\n",
      "l\n",
      "\n",
      "e\n",
      "t\n",
      "n\n",
      "\n",
      "i\n",
      "’\n",
      "l\n",
      " \n",
      "\n",
      "j\n",
      "\n",
      "l\n",
      "\n",
      "i\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "I\n",
      "\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "e\n",
      "m\n",
      "h\n",
      "t\n",
      "i\n",
      "r\n",
      "o\n",
      "g\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      "s\n",
      "e\n",
      "u\n",
      "q\n",
      "h\n",
      "t\n",
      "é\n",
      "x\n",
      "u\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "e\n",
      "L\n",
      "?\n",
      "N\n",
      "A\n",
      "M\n",
      "A\n",
      "L\n",
      "R\n",
      "E\n",
      "D\n",
      "R\n",
      "A\n",
      "G\n",
      "E\n",
      "D\n",
      "E\n",
      "M\n",
      "M\n",
      "O\n",
      "H\n",
      "L’\n",
      "À\n",
      "E\n",
      "R\n",
      "T\n",
      "T\n",
      "E\n",
      "M\n",
      "R\n",
      "E\n",
      "P\n",
      "T\n",
      "N\n",
      "E\n",
      "M\n",
      "M\n",
      "O\n",
      "C\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Commission Nationale de l’Informatique et des Libertés\n",
      "\n",
      "3 place de Fontenoy\n",
      "\n",
      "TSA 80715\n",
      "\n",
      "75334 PARIS CEDEX 07\n",
      "\n",
      "Tél. 01 53 73 22 22\n",
      "Fax 01 53 73 22 00\n",
      "\n",
      "www.cnil.fr\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME \n",
      "\n",
      "DE GARDER LA MAIN ?\n",
      "\n",
      " Les enjeux éthiques des algorithmes et de l’intelligence artificielle\n",
      "\n",
      "SYNTHÈSE DU DÉBAT PUBLIC ANIMÉ PAR LA CNIL DANS LE CADRE DE LA MISSION \n",
      "DE RÉFLEXION ÉTHIQUE CONFIÉE PAR LA LOI POUR UNE RÉPUBLIQUE NUMÉRIQUE\n",
      "\n",
      "DÉCEMBRE 2017\n",
      "\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME \n",
      "\n",
      "DE GARDER LA MAIN ?\n",
      "\n",
      " Les enjeux éthiques des algorithmes et de l’intelligence artificielle\n",
      "\n",
      "SYNTHÈSE DU DÉBAT PUBLIC ANIMÉ PAR LA CNIL DANS LE CADRE DE LA MISSION \n",
      "DE RÉFLEXION ÉTHIQUE CONFIÉE PAR LA LOI POUR UNE RÉPUBLIQUE NUMÉRIQUE\n",
      "\n",
      "DÉCEMBRE 2017\n",
      "\n",
      "Ce rapport a été rédigé par Victor Demiaux avec le concours de Yacine Si Abdallah.\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "PRÉFACE\n",
      "\n",
      "PRÉFACE\n",
      "\n",
      "L’intelligence  artificielle  est  le  grand  mythe  de  notre \n",
      "\n",
      "temps.  L’un  annonce  la  destruction  en  masse  de  nos \n",
      "emplois,  un  autre  l’émergence  apocalyptique  d’une \n",
      "conscience  robotique  hostile,  un  troisième  la  ruine  d’une \n",
      "Europe  écrasée  par  la  concurrence.  D’autres  encore  nour-\n",
      "rissent  plutôt  le  rêve  d’un  monde  sur  mesure,  d’un  nouvel \n",
      "Âge d’or d’où toute tâche ingrate ou répétitive serait bannie \n",
      "et déléguée à des machines ; un Eden où des outils infail-\n",
      "libles auraient éradiqué la maladie et le crime, voire le conflit \n",
      "politique, en un mot aboli le mal. Sous ses avatars tour à tour \n",
      "fascinants  ou  inquiétants,  solaires  ou  chtoniens,  l’intelli-\n",
      "gence artificielle dit sans doute plus de nos phantasmes et \n",
      "de nos angoisses que de ce que sera notre monde demain. \n",
      "À considérer l’attrait de ce type de discours eschatologiques \n",
      "en  Europe,  on  en  vient  à  penser  que  la  technique  cristal-\n",
      "lise aussi une puissance de projection dans l’avenir qui fait \n",
      "parfois défaut à nos imaginaires politiques.\n",
      "\n",
      "Désamorcer ces présentations sensationnalistes des nouvelles technologies est une chose. Cela ne \n",
      "signifie pas pour autant que l’on ignore que l’irruption dans nos vies quotidiennes de ces assistants \n",
      "ou outils d’un nouveau type génère des bouleversements multiples et des défis nouveaux que nous \n",
      "devons relever. Préservation de l’autonomie de la décision humaine face à des machines parfois per-\n",
      "çues comme infaillibles, détection de discriminations générées involontairement par des systèmes \n",
      "mouvants, sauvegarde de logiques collectives parfois érodées par la puissance de personnalisation \n",
      "du numérique, etc. : les enjeux ne manquent pas, aux implications déjà tangibles. Ils questionnent \n",
      "certains des grands pactes et des équilibres sur lesquels repose notre vie collective. \n",
      "\n",
      "Établir de façon claire et lucide ces enjeux est le premier devoir de la puissance publique, la condition \n",
      "pour pouvoir proposer des réponses adaptées, pour intégrer l’innovation technologique à la construc-\n",
      "tion d’une vision déterminée de notre avenir. C’était le sens de la création de la mission de réflexion \n",
      "sur les enjeux éthiques soulevés par les technologies numériques que la Loi pour une République \n",
      "numérique a confiée à la CNIL.\n",
      "\n",
      "Comment appréhender aujourd’hui une telle mission ? Beaucoup se sont interrogés, voire ont ques-\n",
      "tionné cette responsabilité nouvelle de la Commission. Comment exprimer l’éthique sur des sujets \n",
      "hautement complexes et évolutifs, à quel titre, selon quelles modalités ?\n",
      "\n",
      "Réflexion sur les principes fondamentaux de conduite de la vie des hommes et des sociétés, défini-\n",
      "tion d’un pacte social partagé sur un sujet complexe à un moment donné, l’éthique constitue un objet \n",
      "éminemment collectif, pluriel. Dans le domaine bien particulier des sciences de la vie et de la santé, \n",
      "la composition et la collégialité du travail du Comité Consultatif National d’Éthique répondent à cet \n",
      "impératif de pluralité. \n",
      "\n",
      "Garante  de  principes  éthiques  fixés  par  le  législateur  il  y  a  quarante  ans,  la  CNIL  a  certes  toute \n",
      "légitimité pour être le point focal de cette réflexion éthique, à l’heure où des possibilités techniques \n",
      "nouvelles soulèvent de nouveaux enjeux ou questionnent les équilibres antérieurs. \n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "PRÉFACE\n",
      "\n",
      "3\n",
      "\n",
      "En revanche, il est apparu impensable qu’elle puisse se prévaloir d’un quelconque monopole sur la \n",
      "réflexion éthique du numérique. Sur un sujet aussi vaste et transversal, cette dernière ne saurait se \n",
      "concevoir en vase clos. Le numérique n’est pas un secteur, que l’on pourrait confier aux soins d’un \n",
      "comité d’éthique restreint à quelques membres, aussi compétents soient-ils. Il fallait innover.\n",
      "\n",
      "C’est dans cet esprit que la CNIL a suscité une démarche collective, en animant avec l’aide de parte-\n",
      "naires de multiples secteurs un débat public pendant plusieurs mois. L’éthique est à cet égard autant \n",
      "un processus d’élaboration que le résultat du processus lui-même. Nous avons ainsi fait le choix de \n",
      "partir des usages, des interrogations existantes et des pistes de solutions évoqués par les acteurs du \n",
      "débat. Plus de quarante manifestations organisées à Paris et en régions ont permis de recueillir les \n",
      "éléments qui ont alimenté le présent rapport et les recommandations dont il est porteur.\n",
      "\n",
      "Un effort d’innovation était également nécessaire pour faire droit à la nécessité d’associer davantage \n",
      "le citoyen à l’élaboration de la réflexion publique sur un univers complexe qui modèle de plus en plus \n",
      "son existence et implique des choix de société fondamentaux. Un univers dont il doit être de plus en \n",
      "plus un co-acteur. La CNIL a ainsi organisé une journée de concertation citoyenne, à Montpellier, le \n",
      "14 octobre dernier, qui a permis de joindre la voix d’une quarantaine de volontaires à la polyphonie \n",
      "du débat public.\n",
      "\n",
      "Le premier bénéfice de cette démarche ouverte et décentralisée est d’avoir fait respirer le débat le \n",
      "plus largement possible et d’avoir participé à la montée en compétence de la société française vis-à-\n",
      "vis des questions soulevées par les algorithmes et par l’IA. Face à des systèmes socio-techniques de \n",
      "plus en plus complexes et compartimentés, face aux impacts parfois difficilement prévisibles d’arte-\n",
      "facts en évolution constante, cloisonner le débat à quelques cercles d’initiés, c’est prendre le risque \n",
      "de susciter méfiance et défiance. Faire de l’ensemble de nos concitoyens des utilisateurs éclairés et \n",
      "critiques des technologies est au contraire un impératif tout à la fois éthique, démocratique et prag-\n",
      "matique. C’est aussi, pour la CNIL, prolonger l’œuvre d’accompagnement de la rencontre de la société \n",
      "française avec le numérique qu’elle accomplit depuis 40 ans.\n",
      "\n",
      "À l’heure même où se définit la position française – et bientôt européenne – en matière d’intelligence \n",
      "artificielle, le rapport issu de ces mois de débat public contribue à poser les jalons d’un questionne-\n",
      "ment commun. Il propose un panorama des enjeux et formule un certain nombre de principes et de \n",
      "recommandations.\n",
      "\n",
      "Celles-ci ont un objectif commun : permettre à la personne humaine de ne pas « perdre la main ».  \n",
      "À  l’heure  de  la  dématérialisation  généralisée,  ceci  paraitra  peut-être  décalé.  Il  nous  semble  au \n",
      "contraire que c’est là que réside notre défi collectif majeur. Faire en sorte que ces nouveaux outils \n",
      "soient à la main humaine, à son service, dans un rapport de transparence et de responsabilité. \n",
      "\n",
      "Puissent ces réflexions alimenter celles en cours au sein des pouvoirs publics, dont celle de la mis-\n",
      "sion Villani, mais aussi des différentes composantes de la société civile. Puissent-elles ainsi partici-\n",
      "per à l’élaboration d’un modèle français de gouvernance éthique de l’intelligence artificielle.\n",
      "\n",
      "Isabelle Falque-Pierrotin\n",
      "Présidente de la CNIL\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "SOMMAIRE\n",
      "\n",
      "SOMMAIRE\n",
      "\n",
      "RÉSUMÉ\n",
      "\n",
      "UNE DÉMARCHE INNOVANTE AU SERVICE DE L’ÉLABORATION \n",
      "D’UNE RÉFLEXION ÉTHIQUE COLLECTIVE ET PLURALISTE\n",
      "\n",
      "LES DATES CLÉS\n",
      "\n",
      "LES CHIFFRES CLÉS\n",
      "\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "Un effort de définition nécessaire à la qualité du débat public\n",
      "\n",
      "Les algorithmes : une réalité ancienne au coeur de l’informatique\n",
      "\n",
      "Des algorithmes à l’intelligence artificielle\n",
      "\n",
      "Cadrer la réflexion en fonction des applications et des impacts les plus cruciaux \n",
      "des algorithmes aujourd’hui\n",
      "\n",
      "Des usages et des promesses dans tous les secteurs\n",
      "\n",
      "LES ENJEUX ÉTHIQUES\n",
      "L’éthique, éclaireuse du droit\n",
      "\n",
      "L’autonomie humaine au défi de l’autonomie des machines\n",
      "\n",
      "Biais, discriminations et exclusion\n",
      "\n",
      "Fragmentation algorithmique : la personnalisation contre les logiques collectives\n",
      "\n",
      "Entre limitation des mégafichiers et développement de l’intelligence artificielle : \n",
      "un équilibre à réinventer\n",
      "\n",
      "Qualité, quantité, pertinence : l’enjeu des données fournies à l’IA\n",
      "\n",
      "L’identité humaine au défi de l’intelligence artificielle \n",
      "\n",
      "QUELLES RÉPONSES ? \n",
      "De la réflexion éthique à la régulation des algorithmes\n",
      "\n",
      "Ce que la loi dit déjà sur les algorithmes et l’intelligence artificielle\n",
      "\n",
      "Les limites de l’encadrement juridique actuel\n",
      "\n",
      "Faut-il interdire les algorithmes et l’intelligence artificielle dans certains secteurs ?\n",
      "\n",
      "Deux principes fondateurs pour le développement des algorithmes \n",
      "et de l’intelligence artificielle : loyauté et vigilance\n",
      "\n",
      "Des principes d’ingénierie : intelligibilité, responsabilité, intervention humaine\n",
      "\n",
      "Des principes aux recommandations pratiques\n",
      "\n",
      "CONCLUSION\n",
      "\n",
      "ANNEXES\n",
      "\n",
      "REMERCIEMENTS\n",
      "\n",
      "LISTE DES MANIFESTATIONS ORGANISÉES DANS LE CADRE DU DÉBAT PUBLIC\n",
      "\n",
      "GLOSSAIRE\n",
      "\n",
      "5\n",
      "\n",
      "7\n",
      "\n",
      "10\n",
      "\n",
      "11\n",
      "\n",
      "13\n",
      "14\n",
      "\n",
      "15\n",
      "\n",
      "16\n",
      "\n",
      "19\n",
      "\n",
      "21\n",
      "\n",
      "23\n",
      "24\n",
      "\n",
      "26\n",
      "\n",
      "31\n",
      "\n",
      "34\n",
      "\n",
      " \n",
      "38\n",
      "\n",
      "39\n",
      "\n",
      "41\n",
      "\n",
      "43\n",
      "44\n",
      "\n",
      "45\n",
      "\n",
      "46\n",
      "\n",
      "47\n",
      "\n",
      "48\n",
      "\n",
      "51\n",
      "\n",
      "53\n",
      "\n",
      "61\n",
      "\n",
      "62\n",
      "\n",
      "71\n",
      "\n",
      "72\n",
      "\n",
      "75\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "RÉSUMÉ\n",
      "\n",
      "5\n",
      "\n",
      "RÉSUMÉ\n",
      "\n",
      "Ce rapport est le résultat d’un débat public animé par la \n",
      "CNIL. Entre janvier et octobre 2017, 60 partenaires (as-\n",
      "sociations, entreprises, administrations, syndicats, etc.) \n",
      "ont  organisé  45  manifestations  dans  toute  la  France. \n",
      "Il  s’agissait  d’identifier  les  sujets  de  préoccupations \n",
      "éthiques soulevés par les algorithmes et l’intelligence ar-\n",
      "tificielle, ainsi que les pistes de solutions possibles.\n",
      "\n",
      "La  première  partie  du  rapport  apporte  une  définition \n",
      "pragmatique  des  algorithmes  et  de  l’intelligence  artifi-\n",
      "cielle tout en présentant leurs principaux usages et no-\n",
      "tamment  ceux  d’entre  eux  qui  retiennent  aujourd’hui  le \n",
      "plus l’attention publique. Classiquement, l’algorithme se \n",
      "définit ainsi comme une suite finie et non ambigüe d’ins-\n",
      "tructions  permettant  d’aboutir  à  un  résultat  à  partir  de \n",
      "données fournies en entrée. Cette définition rend compte \n",
      "des  multiples  applications  numériques  qui,  exécutant \n",
      "des programmes traduisant eux-mêmes en langage in-\n",
      "formatique  un  algorithme,  remplissent  des  fonctions \n",
      "aussi  diverses  que  fournir  des  résultats  sur  un  moteur \n",
      "de recherche, proposer un diagnostic médical, conduire \n",
      "une voiture d’un point à un autre, détecter des suspects \n",
      "de fraude parmi les allocataires de prestations sociales, \n",
      "etc.  L’intelligence  artificielle  désigne  principalement \n",
      "dans le débat public contemporain une nouvelle classe \n",
      "d’algorithmes,  paramétrés  à  partir  de  techniques  dites \n",
      "d’apprentissage : les instructions à exécuter ne sont plus \n",
      "programmées explicitement par un développeur humain, \n",
      "elles sont en fait générées par la machine elle-même, qui \n",
      "« apprend » à partir  des données qui lui sont  fournies. \n",
      "Ces algorithmes d’apprentissage peuvent accomplir des \n",
      "tâches dont sont incapables les algorithmes classiques \n",
      "(reconnaître  un  objet  donné  sur  de  très  vastes  corpus \n",
      "d’images, par exemple). En revanche, leur logique sous-\n",
      "jacente  reste  incompréhensible  et  opaque  y  compris  à \n",
      "ceux qui les construisent.\n",
      "\n",
      "Le débat public a permis d’identifier 6 grandes \n",
      "problématiques éthiques :\n",
      "\n",
      "•  Le perfectionnement et l’autonomie croissante des arte-\n",
      "facts techniques permettent des formes de délégations \n",
      "de  tâches,  de  raisonnements  et  de  décisions  de  plus \n",
      "en  complexes  et  critiques  à  des  machines.  Dans  ces \n",
      "conditions,  à  côté  de l’augmentation  de sa  puissance \n",
      "d’agir permise par la technique, n’est-ce pas aussi son \n",
      "autonomie, son libre arbitre, qui peut se trouver érodé ? \n",
      "Le  prestige  et  la  confiance  accordés  à  des  machines \n",
      "jugées souvent infaillibles et « neutres » ne risquent-ils \n",
      "pas de générer la tentation de se décharger sur les ma-\n",
      "chines  de  la  fatigue  d’exercer  des  responsabilités,  de \n",
      "juger, de prendre des décisions ? Comment appréhen-\n",
      "\n",
      "der les formes de dilution de la responsabilité que sont \n",
      "susceptibles de susciter les systèmes algorithmiques, \n",
      "complexes et très segmentés ?\n",
      "\n",
      "•  Les algorithmes et l’intelligence artificielle peuvent sus-\n",
      "citer  des  biais,  des  discriminations,  voire  des  formes \n",
      "d’exclusion. Ces phénomènes peuvent être volontaires. \n",
      "Mais le réel enjeu, à l’heure du développement des al-\n",
      "gorithmes  d’apprentissage,  est  leur  développement  à \n",
      "l’insu même de l’homme. Comment y faire face ?\n",
      "\n",
      "•  L’écosystème  numérique  tel  qu’il  s’est  construit  avec \n",
      "le  Web,  mais  également  plus  anciennement  les  tech-\n",
      "niques actuarielles, ont fortement exploité les potentia-\n",
      "lités des algorithmes en termes de personnalisation. Le \n",
      "profilage et la segmentation de plus en plus fine rendent \n",
      "bien  des  services  à  l’individu.  Mais  cette  logique  de \n",
      "personnalisation  est  également  susceptible  d’affecter \n",
      "– outre les individus – des logiques collectives essen-\n",
      "tielles à la vie de nos sociétés (pluralisme démocratique \n",
      "et culturel, mutualisation du risque).\n",
      "\n",
      "•  L’intelligence  artificielle,  dans  la  mesure  où  elle  re-\n",
      "pose  sur  des  techniques  d’apprentissage,  nécessite \n",
      "d’énormes quantités de données. Or, la législation pro-\n",
      "meut une logique de minimisation de la collecte et de \n",
      "la conservation de données personnelles, conforme à \n",
      "une  conscience  aigüe  des  risques  impliqués  pour  les \n",
      "libertés individuelles et publiques de la constitution de \n",
      "grands  fichiers.  Les  promesses  de  l’IA  justifient-elles \n",
      "une révision de l’équilibre construit par le législateur ?\n",
      "\n",
      "•  Le choix du type de données alimentant un modèle al-\n",
      "gorithmique,  leur  quantité  suffisante  ou  insuffisante, \n",
      "l’existence  de  biais  dans  les  jeux  de  données  servant \n",
      "à entraîner les algorithmes d’apprentissage constituent \n",
      "un enjeu majeur. S’y cristallise le besoin d’établir une at-\n",
      "titude critique et de ne pas nourrir une confiance exces-\n",
      "sive dans la machine.\n",
      "\n",
      "•  L’autonomie croissante des machines ainsi que l’émer-\n",
      "gence  de  formes  d’hybridation  entre  humains  et  ma-\n",
      "chines  (hybridation  au  plan  d’une  action  assistée  par \n",
      "des recommandations algorithmiques, mais aussi pro-\n",
      "chainement au plan physique) questionnent l’idée d’une \n",
      "spécificité humaine irréductible. Faut-il et est-il possible \n",
      "de parler au sens propre d’ « éthique des algorithmes » ? \n",
      "Comment  appréhender  cette  nouvelle  classe  d’objets \n",
      "que sont les robots humanoïdes, objets mais suscep-\n",
      "tibles de susciter chez l’homme des formes d’affects et \n",
      "d’attachement ?\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "RÉSUMÉ\n",
      "\n",
      "La  troisième  partie  du  rapport  envisage  les  réponses \n",
      "possibles formulées à l’occasion du débat public.\n",
      "les  principes  susceptibles  de \n",
      "Elle  aborde  d’abord \n",
      "construire  une  intelligence  artificielle  au  service  de \n",
      "l’homme. Deux principes nouveaux apparaissent comme \n",
      "fondateurs.\n",
      "\n",
      "Ils sont complétés par une ingénierie spécifique et nou-\n",
      "velle  articulée  sur  deux  points  :  l’un  visant  à  repenser \n",
      "l’obligation  d’intervention  humaine  dans  la  prise  de  dé-\n",
      "cision algorithmique (article 10 de la loi Informatique et \n",
      "libertés) ; l’autre à  organiser l’intelligibilité et la responsa-\n",
      "bilité des systèmes algorithmiques.\n",
      "\n",
      "Ces principes font ensuite l’objet d’une déclinaison opéra-\n",
      "tionnelle sous la forme de 6 recommandations adressées \n",
      "tant aux pouvoirs publics qu’aux diverses composantes \n",
      "de  la  société  civile  (grand  public,  entreprises,  associa-\n",
      "tions, etc.) :\n",
      "\n",
      "•  Former à l’éthique tous les maillons de la « chaîne algo-\n",
      "rithmique (concepteurs, professionnels, citoyens) ;\n",
      "\n",
      "•  Rendre les systèmes algorithmiques compréhensibles \n",
      "en renforçant les droits existants et en organisant la \n",
      "médiation avec les utilisateurs ;\n",
      "\n",
      "•  Travailler le design des systèmes algorithmiques au \n",
      "service de la liberté humaine ;\n",
      "\n",
      "•  Constituer une plateforme nationale d’audit des algo-\n",
      "rithmes ;\n",
      "\n",
      "•  Encourager la recherche sur l’IA éthique et lancer une \n",
      "grande cause nationale participative autour d’un projet \n",
      "de recherche d’intérêt général ;\n",
      "\n",
      "•  Renforcer la fonction éthique au sein des entreprises.\n",
      "\n",
      "Le  premier,  substantiel,  est  le  principe  de  loyauté,  dans \n",
      "une version approfondie par rapport à celle initialement \n",
      "formulée par le Conseil d’Etat sur les plateformes. Cette \n",
      "version  intègre  en  effet  une  dimension  collective  de  la \n",
      "loyauté,  celle-ci  visant  à  ce  que  l’outil  algorithmique  ne \n",
      "puisse trahir sa communauté d’appartenance (consumé-\n",
      "riste ou citoyenne), qu’il traite ou non des données per-\n",
      "sonnelles.\n",
      "\n",
      "Le second, d’ordre plus méthodique, est un principe de \n",
      "vigilance/réflexivité. Il vise à répondre dans le temps au \n",
      "défi  constitué  par  le  caractère  instable  et  imprévisible \n",
      "des algorithmes d’apprentissage. Il constitue aussi une \n",
      "réponse aux formes d’indifférence, de négligence et de \n",
      "dilution de responsabilité que peut générer le caractère \n",
      "très  compartimenté  et  segmenté  des  systèmes  algo-\n",
      "rithmiques. Il a enfin pour but de prendre en compte et \n",
      "de contrebalancer la forme de biais cognitif conduisant \n",
      "l’esprit humain à accorder une confiance excessive aux \n",
      "décrets des algorithmes. Il s’agit d’organiser, par des pro-\n",
      "cédures et mesures concrètes, une forme de questionne-\n",
      "ment régulier, méthodique, délibératif et fécond à l’égard \n",
      "de ces objets techniques de la part de tous les acteurs \n",
      "de la chaine algorithmique, depuis le concepteur, jusqu’à \n",
      "l’utilisateur final, en passant par ceux qui entraînent les \n",
      "algorithmes. \n",
      "\n",
      "Ces deux principes apparaissent comme fondateurs de \n",
      "la régulation de ces outils et assistants complexes que \n",
      "sont les algorithmes et l’IA. Ils en permettent l’utilisation \n",
      "et  le  développement  tout  en  intégrant  leur  mise  sous \n",
      "contrôle par la communauté.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "UNE DÉMARCHE INNOVANTE AU SERVICE DE L’ÉLABORATION \n",
      "D’UNE RÉFLEXION ÉTHIQUE COLLECTIVE ET PLURALISTE\n",
      "\n",
      "7\n",
      "\n",
      "Une démarche innovante au service \n",
      "de l’élaboration d’une réflexion éthique  \n",
      "collective et pluraliste\n",
      "\n",
      "Un débat public national sur \n",
      "les enjeux éthiques des algorithmes \n",
      "et de l’intelligence artificielle\n",
      "\n",
      "La loi pour une République numérique de 2016 a confié \n",
      "à  la  CNIL  la  mission  de  conduire  une  réflexion  sur  les \n",
      "enjeux éthiques et les questions de société soulevés par \n",
      "l’évolution des technologies numériques. \n",
      "\n",
      "La CNIL a choisi de faire porter en 2017 cette réflexion \n",
      "sur les algorithmes à l’heure de l’intelligence artificielle. \n",
      "En effet, ceux-ci occupent dans nos vies une place crois-\n",
      "sante,  bien  qu’invisible.  Résultats  de  requêtes  sur  un \n",
      "moteur de recherche, ordres financiers passés par des \n",
      "robots sur les marchés, diagnostics médicaux automa-\n",
      "tiques,  affectation  des  étudiants  à  l’Université  :  dans \n",
      "tous ces domaines, des algorithmes sont à l’œuvre. En \n",
      "2016, le sujet des algorithmes s’était d’ailleurs invité de \n",
      "manière  inédite  dans  le  débat  public  et  a  suscité  une \n",
      "forte attention médiatique (questions sur l’algorithme du \n",
      "logiciel Admission Post-Bac, recours à l’intelligence artifi-\n",
      "cielle dans la stratégie électorale du candidat Trump, rôle \n",
      "des réseaux sociaux dans la diffusion des « fake news »).\n",
      "\n",
      "La réflexion éthique porte \n",
      "\n",
      "sur des choix de société décisifs.\n",
      "\n",
      "Elle ne saurait se construire \n",
      "indépendamment d’une prise \n",
      "en compte de cette dimension \n",
      "\n",
      "pluraliste et collective\n",
      "\n",
      "La réflexion éthique porte sur des choix de société dé-\n",
      "cisifs.  Elle  ne  saurait  se  construire  indépendamment \n",
      "d’une prise en compte de cette dimension pluraliste et \n",
      "collective. Ceci est d’autant plus vrai quand il s’agit d’un \n",
      "objet aussi transversal à toutes les dimensions de notre \n",
      "vie individuelle et sociale que les algorithmes. Il ne serait \n",
      "guère envisageable de rassembler en un unique comité \n",
      "l’ensemble des compétences et des regards nécessaire \n",
      "à l’examen des enjeux soulevés par les algorithmes dans \n",
      "des  secteurs  aussi  divers  que  la  santé,  l’éducation,  le \n",
      "marketing, la culture, la sécurité, etc.\n",
      "\n",
      "Plutôt  que  de  conduire  directement  sur  ces  sujets  une \n",
      "réflexion centralisée, la CNIL a donc fait le choix de se \n",
      "positionner, d’une façon originale, en tant qu’animatrice \n",
      "d’un débat public national ouvert et décentralisé. À l’occa-\n",
      "sion d’un événement de lancement organisé le 23 janvier \n",
      "2017, elle a ainsi appelé tous les acteurs et organismes \n",
      "– institutions publiques, société civile, entreprises – qui \n",
      "le souhaitaient à organiser un débat ou une manifesta-\n",
      "tion sur le sujet, dont ils lui feraient ensuite parvenir la \n",
      "restitution. L’objectif a donc été de s’adresser aux acteurs \n",
      "de terrain pour recueillir auprès d’eux les sujets éthiques \n",
      "identifiés  comme  tels  à  ce  jour  ainsi  que  les  pistes  de \n",
      "solutions évoquées par les uns et par les autres. \n",
      "\n",
      "Soixante  partenaires  ont  souhaité  répondre  à  l’appel \n",
      "lancé par la CNIL. De natures très diverses, ces acteurs \n",
      "relevaient  de  secteurs  très  différents.  Citons,  à  titre \n",
      "d’exemples, la Ligue de l’Enseignement dans l’éducation, \n",
      "la Fédération Française de l’Assurance (FFA), le Ministère \n",
      "de la Culture (DGMIC), l’association Open Law, ou encore \n",
      "la  CFE-CFC  et  FO  Cadres  (ressources  humaines),  etc. \n",
      "Ces 60 partenaires ont organisé 45 manifestations entre \n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "UNE DÉMARCHE INNOVANTE AU SERVICE DE L’ÉLABORATION \n",
      "D’UNE RÉFLEXION ÉTHIQUE COLLECTIVE ET PLURALISTE\n",
      "\n",
      "Une journée de concertation a ainsi été organisée le 14 \n",
      "octobre 2017, avec le soutien de la Ville de Montpellier et \n",
      "de Montpellier Méditerranée Métropole. Un appel à can-\n",
      "didature a permis de recruter un panel diversifié de 37 \n",
      "citoyens.\n",
      "\n",
      "Le format retenu visait à favoriser l’échange d’idées et la \n",
      "construction d’un avis collectif. La technique d’animation \n",
      "a permis successivement aux participants de :\n",
      "\n",
      "•  Comprendre  ce  que  sont  les  algorithmes  et  l’intelli-\n",
      "gence artificielle ;\n",
      "\n",
      " \n",
      "\n",
      "mars  et  octobre  2017  dans  plusieurs  villes  de  France \n",
      "(mais également à l’étranger grâce à la participation de \n",
      "la « Future Society at Harvard Kennedy School »), aux-\n",
      "quelles ont participé environ 3000 personnes. La CNIL a \n",
      "assuré la coordination et la mise en cohérence de l’en-\n",
      "semble.\n",
      "\n",
      "Les manifestations organisées dans le cadre du débat \n",
      "public ont aussi constitué l’occasion de faire vivre dans la \n",
      "société française la réflexion sur des enjeux dont la prise de \n",
      "conscience par l’ensemble de nos contemporains, et pas \n",
      "seulement par les experts, est un enjeu civique et démo-\n",
      "cratique capital.\n",
      "\n",
      "•  Analyser  collectivement  quatre  études  de  cas  (méde-\n",
      "cine et santé / ressources humaines / personnalisation \n",
      "et enfermement algorithmique / éducation et transpa-\n",
      "rence) pour identifier les opportunités et les risques liés \n",
      "à l’usage des algorithmes ;\n",
      "\n",
      " \n",
      "•  Formuler  des  recommandations  pour  assurer  le  dé-\n",
      "ploiement dans un cadre éthique des algorithmes et de \n",
      "l’IA, le degré de consensus de celles-ci ayant ensuite été \n",
      "évalué.\n",
      "\n",
      " \n",
      "Les résultats et enseignements sont présentés dans les \n",
      "encadrés « Le regard du citoyen ».\n",
      "\n",
      "Une concertation citoyenne : \n",
      "Montpellier, 14 octobre 2017\n",
      "\n",
      "Les questions posées par les algorithmes et l’intelligence \n",
      "artificielle renvoient à des choix de société et concernent \n",
      "tous \n",
      "les  citoyens.  L’organisation  d’une  concertation \n",
      "a donc eu pour  objectif de recueillir le point  de vue de \n",
      "simples citoyens. Il s’agissait de compléter les réflexions \n",
      "émises  à  l’occasion  de  diverses  manifestations  ayant \n",
      "principalement  donné  la  parole  à  des  experts  de  diffé-\n",
      "rents secteurs.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "UNE DÉMARCHE INNOVANTE AU SERVICE DE L’ÉLABORATION \n",
      "D’UNE RÉFLEXION ÉTHIQUE COLLECTIVE ET PLURALISTE\n",
      "\n",
      "9\n",
      "\n",
      "La composition du rapport\n",
      "\n",
      "Les manifestations organisées par les partenaires, ain-\n",
      "si que la concertation citoyenne, ont fait l’objet de res-\n",
      "titutions  recueillies  par  la  CNIL.  Les  réflexions  émises \n",
      "par  des  acteurs  pluriels  (syndicats,  associations,  en-\n",
      "treprises, chercheurs, citoyens, etc.) dans des secteurs \n",
      "très divers (de l’assurance à l’éducation, en passant par \n",
      "la justice et la santé) ont ainsi alimenté le présent rap-\n",
      "port, qui constitue un panorama général des questions \n",
      "éthiques soulevées par les algorithmes et l’intelligence \n",
      "artificielle dans leurs applications actuelles et dans leurs \n",
      "promesses à relativement court terme.\n",
      "\n",
      "Animatrice du débat public, la CNIL en est aussi la res-\n",
      "titutrice.  À  cet  égard,  elle  a  assumé  la  composition  du \n",
      "rapport, ce qui implique inévitablement certains choix. La \n",
      "ligne de conduite adoptée a consisté à rendre loyalement \n",
      "et pleinement compte de la pluralité des points de vue \n",
      "exprimés. C’est aussi ce qui explique que les recomman-\n",
      "dations  formulées  à  la  fin  du  rapport  entendent  moins \n",
      "clore  le  débat  que  laisser  ouvertes  un  certain  nombre \n",
      "d’options  possibles  (dimension  incitative  ou  obligatoire \n",
      "des mesures proposées, par exemple) qui devraient faire \n",
      "l’objet d’arbitrages ultérieurs. Il s’agit donc d’éclairer la dé-\n",
      "cision publique et non de s’y substituer. \n",
      "\n",
      "La  CNIL  s’est  également  appuyée  pour  la  rédaction  du \n",
      "rapport  sur  un  travail  de  recherche  documentaire,  sou-\n",
      "vent initié sur la recommandation de tel ou tel partenaire. \n",
      "Les articles ou ouvrages utilisés ont été mentionnés en \n",
      "notes  de  bas  de  page.  On  pourra  également  se  repor-\n",
      "ter  aux  pages  du  site  de  la  CNIL  consacrées  au  débat \n",
      "éthique pour retrouver quelques éléments de bibliogra-\n",
      "phie sommaire1. Enfin, ont été exploités les résultats d’un \n",
      "certain nombre de travaux déjà conduits par diverses ins-\n",
      "titutions en France et à l’étranger (entre autres, l’OPECST, \n",
      "la CERNA, le CNNUM, le Conseil d’Etat, la CGE, la Maison \n",
      "Blanche, France IA, INRIA, AI Now).\n",
      "\n",
      "Les questions posées par les algorithmes \n",
      "\n",
      "et l’intelligence artificielle renvoient à des choix \n",
      "\n",
      "de société et concernent tous les citoyens\n",
      "\n",
      "1      https://www.cnil.fr/fr/ethique-et-numerique-les-algorithmes-en-debat-1 \n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES DATES CLÉS\n",
      "\n",
      "LES DATES CLÉS\n",
      "\n",
      "7 \n",
      "\n",
      "OCTOBRE\n",
      "\n",
      "2016\n",
      "\n",
      "La CNIL obtient pour mission par la loi « République Numérique » de conduire une réflexion  \n",
      "\n",
      "sur les enjeux éthiques et de société soulevés par les nouvelles technologies\n",
      "\n",
      "23 \n",
      "\n",
      "JANVIER\n",
      "\n",
      "2017\n",
      "\n",
      "La CNIL annonce pour 2017 le thème des algorithmes et de l’intelligence artificielle \n",
      "et organise des tables-rondes de lancement réunissant des experts de ces sujets\n",
      "\n",
      "FIN\n",
      "MARS\n",
      "2017\n",
      "\n",
      "Les premiers événements sont organisés par les partenaires du débat public\n",
      "\n",
      "DÉBUT\n",
      "\n",
      "OCTOBRE\n",
      "\n",
      "2017\n",
      "\n",
      "45 événements se sont tenus,  à l’initiative des 60 partenaires du débat public\n",
      "\n",
      "14\n",
      "\n",
      "OCTOBRE\n",
      "\n",
      "2017\n",
      "\n",
      "La CNIL organise une concertation citoyenne à Montpellier réunissant près de 40 citoyens\n",
      "\n",
      "15\n",
      "\n",
      "2017\n",
      "\n",
      "DÉCEMBRE\n",
      "\n",
      "La CNIL présente le rapport « Comment permettre à l’Homme de garder la main ?\n",
      "\n",
      "Les enjeux éthiques des algorithmes et de l’intelligence artificielle », synthèse du débat public\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES CHIFFRES CLÉS\n",
      "\n",
      "11\n",
      "\n",
      "LES CHIFFRES CLÉS\n",
      "\n",
      "45ÉVÉNEMENTS\n",
      "\n",
      "27\n",
      "\n",
      "À PARIS\n",
      "\n",
      "14\n",
      "\n",
      "EN PROVINCE\n",
      "\n",
      "4 \n",
      "\n",
      "OUTRE \n",
      "\n",
      "ATLANTIQUE\n",
      "\n",
      "60 \n",
      "ENVIRON3 000\n",
      "\n",
      "PARTENAIRES\n",
      "\n",
      "1JOURNÉE \n",
      "\n",
      "DE CONCERTATION \n",
      "\n",
      "CITOYENNE \n",
      "\n",
      "PERSONNES PRÉSENTES \n",
      "LORS DES MANIFESTATIONS\n",
      "\n",
      "27\n",
      "\n",
      "PARIS\n",
      "\n",
      "1\n",
      "\n",
      "CAEN\n",
      "\n",
      "2\n",
      "\n",
      "BORDEAUX\n",
      "\n",
      "3\n",
      "\n",
      "TOULOUSE\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "AX-LES-TERMES\n",
      "\n",
      "MONTPELLIER\n",
      "\n",
      "3\n",
      "\n",
      "LILLE\n",
      "\n",
      "2\n",
      "\n",
      "LYON\n",
      "\n",
      "1\n",
      "\n",
      "MARSEILLE\n",
      "\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "13\n",
      "\n",
      "Algorithmes et \n",
      "\n",
      "Intelligence artificielle \n",
      "\n",
      "aujourd’hui\n",
      "\n",
      "Un effort de définition nécessaire \n",
      "\n",
      "à la qualité du débat public\n",
      "\n",
      "P.14\n",
      "\n",
      "Les algorithmes : une réalité ancienne \n",
      "\n",
      "au cœur de l’informatique\n",
      "\n",
      "P.15\n",
      "\n",
      "Des algorithmes à l’intelligence artificielle \n",
      "\n",
      "P.16\n",
      "\n",
      "Cadrer la réflexion en fonction des applications et des impacts \n",
      "\n",
      "les plus cruciaux des algorithmes aujourd’hui\n",
      "\n",
      "P.19\n",
      "\n",
      "Des usages et des promesses dans tous les secteurs\n",
      "\n",
      "P.21\n",
      "\n",
      "\n",
      "14\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "Algorithmes et IA aujourd’hui\n",
      "\n",
      "Un effort de définition nécessaire \n",
      "à la qualité du débat public\n",
      "\n",
      "Algorithmes et intelligence artificielle sont à la mode. Ces \n",
      "mots sont aujourd’hui partout, non sans confusion parfois. \n",
      "Les définitions et les exemples qui en sont donnés dans \n",
      "le débat public aujourd’hui sont souvent imprécis. Ils sont \n",
      "parfois même contradictoires. Cette situation s’explique \n",
      "par le caractère très technique de sujets qui se sont trou-\n",
      "vés rapidement mis en circulation et en débat dans un \n",
      "espace public dépassant largement les cercles d’experts \n",
      "et de spécialistes auxquels ils se sont longtemps trouvés \n",
      "cantonnés.\n",
      "\n",
      "De là, pour peu que l’on y prête attention, une extrême impré-\n",
      "cision dans les termes employés. Quoi de commun entre \n",
      "l’austère notion d’ « intelligence artificielle » définie dans \n",
      "les milieux de la cybernétique dans les années 1950 et \n",
      "sa représentation populaire diffusée notamment par le \n",
      "cinéma hollywoodien ? Qui prête d’ailleurs attention au fait \n",
      "qu’ « intelligence » n’a pas la même signification en français \n",
      "et en anglais, langue dans laquelle a été créé le vocable \n",
      "« artificial intelligence » ? Comment comprendre que l’on \n",
      "dise ici que les algorithmes sont nouveaux et que d’autres \n",
      "voix nous assurent que l’homme y a recours depuis plu-\n",
      "sieurs milliers d’années ?\n",
      "\n",
      "Outre les réalités et les projets techniques qu’ils entendent \n",
      "désigner, les algorithmes et l’intelligence artificielle en sont \n",
      "venus  à  constituer  de  nouvelles  mythologies  de  notre \n",
      "\n",
      "temps, dont la simple évocation suffit à connoter la moder-\n",
      "nité et l’innovation numériques. Rien d’étonnant dès lors \n",
      "à ce que ces termes soient apposés de manière souvent \n",
      "rapide et peu justifiée à des réalités ou à des entreprises \n",
      "soucieuses de se forger une image flatteuse et futuriste : \n",
      "présenter son activité comme relevant du domaine de l’IA \n",
      "est aujourd’hui pour de nombreux acteurs un enjeu d’image, \n",
      "comparable à celui représenté depuis quelques années par \n",
      "l’invocation d’un « Big data » dont les spécialistes soulignent \n",
      "pourtant souvent qu’il demeure une réalité aux dimensions \n",
      "encore modestes. En tout état de cause, la réalité des pro-\n",
      "messes de l’IA est aujourd’hui un sujet de controverses \n",
      "plus ou moins explicites entre chercheurs en intelligence \n",
      "artificielle, entrepreneurs et prescripteurs d’opinions divers \n",
      "dans le domaine des technologies.\n",
      "\n",
      "Comme on le rappellera par la suite, un autre type de confu-\n",
      "sion semble parfois entretenu par des acteurs dont l’activité \n",
      "est généralement reconnue comme relevant du domaine \n",
      "de l’intelligence artificielle. Ces derniers majoreraient réso-\n",
      "lument et exagérément non tant les promesses que les \n",
      "risques d’une intelligence artificielle qui parviendrait à s’au-\n",
      "tonomiser totalement de son créateur au point de mettre en \n",
      "danger l’humanité. Les voix les plus compétentes s’élèvent \n",
      "pour battre en brèche de telles prévisions, assimilées au \n",
      "mieux à des fantasmes, voire à des mensonges. Ceux-ci \n",
      "auraient pour fonction de détourner l’attention publique des \n",
      "\n",
      "Fonder une discussion publique saine et constructive \n",
      "\n",
      "sur les sujets des algorithmes et de l’intelligence \n",
      "\n",
      "artificielle nécessite absolument de préciser le rapport \n",
      "\n",
      "entre algorithmes et intelligence artificielle\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "15\n",
      "\n",
      "problèmes certes plus prosaïques mais plus pressants \n",
      "soulevés par le déploiement de l’intelligence artificielle, en \n",
      "matière de lutte contre les discriminations ou de protection \n",
      "des données personnelles par exemple. \n",
      "\n",
      "Disons-le d’emblée : toute définition en ces matières pourra \n",
      "être sujette à caution selon les différents points de vue. \n",
      "Dans la perspective du présent rapport, l’essentiel est de \n",
      "\n",
      "parvenir à une base de discussion minimale et opératoire \n",
      "qui permette de tracer pragmatiquement le périmètre des \n",
      "algorithmes et de l’intelligence artificielle sources de ques-\n",
      "tions éthiques et de société cruciales. Autrement dit, il s’agit \n",
      "de proposer une définition aussi rigoureuse que possible \n",
      "mais prenant en compte la perception commune de ce en \n",
      "quoi algorithmes et IA constituent aujourd’hui des enjeux \n",
      "dignes d’attention.\n",
      "\n",
      "ENQUÊTE\n",
      "\n",
      "Algorithmes et IA : un objet mal connu des Français*\n",
      "\n",
      "Les algorithmes sont présents dans l’esprit des Français mais de façon assez confuse. Si 83% des Français \n",
      "ont déjà entendu parler des algorithmes, ils sont plus de la moitié à ne pas savoir précisément de quoi \n",
      "il s’agit (52%). Leur présence est déjà appréhendée comme massive dans la vie de tous \n",
      "les jours par 80% des Français qui considèrent, à 65%, que cette dynamique va encore \n",
      "s’accentuer dans les années qui viennent.\n",
      "\n",
      "83 %\n",
      "\n",
      "des Français \n",
      "ont déjà entendu\n",
      "parler des\n",
      "algorithmes\n",
      "\n",
      "*  Sondage mené par l’IFOP pour la CNIL en janvier 2017 (auprès d’un échantillon de 1001 personnes, \n",
      "représentatif de la population française âgée de 18 ans et plus) sur le niveau de notoriété des \n",
      "algorithmes au sein de la population française.\n",
      "\n",
      "Les algorithmes : une réalité ancienne \n",
      "au cœur de l’informatique\n",
      "\n",
      "Au sens strict, un algorithme est la description d’une suite \n",
      "finie et non ambigüe d’étapes (ou d’instructions) permettant \n",
      "d’obtenir un résultat à partir d’éléments fournis en entrée. \n",
      "Par exemple, une recette de cuisine est un algorithme, \n",
      "permettant d’obtenir un plat à partir de ses ingrédients2. \n",
      "L’existence d’algorithmes utilisés pour résoudre des équa-\n",
      "tions est d’ailleurs attestée très anciennement, dès le IIIe \n",
      "millénaire en Mésopotamie babylonienne.\n",
      "\n",
      "Dans le monde de plus en plus numérique dans lequel nous \n",
      "vivons, les algorithmes informatiques permettent de com-\n",
      "biner des informations les plus diverses pour produire \n",
      "une grande variété de résultats : simuler l’évolution de \n",
      "la propagation de la grippe en hiver, recommander des \n",
      "\n",
      "livres à des clients sur la base des choix déjà effectués \n",
      "par d’autres clients, comparer des images numériques \n",
      "de visages ou d’empreintes digitales, piloter de façon \n",
      "autonome des automobiles ou des sondes spatiales, etc.\n",
      "\n",
      "Pour qu’un algorithme puisse être mis en œuvre par un \n",
      "ordinateur, il faut qu’il soit exprimé dans un langage infor-\n",
      "matique, transcrit en un programme (une sorte de texte \n",
      "composé de commandes écrites, également appelé « code \n",
      "source »). Ce programme peut alors être exécuté dans un \n",
      "logiciel ou compilé sous la forme d’une application. Un logi-\n",
      "ciel a recours en général à de nombreux algorithmes : pour \n",
      "la saisie des données, le calcul du résultat, leur affichage, \n",
      "la communication avec d’autres logiciels, etc.\n",
      "\n",
      "2  Voir par exemple : http://www.cnrtl.fr/definition/algorithme\n",
      "\n",
      "\n",
      "16\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "Des algorithmes à l’intelligence artificielle\n",
      "\n",
      "Peu de notions font aujourd’hui l’objet d’un usage plus \n",
      "mouvant que celle d’ « intelligence artificielle » (IA). Le \n",
      "choix a été fait dans ce rapport de se concentrer pragmati-\n",
      "quement sur les usages d’ores et déjà effectifs de l’intelligence \n",
      "artificielle et, plus précisément, sur ceux qui ont fait l’objet des \n",
      "plus rapides développement au cours des dernières années, \n",
      "en lien avec les progrès du machine learning (ou apprentis-\n",
      "sage automatique).\n",
      "\n",
      "De façon large, l’intelligence artificielle peut être définie \n",
      "comme « la science qui consiste à faire faire aux machines \n",
      "ce que l’homme ferait moyennant une certaine intelligence » \n",
      "(Marvin Minsky). Si c’est en 1956, lors de la conférence de \n",
      "Darmouth que naît formellement la notion d’intelligence \n",
      "artificielle dans le milieu de la cybernétique, on peut consi-\n",
      "dérer comme point de départ l’article publié en 1950 par \n",
      "Alan Turing (Computing Machinery and Intelligence) où celui-ci \n",
      "pose la question de savoir si les machines peuvent penser. \n",
      "Les chercheurs de cette discipline naissante ambitionnent \n",
      "de doter des ordinateurs d’une intelligence généraliste com-\n",
      "parable à celle de l’homme, et non pas limitée à certains \n",
      "domaines ou à certaines tâches. \n",
      "\n",
      "L’histoire  de  l’intelligence  artificielle  depuis  les  années \n",
      "1950 n’a pas été celle d’un progrès continu. En premier \n",
      "lieu, les chercheurs se sont vus contraints de délaisser \n",
      "l’objectif visant à mettre au point une IA généraliste (ou \n",
      "« IA forte ») pour se concentrer sur des tâches plus spé-\n",
      "cifiques, sur la résolution de problèmes tels que la recon-\n",
      "naissance d’images, la compréhension du langage naturel \n",
      "ou la pratique de jeux (jeu de dames, échecs, jeu de go, par \n",
      "exemple). On parle dès lors d’ « IA faible », car spécialisée. \n",
      "Même si l’on s’en tient au domaine de l’IA faible, l’histoire de \n",
      "ce champ de recherche et de ses applications est marquée \n",
      "par des discontinuités. À une période d’optimisme dans \n",
      "les années 1980 a succédé à partir des années 1990 un \n",
      "« hiver de l’IA » : les progrès se sont heurtés à une insuf-\n",
      "fisance tant de la puissance de calcul que des données \n",
      "disponibles, notamment.\n",
      "\n",
      "Ces  dernières  années  ont  au  contraire  été  marquées \n",
      "par une série de succès spectaculaires qui ont remis au \n",
      "goût du jour les promesses de l’IA. La victoire d’Alpha Go \n",
      "(Google) contre le champion du monde de jeu de Go, Lee \n",
      "Sedol, en mars 2016, a constitué symboliquement le plus \n",
      "notable de ces événements. Contrairement au jeu d’échecs, \n",
      "le go, du fait de la multiplicité innombrable des combinai-\n",
      "\n",
      "sons qu’il permet, ne se prête pas à la mémorisation d’un \n",
      "grand nombre de parties que la machine pourrait se conten-\n",
      "ter de reproduire. \n",
      "\n",
      "La victoire d’Alpha Go illustre le fait que les développe-\n",
      "ments récents de l’IA sont notamment liés au perfectionne-\n",
      "ment de la technique du machine learning (apprentissage \n",
      "automatique), qui en constitue l’une des branches. Alors \n",
      "que le programmeur doit traditionnellement décomposer \n",
      "en de multiples instructions la tâche qu’il s’agit d’automa-\n",
      "tiser de façon à en expliciter toutes les étapes, l’apprentis-\n",
      "sage automatique consiste à alimenter la machine avec \n",
      "des exemples de la tâche que l’on se propose de lui faire \n",
      "accomplir. L’homme entraîne ainsi le système en lui fournis-\n",
      "sant des données à partir desquelles celui-ci va apprendre \n",
      "et déterminer lui-même les opérations à effectuer pour \n",
      "accomplir la tâche en question. Cette technique permet \n",
      "de réaliser des tâches hautement plus complexes qu’un \n",
      "algorithme classique. Andrew Ng, de l’Université Stanford, \n",
      "définit ainsi le machine learning comme « la science per-\n",
      "mettant de faire agir les ordinateurs sans qu’ils aient à \n",
      "être explicitement programmés ». Cela recouvre la concep-\n",
      "tion, l’analyse, le développement et la mise en œuvre de \n",
      "méthodes permettant à une machine d’évoluer par un pro-\n",
      "cessus systématique, et de remplir des tâches difficiles. \n",
      "L’intelligence artificielle qui repose sur le machine learning \n",
      "concerne donc des algorithmes dont la particularité est \n",
      "d’être conçus de sorte que leur comportement évolue dans \n",
      "le temps, en fonction des données qui leur sont fournies. \n",
      "\n",
      "L’apprentissage profond (Deep learning) est le socle des \n",
      "avancées récentes de l’apprentissage automatique, dont il \n",
      "est l’une des branches3. On distingue apprentissage auto-\n",
      "matique supervisé4  (des données d’entrées qualifiées par \n",
      "des humains sont fournies à l’algorithme qui définit donc \n",
      "des règles à partir d’exemples qui sont autant de cas vali-\n",
      "dés) et non supervisé5  (les données sont fournies brutes \n",
      "à l’algorithme qui élabore sa propre classification et est \n",
      "libre d’évoluer vers n’importe quel état final lorsqu’un motif \n",
      "ou un élément lui est présenté). L’apprentissage supervisé \n",
      "nécessite que des instructeurs apprennent à la machine \n",
      "les  résultats  qu’elle  doit  fournir,  qu’ils  l’«  entraînent  ». \n",
      "Les personnes entraînant l’algorithme remplissent en fait \n",
      "souvent une multitude de tâches très simples. Des plate-\n",
      "formes telles que le « Mechanical Turk » d’Amazon sont \n",
      "les lieux où se recrutent ces milliers de « micro-tâcherons » \n",
      "(Antonio Casilli) qui, par exemple, étiquettent les immenses \n",
      "\n",
      "3    Il s’agit d’un ensemble de méthodes d’apprentissage automatique tentant de modéliser avec un haut niveau d’abstraction des données grâce à des architectures articulées \n",
      "\n",
      "de différentes transformations non linéaires. Sa logique étant inspirée du fonctionnement des neurones, on parle souvent de « réseaux neuronaux ».\n",
      "\n",
      "4  Un algorithme de scoring de crédit utilisera cette technique : on fournit l’ensemble des caractéristiques connues des clients et de leur emprunt en indiquant ceux qui n’ont pas \n",
      "\n",
      "remboursé leur crédit, et l’algorithme sera capable de fournir un score de risque de non remboursement pour les futurs clients. \n",
      "\n",
      "5  Un algorithme de détection des typologies de fraudes utilisera cette technique : on fournit à l’algorithme toutes les données relatives à des fraudes avérées, et l’algorithme sera \n",
      "capable de dégager des similitudes entre ces fraudes, et de dégager des typologies de fraudes. L’apprentissage non supervisé peut aussi servir à identifier, sur la bande sonore \n",
      "d’une émission de radio, les séquences de parole de différents locuteurs.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "17\n",
      "17\n",
      "\n",
      "FOCUS\n",
      "\n",
      "L’exemple de la reconnaissance d’images\n",
      " \n",
      "La reconnaissance d’images permet de prendre la mesure de ce qui distingue algorithmes classiques et \n",
      "algorithmes de machine learning (que le vocabulaire courant confond aujourd’hui généralement avec l’IA). \n",
      "Imaginons que l’on ait pour objectif de faire reconnaître les tigres à une machine. Si l’on se proposait d’y \n",
      "parvenir au moyen d’un algorithme classique, il faudrait imaginer pouvoir décrire explicitement en langage \n",
      "de programmation la totalité des opérations intellectuelles que nous réalisons lorsque nous identifions que \n",
      "nous avons à faire à un tigre et non pas, par exemple, à tout autre animal, voire à un lion ou à un chat. Si \n",
      "distinguer un tigre d’un chat ne pose aucun problème même à un jeune enfant, en décomposer et expliciter \n",
      "l’ensemble des étapes nécessaires à reconnaitre un tigre (autrement dit, en donner l’algorithme) s’avère \n",
      "être une tâche, sinon impossible du moins d’une ampleur rédhibitoire. C’est ici qu’intervient la technique \n",
      "du machine learning. Il s’agit de fournir à la machine des exemples en grande quantité, en l’occurrence de \n",
      "très nombreuses photographies de tigres, ainsi que des photographies d’autres animaux. À partir de ce jeu \n",
      "de données, la machine apprend à reconnaître des tigres. Elle élabore elle-même, par la confrontation des \n",
      "milliers de photographies qui lui sont fournies, les critères sur lesquels elle s’appuiera pour reconnaître \n",
      "des tigres dans des photographies qui lui seront ultérieurement soumises. \n",
      "\n",
      "Il s’agit ici d’ « apprentissage supervisé » : c’est bien l’homme qui fournit à la machine des milliers de photo-\n",
      "graphies qu’il a préalablement identifiées comme représentant des tigres ainsi que d’autres explicitement \n",
      "identifiées comme ne représentant pas des tigres. \n",
      "\n",
      "quantités de photographies utilisées pour entraîner un logi-\n",
      "ciel de reconnaissance d’images. Le système de captcha \n",
      "de Google « recaptcha » est un autre exemple d’utilisation \n",
      "à grande échelle d’humains pour entrainer des machines.\n",
      "Ces algorithmes d’apprentissage sont utilisés dans un \n",
      "nombre croissant de domaines, allant de la prédiction du \n",
      "trafic routier à l’analyse d’images médicales.\n",
      "\n",
      "On comprend à travers l’exemple de la reconnaissance \n",
      "d’images (voir encadré) en quoi l’intelligence artificielle \n",
      "ouvre la voie à l’automatisation de tâches incomparable-\n",
      "ment plus complexes que l’algorithmique classique. L’IA, \n",
      "contrairement aux algorithmes déterministes construit \n",
      "elle-même à partir des données qui lui sont fournies les \n",
      "modèles qu’elle va appliquer pour appréhender les réali-\n",
      "tés qui lui sont soumises. Ainsi s’explique qu’elle s’avère \n",
      "aujourd’hui particulièrement prometteuse dans des sec-\n",
      "teurs produisant des quantités énormes de données, telles \n",
      "que la météorologie.\n",
      "\n",
      "Les exemples d’utilisation de l’intelligence artificielle sont \n",
      "d’ores et déjà nombreux, bien au-delà du seul domaine de \n",
      "la reconnaissance de formes. Ainsi, la classification du \n",
      "spam parmi les messages reçus sur Gmail constitue une \n",
      "application caractéristique, dans sa simplicité même, de l’IA. \n",
      "\n",
      "?\n",
      "\n",
      "LE SAVIEZ-VOUS ?\n",
      "Une entreprise comme Airbus mobilise \n",
      "aujourd’hui concrètement l’intelligence \n",
      "artificielle à des fins de reconnaissance \n",
      "de forme. Apprendre à un système \n",
      "à reconnaître sur une photographie \n",
      "aérienne d’une zone maritime les \n",
      "différents navires présents peut servir, \n",
      "par exemple, à confronter l’emplacement \n",
      "des embarcations ainsi repérées aux \n",
      "signaux émis par les balises et à identifier \n",
      "des navires en perdition ou qui cherchent \n",
      "à se soustraire à la surveillance maritime. \n",
      "L’intérêt réside dans la rapidité d’une \n",
      "opération qui, si elle n’est pas automa-\n",
      "tisée, réclame un temps et des moyens \n",
      "considérables. Depuis quelques années, \n",
      "les progrès de ces techniques sont tels que \n",
      "la machine surpasse désormais l’humain \n",
      "pour la fiabilité de l’identification de \n",
      "navires parfois difficilement distinguables \n",
      "de nuages.\n",
      "\n",
      "\n",
      "18\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "Le signalement par les usagers de messages considérés \n",
      "comme indésirables permet à Google de constituer une \n",
      "base conséquente et constamment alimentée à partir de \n",
      "laquelle le système peut apprendre à déterminer les carac-\n",
      "téristiques des spams qui vont ensuite lui permettre de \n",
      "proposer de lui-même quels messages filtrer. Toujours chez \n",
      "Google, l’intelligence artificielle est à l’œuvre dans le ser-\n",
      "vice de traduction automatique. L’entreprise explique éga-\n",
      "lement avoir eu recours au machine learning pour analyser \n",
      "le fonctionnement du système de refroidissement de ses \n",
      "data centers. L’automatisation de cette fonction d’analyse \n",
      "aurait ainsi permis de réduire de 40 % l’énergie nécessaire \n",
      "au refroidissement de ces installations.\n",
      "\n",
      "L’utilisation industrielle de l’IA n’est pas nouvelle : elle s’est \n",
      "notamment développée dans les années 1980, quand les \n",
      "« systèmes experts » ont permis d’optimiser l’opération de \n",
      "vidange des cuves des centrales nucléaires, automatisant \n",
      "les calculs et renforçant du même coup leur fiabilité en per-\n",
      "mettant de substantielles économies liées à la réduction \n",
      "de la durée d’immobilisation des installations à des fins \n",
      "de maintenance.\n",
      "\n",
      "Les  robots  conversationnels  (chat  bots)  et  assistants \n",
      "vocaux (comme Siri, Google Assistant ou Alexa) consti-\n",
      "tuent un autre pan en rapide développement de l’intelligence \n",
      "artificielle : ils peuvent par exemple fournir des informations \n",
      "et répondre à des questions standardisées.\n",
      "\n",
      "À la lumière de ces applications, on comprend donc en \n",
      "quoi le machine learning constitue à strictement parler une \n",
      "rupture par rapport à l’algorithmique classique. Avec les \n",
      "algorithmes apprenants, c’est bien une nouvelle classe d’al-\n",
      "gorithmes qui émerge : on passe progressivement « d’un \n",
      "monde de programmation à un monde d’apprentissage » \n",
      "(Jean-Philippe Desbiolles, événement de lancement du \n",
      "débat public, CNIL, 23 janvier 2017). Les algorithmes clas-\n",
      "siques sont déterministes, leurs critères de fonctionne-\n",
      "ment sont explicitement définis par ceux qui les mettent \n",
      "en œuvre. Les algorithmes apprenants, au contraire, sont \n",
      "dits probabilistes. S’ils constituent une technologie bien \n",
      "plus puissante que les algorithmes classiques, leurs résul-\n",
      "tats sont mouvants et dépendent à chaque instant de la \n",
      "base d’apprentissage qui leur a été fournie et qui évolue \n",
      "elle-même au fur et à mesure de leur utilisation. Pour \n",
      "\n",
      "reprendre l’exemple du tigre (voir encadré), il est possible \n",
      "qu’une intelligence artificielle ayant été entraînée sur une \n",
      "base dans laquelle figure une seule espèce de tigres ne \n",
      "soit pas à même de reconnaître un tigre appartenant à \n",
      "une autre espèce. Mais on peut supposer qu’elle puisse \n",
      "aussi élargir sa capacité à reconnaître d’autres espèces \n",
      "de tigres à force d’être confrontée à de plus en plus d’in-\n",
      "dividus partageant des traits communs aux deux races.\n",
      "\n",
      "Au-delà de ces différences techniques, une approche \n",
      "globale des algorithmes et de l’IA demeure cependant \n",
      "pertinente.  Algorithmes  déterministes  et  algorithmes \n",
      "apprenants soulèvent en effet des problèmes communs. \n",
      "Dans un cas comme dans l’autre, la finalité des applica-\n",
      "tions de ces classes d’algorithmes consiste à automati-\n",
      "ser des tâches autrement accomplies par des humains, \n",
      "voire à déléguer à ces systèmes automatisés des prises \n",
      "de décisions plus ou moins complexes. Dès lors que l’on \n",
      "se détache d’une appréhension strictement technique de \n",
      "ces objets pour en aborder les conséquences et les impli-\n",
      "cations sociales, éthiques, voire politiques, les problèmes \n",
      "posés se recoupent largement et méritent de faire l’objet \n",
      "d’une investigation conjointe. \n",
      "\n",
      "Précisons enfin qu’algorithmes et intelligence artificielle \n",
      "recoupent à bien des égards ce que l’on appelle, de façon \n",
      "généralement imprécise, « Big data ». Le Big data désigne \n",
      "non seulement d’immenses quantités de données diverses \n",
      "mais également les techniques qui permettent de les traiter, \n",
      "de les faire parler, d’y repérer des corrélations inattendues, \n",
      "voire de leur conférer une capacité prédictive. De même, \n",
      "l’intelligence artificielle est indissociable des immenses \n",
      "quantités de données nécessaires pour l’entraîner et qu’elle \n",
      "permet en retour de traiter.\n",
      "\n",
      "L’algorithme sans données \n",
      "est aveugle. Les données \n",
      "\n",
      "sans algorithmes sont muettes\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "19\n",
      "\n",
      "Cadrer la réflexion en fonction \n",
      "des applications et des impacts les plus \n",
      "cruciaux des algorithmes aujourd’hui\n",
      "\n",
      "En un sens l’algorithmique recouvre l’informatique et croise \n",
      "plus généralement tout ce qu’on a coutume d’englober sous \n",
      "le terme de « numérique ».\n",
      "\n",
      "Face à un sujet potentiellement aussi vaste, il est donc \n",
      "aussi nécessaire que légitime de limiter le périmètre de la \n",
      "réflexion aux algorithmes qui posent aujourd’hui les ques-\n",
      "tions éthiques et de société les plus pressantes. La réflexion \n",
      "éthique sur les systèmes d’IA et sur les algorithmes n’a \n",
      "en effet de sens que si elle prend aussi en compte l’ins-\n",
      "cription de ceux-ci dans des contextes sociaux, humains, \n",
      "professionnels. \n",
      "\n",
      "Les pages qui suivent envisageront ainsi les usages de l’in-\n",
      "telligence artificielle en limitant cette dernière aux usages \n",
      "s’appuyant sur le machine learning, qui sont les plus discu-\n",
      "tés aujourd’hui même si, en toute rigueur, ils ne constituent \n",
      "pas l’entièreté de ce domaine6.\n",
      "\n",
      "Par ailleurs, il a été décidé d’exclure du champ de la réflexion \n",
      "les problèmes soulevés par l’IA forte (ou générale). L’IA forte \n",
      "désigne des systèmes susceptibles de devenir complète-\n",
      "ment autonomes qui pourraient même se retourner contre \n",
      "l’homme. Cette vision se nourrit souvent d’un imaginaire \n",
      "apocalyptique alimenté par le cinéma hollywoodien dans le \n",
      "sillage de mythes parfois bien plus anciens (Frankenstein, \n",
      "etc.). Elle est souvent reliée à une interrogation concernant \n",
      "le niveau de conscience de soi d’une telle machine (en \n",
      "lien avec le thème de la singularité technologique). Elle \n",
      "est par ailleurs propagée par des prises de positions de \n",
      "personnalités du numérique disposant d’une forte visibilité \n",
      "médiatique, comme Elon Musk ou Stephen Hawking. Enfin, \n",
      "la diffusion du thème de la « singularité » par les milieux \n",
      "transhumanistes rayonnant depuis la Silicon Valley ren-\n",
      "force les discours annonçant le dépassement prochain de \n",
      "l’homme par les machines. Force est pourtant de constater \n",
      "qu’elle est accueillie avec scepticisme par les plus éminents \n",
      "chercheurs et experts en informatique, comme en France \n",
      "Jean-Gabriel Ganascia. L’hypothèse de l’avènement d’une \n",
      "\n",
      "IA forte est même dénoncée par certains (dont ce dernier) \n",
      "comme un moyen d’éluder de plus sérieux problèmes – \n",
      "éthiques voire tout simplement juridiques – que posent \n",
      "déjà et à brève échéance les progrès effectifs de l’IA faible \n",
      "et son déploiement croissant. \n",
      "\n",
      "Il aurait été possible, en toute rigueur et en prenant les \n",
      "termes au pied de la lettre, d’inclure dans le périmètre de \n",
      "notre réflexion sur les algorithmes les questions liées au \n",
      "chiffrement dans la mesure où cette technologie repose \n",
      "sur l’utilisation d’algorithmes. Le même procédé aurait pu \n",
      "conduire à considérer la « blockchain » comme partie inté-\n",
      "grante du sujet. Là encore, il a semblé préférable d’adopter \n",
      "une attitude pragmatique, guidée par la perception publique \n",
      "de ce que sont aujourd’hui les algorithmes et leurs applica-\n",
      "tions soulevant le plus de problèmes et d’interrogations. En \n",
      "d’autres termes, nous avons choisi de limiter le champ de la \n",
      "réflexion à ceux des algorithmes qui, dans l’immense diver-\n",
      "sité qui est la leur à l’ère numérique, soulèvent aujourd’hui \n",
      "des problèmes susceptibles d’interpeller directement le \n",
      "grand public et les décideurs, tant publics que privés. \n",
      "\n",
      "À cet égard, les algorithmes de recommandation, s’ils ne \n",
      "constituent techniquement qu’une fraction des différents \n",
      "types d’algorithmes, constituent une partie importante de \n",
      "la question. Les algorithmes de recommandation sont \n",
      "employés pour établir des modèles prédictifs à partir d’une \n",
      "quantité importante de données et les appliquer en temps \n",
      "réel à des cas concrets. Ils élaborent des prévisions sur \n",
      "des comportements ou des préférences permettant de \n",
      "devancer les besoins des consommateurs, d’orienter une \n",
      "personne vers le choix jugé le plus approprié pour elle... Ces \n",
      "algorithmes peuvent par exemple être utilisés pour proposer \n",
      "des restaurants sur un moteur de recherche.\n",
      "\n",
      "Si l’on prolonge cette approche, on peut lister ainsi les \n",
      "principales fonctions et applications des algorithmes \n",
      "susceptibles de faire débat et sur lesquelles la présente \n",
      "réflexion est centrée :\n",
      "\n",
      "6    Les deux grandes approches de l’IA sont, d’une part, l’approche symboliste et cognitiviste et, d’autre part, l’approche neuro-inspirée et connexionniste (apprentissage automatique, \n",
      "réseaux de neurones, etc.). Les systèmes experts ont connu un important développement dans les années 1980. Les principales avancées récentes reposent sur l’apprentissage \n",
      "automatique.\n",
      "\n",
      "\n",
      "20\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "•  Produire des connaissances ;\n",
      "•  Apparier une demande et une offre (« matching »), répartir \n",
      "des ressources (passagers et chauffeurs de taxis, parents \n",
      "et places en crèche, étudiants et places à l’université, etc.) ;\n",
      "•  Recommander un produit, une offre de façon person-\n",
      "nalisée ;\n",
      "•  Aider la prise de décision ;\n",
      "•  Prédire, anticiper (par exemple, des phénomènes naturels, \n",
      "des infractions, la survenue d’une maladie).\n",
      "\n",
      "Ces grandes fonctions découlent de la capacité des algo-\n",
      "rithmes à filtrer l’information, à modéliser des phénomènes \n",
      "en identifiant des motifs parmi de grandes masses de don-\n",
      "nées et à profiler les individus7. \n",
      "\n",
      "D’une manière générale, la visibilité accrue des algorithmes \n",
      "et des questions qu’ils posent aujourd’hui est indissociable \n",
      "des masses de données inédites à disposition dans tous \n",
      "les secteurs qu’il faut trier pour pouvoir en tirer tout le \n",
      "potentiel. La numérisation de notre société sous toutes ses \n",
      "formes – dématérialisation des transactions et services, \n",
      "révolution des capteurs, de l’Internet des objets, diffusion \n",
      "du smartphone, généralisation des politiques d’open data, \n",
      "etc. – est à l’origine de cette profusion. Celle-ci constitue \n",
      "aujourd’hui une ressource mais aussi un défi : si nous avons \n",
      "besoin de recommandations, c’est que l’offre information-\n",
      "nelle est devenue pléthorique ; s’il est possible de profiler, \n",
      "c’est que la quantité de données collectées sur les indivi-\n",
      "dus permet de dépasser la segmentation par catégories \n",
      "prédéterminées. L’enjeu soulevé par la qualité et la perti-\n",
      "nence des données disponibles ou choisies pour alimen-\n",
      "\n",
      "ter les algorithmes constitue un autre point essentiel que \n",
      "rencontre toute réflexion à l’égard de ceux-ci.\n",
      "\n",
      "Il faut aussi introduire l’idée d’autonomisation, pour bien \n",
      "prendre la mesure des enjeux soulevés par les algorithmes \n",
      "aujourd’hui. Si les algorithmes posent question, c’est aussi \n",
      "parce qu’ils permettent de déléguer des tâches auparavant \n",
      "accomplies par l’homme à des systèmes automatiques de \n",
      "plus en plus « autonomes ». Cependant, la délégation de \n",
      "tâches voire de décisions à des algorithmes traditionnels \n",
      "n’implique nullement que la production des algorithmes \n",
      "elle-même échappe à l’homme. L’intervention humaine est \n",
      "bien présente dans le recours aux algorithmes, par l’inter-\n",
      "médiaire du paramétrage de l’algorithme, du choix et de la \n",
      "pondération des critères et des catégories de données à \n",
      "prendre en compte pour arriver au résultat recherché. Par \n",
      "exemple, si l’humain n’intervient pas directement dans la \n",
      "recommandation d’un restaurant par le biais d’une plate-\n",
      "forme algorithmique, en revanche le rôle des développeurs \n",
      "est fondamental. En effet, ces derniers déterminent notam-\n",
      "ment l’importance que pourra jouer la localisation des res-\n",
      "taurants, leur notation par d’autres usagers ou encore sa \n",
      "concordance supposée (là encore en fonction de critères \n",
      "à définir) avec le profil du requêteur.\n",
      "\n",
      "Avec le développement du machine learning, on se situe \n",
      "un pas plus loin dans cette dynamique d’autonomisation, \n",
      "la machine écrivant « elle-même » les instructions qu’elle \n",
      "exécute, déterminant les paramètres qui doivent la guider \n",
      "dans le but d’accomplir une finalité qui reste cependant \n",
      "définie par l’homme.\n",
      "\n",
      "La visibilité accrue des algorithmes \n",
      "\n",
      "aujourd’hui est indissociable des masses de données \n",
      "\n",
      "inédites à disposition dans tous les secteurs, \n",
      "\n",
      "qu’il faut trier pour pouvoir en tirer tout le potentiel\n",
      "\n",
      "7    Le profilage est défini par le Règlement européen sur la protection des données à caractère personnel comme « toute forme de traitement automatisé de données à caractère \n",
      "\n",
      "personnel consistant à utiliser ces données à caractère personnel pour évaluer certains aspects personnels relatifs à une personne physique, notamment pour analyser ou \n",
      "prédire des éléments concernant le rendement au travail, la situation économique, la santé, les préférences personnelles, les intérêts, la fiabilité, le comportement, la localisation \n",
      "ou les déplacements de cette personne physique ».\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "21\n",
      "\n",
      "Des usages et des promesses \n",
      "dans tous les secteurs\n",
      "\n",
      "Les usages des algorithmes et de l’intelligence artificielle \n",
      "se développent dans tous les secteurs. Un discours porté \n",
      "très énergiquement par les acteurs économiques met en \n",
      "avant les avantages et les promesses de ces outils. On \n",
      "en mentionnera ici quelques exemples tout en renvoyant \n",
      "pour plus de détails aux fiches sectorielles présentes en \n",
      "annexe et traçant les contours des grandes applications \n",
      "des algorithmes que les débats ont permis d’évoquer8.\n",
      "\n",
      "Les usages aujourd’hui les plus banalisés ont trait, notamment, \n",
      "aux moteurs de recherche sur internet, aux applications de \n",
      "navigation routière, à la recommandation sur les plateformes \n",
      "de contenu culturel (type Netflix ou Amazon) ou sur les réseaux \n",
      "sociaux, au marketing pour le ciblage publicitaire et, de plus \n",
      "en plus, pour la prospection électorale.\n",
      "\n",
      "Dans le domaine de la santé publique, l’utilisation des algo-\n",
      "rithmes est mise en avant pour la veille sanitaire (détection \n",
      "d’épidémies, de risques psycho-sociaux). On évoque de plus \n",
      "en plus les promesses d’une médecine de précision bâtissant \n",
      "des solutions thérapeutiques personnalisées en croisant les \n",
      "données du patient à celles de gigantesques cohortes. \n",
      "\n",
      "Les fonctions régaliennes de l’État sont également concer-\n",
      "nées par l’émergence d’acteurs prétendant, par exemple, \n",
      "fournir des outils d’aide aux professions juridiques qui \n",
      "permettraient, à partir du traitement de données de juris-\n",
      "prudence, d’anticiper l’issue d’un procès ou d’affiner une \n",
      "stratégie judiciaire. Les services de police, en France et à \n",
      "l’étranger, commencent quant à eux à recourir à des outils \n",
      "algorithmiques destinés, par l’analyse de données, à orienter \n",
      "leurs efforts vers tel ou tel secteur.\n",
      "\n",
      "Le débat largement médiatisé autour d’ « APB » a mis en \n",
      "lumière aux yeux du grand public le recours à l’algorithme \n",
      "pour la répartition de centaines de milliers d’étudiants dans \n",
      "les universités. Au-delà de la gestion des flux, l’algorithme \n",
      "interroge les pratiques pédagogiques par des stratégies de \n",
      "personnalisation de l’enseignement toujours plus fines ou \n",
      "par la détection possible de décrochages scolaires. \n",
      "\n",
      "ENQUÊTE\n",
      "\n",
      "Une connaissance inégale \n",
      "des usages des algorithmes*\n",
      "\n",
      "L’intervention d’algorithmes est bien repérée \n",
      "par le public lorsqu’il s’agit d’un usage tel que \n",
      "le ciblage publicitaire (90 % des sondés en ont \n",
      "conscience).\n",
      "\n",
      " \n",
      "Elle est en revanche souvent moins clairement \n",
      "perçue en ce qui concerne l’évaluation de la \n",
      "« compatibilité amoureuse » sur des applica-\n",
      "tions de rencontre (46 % des répondants) ou \n",
      "l’élaboration d’un diagnostic médical (33 %).\n",
      "\n",
      "*  Enquête réalisée dans le cadre du débat public \n",
      "par l’association « Familles rurales », association \n",
      "familiale orientée vers les milieux ruraux, auprès \n",
      "de 1076 de ses adhérents.\n",
      "\n",
      "Sur le marché de l’emploi, enfin, de nombreux acteurs \n",
      "travaillent actuellement au développement de solutions \n",
      "d’aide au recrutement (par appariement de l’offre et de \n",
      "la demande d’emploi, notamment) et de gestion des res-\n",
      "sources humaines.\n",
      "\n",
      "Sans prétendre épuiser un objet aux applications innom-\n",
      "brables, le tableau qui figure à la page suivante donne \n",
      "cependant une idée de la façon dont les grandes fonctions \n",
      "identifiées des algorithmes et de l’intelligence artificielle se \n",
      "retrouvent dans différents secteurs.\n",
      "\n",
      "8    Le développement industriel de l’intelligence artificielle est porté principalement par deux types d’acteurs. D’une part, des spécialistes de la fourniture de technologies et de \n",
      "\n",
      "services aux grandes entreprises, comme IBM avec Watson. D’autre part, les grands industriels de la donnée numérique (dont les GAFA), qui investissent fortement et chargent \n",
      "leurs services en IA (comme Google avec Translate, la reconnaissance d’images ou le traitement automatique de la parole).\n",
      "\n",
      "\n",
      "22\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ALGORITHMES ET INTELLIGENCE ARTIFICIELLE AUJOURD’HUI\n",
      "\n",
      "Les grandes fonctions des algorithmes et de l’IA dans différents secteurs\n",
      "\n",
      "Education\n",
      "\n",
      "Justice\n",
      "\n",
      "Santé\n",
      "\n",
      "Sécurité\n",
      "\n",
      "Travail, RH\n",
      "\n",
      "Culture\n",
      "\n",
      "Autres\n",
      "\n",
      "Générer de la \n",
      "connaissance\n",
      "\n",
      "Mieux cerner \n",
      "les aptitudes \n",
      "d’apprentissage \n",
      "des élèves\n",
      "\n",
      "Mettre en \n",
      "évidence \n",
      "les manières \n",
      "différenciées \n",
      "de rendre la \n",
      "justice selon \n",
      "les régions\n",
      "\n",
      "Répartir les \n",
      "candidats au sein \n",
      "des formations \n",
      "d’enseignement \n",
      "supérieur (APB) \n",
      "\n",
      "Faire du \n",
      "matching\n",
      "\n",
      "Tirer profit \n",
      "de la quantité \n",
      "immense de \n",
      "publications \n",
      "scientifiques\n",
      "\n",
      "Répartir des \n",
      "patients pour \n",
      "participation \n",
      "à un essai \n",
      "clinique\n",
      "\n",
      "Repérer \n",
      "des liens \n",
      "insoupçonnés \n",
      "pour la résolution \n",
      "d’enquêtes \n",
      "par les services \n",
      "de gendarmerie\n",
      "\n",
      "Comprendre \n",
      "les phénomènes \n",
      "sociaux en \n",
      "entreprise\n",
      "\n",
      "Créer \n",
      "des œuvres \n",
      "culturelles \n",
      "(peinture, \n",
      "musique)\n",
      "\n",
      "Affiner le profil \n",
      "de risque \n",
      "d’un client \n",
      "d’un assureur\n",
      "\n",
      "Faire corres-\n",
      "pondre une liste \n",
      "de candidatures \n",
      "avec une offre \n",
      "d’emploi\n",
      "\n",
      "Mettre \n",
      "en relation \n",
      "des profils \n",
      "« compatibles » \n",
      "sur des \n",
      "applications de \n",
      "rencontres, etc.\n",
      "\n",
      "Prédire des \n",
      "décrochages \n",
      "scolaires\n",
      "\n",
      "Prédire\n",
      "\n",
      "Prédire \n",
      "la chance \n",
      "de succès \n",
      "d’un procès \n",
      "et le montant \n",
      "potentiel \n",
      "de dommages- \n",
      "intérêts\n",
      "\n",
      "Prédire \n",
      "des épidémies\n",
      "\n",
      "Repérer des \n",
      "prédispositions \n",
      "à certaines \n",
      "pathologies afin \n",
      "d’en éviter le \n",
      "développement\n",
      "\n",
      "Détecter \n",
      "les profils  \n",
      "à risque dans \n",
      "la lutte anti- \n",
      "terroriste\n",
      "\n",
      "Prédire \n",
      "l’occurrence \n",
      "future de\n",
      "crimes et délits\n",
      "\n",
      "Détecter les \n",
      "collaborateurs \n",
      "qui risquent de \n",
      "démissionner \n",
      "dans les  \n",
      "prochains mois\n",
      "\n",
      "Créer des \n",
      "œuvres ayant \n",
      "un maximum de \n",
      "chance de plaire \n",
      "aux spectateurs \n",
      "(Netflix)\n",
      "\n",
      "Recommander\n",
      "\n",
      "Recommander \n",
      "des voies \n",
      "d’orientation \n",
      "personnalisées \n",
      "aux élèves \n",
      "\n",
      "Recommander \n",
      "des solutions \n",
      "de médiation en \n",
      "fonction du profil \n",
      "des personnes \n",
      "et des cas \n",
      "similaires passés\n",
      "\n",
      "Proposer des \n",
      "orientations de \n",
      "carrière adaptées \n",
      "aux profils des \n",
      "personnes\n",
      "\n",
      "Recommander \n",
      "des livres \n",
      "(Amazon), des \n",
      "séries télévisées \n",
      "(Netflix), etc.\n",
      "\n",
      "Individualiser \n",
      "des messages \n",
      "politiques sur les \n",
      "réseaux sociaux\n",
      "\n",
      "Aider \n",
      "la décision\n",
      "\n",
      "Suggérer au \n",
      "juge la solution \n",
      "jurisprudentielle \n",
      "la plus adéquate \n",
      "pour un cas \n",
      "donné\n",
      "\n",
      "Suggérer au \n",
      "médecin des \n",
      "solutions \n",
      "thérapeutiques \n",
      "adaptées\n",
      "\n",
      "Suggérer aux \n",
      "forces de \n",
      "police les zones \n",
      "prioritaires \n",
      "dans lesquelles \n",
      "patrouiller\n",
      "\n",
      "Aider le conduc-\n",
      "teur à trouver \n",
      "le chemin le plus \n",
      "court d’un point \n",
      "à un autre (GPS)\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "23\n",
      "\n",
      "Les enjeux éthiques\n",
      "\n",
      "L’éthique, éclaireuse du droit\n",
      "\n",
      "P.24\n",
      "\n",
      "L’autonomie humaine au défi de l’autonomie des machines\n",
      "\n",
      "P.26\n",
      "\n",
      "Biais, discriminations et exclusion \n",
      "\n",
      "P.31\n",
      "\n",
      "Fragmentation algorithmique : la personnalisation \n",
      "\n",
      "contre les logiques collectives\n",
      "\n",
      "P.34\n",
      "\n",
      "Entre limitation des mégafichiers et développement \n",
      "de l’intelligence artificielle : un équilibre à réinventer\n",
      "\n",
      "P.38\n",
      "\n",
      "Qualité, quantité, pertinence : l’enjeu des données fournies à l’IA\n",
      "\n",
      "P.39\n",
      "\n",
      "L’identité humaine au défi de l’intelligence artificielle\n",
      "\n",
      "P.41\n",
      "\n",
      "\n",
      "24\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "Les enjeux éthiques\n",
      "\n",
      "L’éthique, éclaireuse du droit\n",
      "\n",
      "La notion d’éthique fait souvent l’objet d’usages différents, \n",
      "laissant parfois place à une forme d’ambigüité. Les défini-\n",
      "tions proposées par les dictionnaires renvoient l’éthique à \n",
      "la morale, autrement dit à des normes qui n’ont pas néces-\n",
      "sairement vocation à entrer dans le droit et qui portent sur \n",
      "la conduite des individus. Chez les philosophes antiques, \n",
      "l’éthique n’est ainsi rien d’autre que la réponse à la question \n",
      "suivante : « qu’est-ce qu’une vie bonne ? », c’est-à-dire des \n",
      "principes d’action qui concernent d’abord l’individu. \n",
      "\n",
      "Plus récemment, la notion d’éthique s’est notamment déve-\n",
      "loppée comme renvoyant à une forme d’à côté du droit, \n",
      "évoqué entre autres par des acteurs privés comme les \n",
      "entreprises. L’éthique est alors un ensemble de normes \n",
      "édictées par l’entreprise et qu’elle s’impose à elle-même. \n",
      "Ces normes peuvent aller au-delà du droit. Souvent, elles \n",
      "peuvent n’avoir pour principale fonction que de redire – \n",
      "consciemment ou pas – des normes juridiques. Certaines \n",
      "évocations de l’utilisation « éthique » des données du client \n",
      "ne sont parfois rien d’autre qu’une façon de dire que l’en-\n",
      "treprise se plie à la loi.\n",
      "\n",
      "Un troisième usage de la notion d’éthique – sans doute \n",
      "le plus pertinent dans le contexte du présent rapport – \n",
      "s’est développé dans le langage des institutions publiques \n",
      "depuis la création en 1983 du Comité Consultatif National \n",
      "d’Ethique pour les sciences de la vie et de la santé (CCNE). \n",
      "Dans ce cadre, l’éthique apparaît comme une éclaireuse \n",
      "du droit, la norme éthique une préfiguration de la norme \n",
      "juridique. Que le législateur demande à une institution de \n",
      "produire une réflexion éthique place bien à l’horizon – plus \n",
      "ou moins proche – d’une telle réflexion l’inscription légis-\n",
      "lative de celle-ci. La création par la loi du CCNE partageait \n",
      "un point commun important avec celle de la Loi pour une \n",
      "République numérique et sa création d’une mission de \n",
      "réflexion éthique confiée à la CNIL : un contexte marqué \n",
      "par de rapides avancées technologiques et par de fortes \n",
      "incertitudes sur l’attitude que la collectivité avait à adopter \n",
      "face à celles-ci. D’une part, les progrès de la biotechnologie \n",
      "(le premier bébé-éprouvette français naît en 1982), de l’autre \n",
      "\n",
      "ENQUÊTE\n",
      "\n",
      "Une perception publique \n",
      "des algorithmes et de l’IA \n",
      "empreinte de méfiance*\n",
      "Les trois craintes les plus partagées sont la \n",
      "perte de contrôle humain (63 % des adhérents), \n",
      "la  normativité  et  l’enfermement  à  travers \n",
      "l’uniformisation des recrutements (56 %) et la \n",
      "collecte disproportionnée de données person-\n",
      "nelles (50 %).\n",
      "\n",
      "Dans le champ de l’emploi, quelques opportuni-\n",
      "tés sont mises en exergue comme la possibilité \n",
      "d’examiner toutes les candidatures sur la base \n",
      "de critères identiques (52 %). Toutefois, 72 % des \n",
      "répondants envisagent comme une menace la \n",
      "possibilité d’être recruté par des algorithmes, \n",
      "sur la base d’une analyse de leur profil et de sa \n",
      "compatibilité à un poste défini. 71 % d’entre eux \n",
      "affirment ainsi que la définition d’une charte \n",
      "éthique  autour  de  l’usage  des  algorithmes \n",
      "constitue une réelle priorité.\n",
      "\n",
      "72 %\n",
      "\n",
      "des répondants \n",
      "envisagent \n",
      "comme une \n",
      "menace la \n",
      "possibilité \n",
      "d’être recruté \n",
      "par des \n",
      "algorithmes\n",
      "\n",
      "*  Enquête  réalisée  dans \n",
      "le cadre du débat public \n",
      "par la CFE-CGC, syndicat \n",
      "de l’encadrement, auprès \n",
      "de  1263  de  ses  adhé-\n",
      "rents \n",
      "(essentiellement \n",
      "issus  des  fédérations  « \n",
      "Métallurgie » et « Finance \n",
      "et Banque »).\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "25\n",
      "\n",
      "ce qui est ressenti comme une « révolution numérique ». \n",
      "L’inscription dans la loi d’une réflexion éthique répond donc \n",
      "au besoin d’un espace nécessaire pour une réflexion col-\n",
      "lective sur un pacte social dont certains aspects essentiels \n",
      "(libertés fondamentales, égalité entre les citoyens, dignité \n",
      "humaine) peuvent être remis en question dès lors que \n",
      "l’évolution technologique déplace la limite entre le possible \n",
      "et l’impossible et nécessite de redéfinir la limite entre le \n",
      "souhaitable et le non souhaitable.\n",
      "\n",
      "La CNIL a choisi pour cette première réflexion de s’appuyer \n",
      "sur les acteurs désireux de s’exprimer sur les sujets liés \n",
      "aux algorithmes et à l’intelligence artificielle. Les enjeux \n",
      "éthiques retenus sont donc ceux qui ont été évoqués par \n",
      "ces mêmes acteurs. De manière logique, ces enjeux sont \n",
      "pour la plupart déjà bel et bien présents dans nos sociétés, \n",
      "même s’ils sont probablement appelés à gagner en inten-\n",
      "sité dans les années à venir. En revanche, des enjeux plus \n",
      "prospectifs, liés à des progrès pour l’heure hypothétiques \n",
      "\n",
      "des technologies numériques (transhumanisme, hybrida-\n",
      "tion homme-machine, etc.), ont peu mobilisé la réflexion \n",
      "des partenaires impliqués et sont de ce fait peu développés \n",
      "dans le rapport.\n",
      "\n",
      "L’évolution technologique \n",
      "\n",
      "déplace la limite entre \n",
      "\n",
      "le possible et l’impossible \n",
      "et nécessite de redéfinir \n",
      "\n",
      "la limite entre le souhaitable \n",
      "\n",
      "et le non souhaitable\n",
      "\n",
      "LE REGARD DU CITOYEN\n",
      "\n",
      "Les participants à la concertation citoyenne organisée par la CNIL à Montpellier le 14 octobre 2017 se \n",
      "sont prononcés sur les questions éthiques posées par les algorithmes et l’intelligence artificielle (voir \n",
      "«  Une  démarche  innovante  au  service  de  l’élaboration  d’une  réflexion  éthique  collective  et  pluraliste  »)  : \n",
      "les enjeux qu’ils soulèvent résonnent en grande partie avec ceux identifiés tout au long du débat public.\n",
      "\n",
      "Les citoyens semblent prioritairement préoccupés par les nouvelles modalités de prise de décision et \n",
      "la dilution de la responsabilité créées par l’algorithme. La « perte de compétence » éventuelle de méde-\n",
      "cins ou d’employeurs qui se reposeraient intensément sur l’algorithme a été mise en exergue. Parmi les \n",
      "conséquences préjudiciables évoquées : une « gestion des incertitudes » jugée inefficace chez la machine \n",
      "comparativement à ce dont est capable l’homme ; une incapacité à « gérer les exceptions » ou encore la \n",
      "« perte du sentiment d’humanité » (évoquées notamment à propos de l’absence de recours sur « APB »).\n",
      "\n",
      "Le recours à des systèmes informatiques, parfois autonomes, pour prendre des décisions fait craindre que \n",
      "la responsabilité en cas d’erreurs ne soit « pas claire », une préoccupation soulevée notamment à propos \n",
      "du secteur médical. Concernant le cas « APB », certains citoyens critiquent le manque de transparence qui \n",
      "explique que l’algorithme serve « de bouc émissaire faisant tampon entre ceux qui font des choix politiques \n",
      "et ceux qui se plaignent de ces choix ». La problématique de la personnalisation informationnelle sur les \n",
      "réseaux sociaux et de ses effets collectifs, évoquée au sujet des élections présidentielles aux Etats-Unis, \n",
      "accentue également leur crainte que « plus personne ne soit réellement responsable du contrôle d’Internet ».\n",
      "\n",
      "Moins évoqué, le danger de l’enfermement algorithmique est cependant mentionné par plusieurs participants \n",
      "des ateliers « ressources humaines » et « plateformes numériques ». Les citoyens ont aussi évoqué le risque \n",
      "de « formatage » des recrutements, et la rationalisation consécutive d’un champ qui ne devrait pas autant \n",
      "l’être, ou encore celui d’être figé sur Internet « dans un profil qui freinerait nos évolutions personnelles ».\n",
      "\n",
      "Enfin, la thématique des biais, des discriminations et de l’exclusion mérite une vigilance toute particulière \n",
      "aux yeux des participants, et cela que les biais en question soit volontaires (en matière de recrutement, on \n",
      "craint l’éventualité qu’un algorithme soit codé « selon les objectifs des employeurs aux dépens des salariés ») \n",
      "ou involontaires (l’outil algorithmique est facteur d’inquiétudes quant aux erreurs qu’il pourrait générer).\n",
      "\n",
      "\n",
      "26\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "L’autonomie humaine au défi \n",
      "de l’autonomie des machines\n",
      " \n",
      "\n",
      "Au-delà de la multiplicité des applications pratiques et des \n",
      "utilisations qui peuvent en être faites, algorithmes et intel-\n",
      "ligence artificielle ont pour objet commun d’accomplir \n",
      "automatiquement une tâche ou une opération impliquant \n",
      "une forme d’« intelligence » qui serait autrement effectuée \n",
      "directement par un agent humain. Autrement dit, il s’agit \n",
      "pour l’homme de déléguer des tâches à des systèmes \n",
      "automatiques9. \n",
      "\n",
      "Le cas d’APB en offre un bon exemple. Ce logiciel détermine \n",
      "l’affectation des bacheliers dans l’enseignement supérieur. Il \n",
      "peut être considéré comme ne faisant rien d’autre que d’ap-\n",
      "pliquer un ensemble d’instructions et de critères qui pour-\n",
      "raient tout aussi bien l’être par des fonctionnaires. L’intérêt \n",
      "essentiel du recours à l’algorithme est dans ce cas le gain \n",
      "de productivité induit par la délégation d’une tâche très coû-\n",
      "teuse en temps et en moyens à un système automatique. Un \n",
      "autre intérêt de l’algorithme est de garantir le déploiement \n",
      "uniforme et impartial des règles définies en amont pour la \n",
      "répartition des futurs étudiants. En effet, l’application de ces \n",
      "mêmes règles par une chaîne administrative complexe peut \n",
      "donner prise, bien plus facilement, à des formes d’arbitraires \n",
      "ou même tout simplement à des interprétations différentes \n",
      "selon les agents qui les appliquent. Spécialiste des politiques \n",
      "éducatives, Roger-François Gauthier n’hésite ainsi pas à affir-\n",
      "mer qu’APB a au moins eu le mérite de mettre fin à un sys-\n",
      "tème « mafieux » où le passe-droit avait sa place10.\n",
      "\n",
      "Si APB est un algorithme déterministe classique, l’utilisation \n",
      "de la reconnaissance de formes pour identifier en temps \n",
      "réel des embarcations sur les photographies satellitaires \n",
      "de très vastes surfaces maritimes fournit quant à elle une \n",
      "illustration de la façon dont l’intelligence artificielle permet \n",
      "aussi d’accomplir des tâches qui pourraient autrement s’avé-\n",
      "rer trop coûteuses en ressources humaines. Un simple logi-\n",
      "ciel peut ainsi assurer la surveillance 24 heures sur 24 de \n",
      "zones immenses qui nécessiterait autrement l’activité de \n",
      "nombreuses personnes.\n",
      "\n",
      "De façon plus prospective, il serait au moins techniquement \n",
      "envisageable de confier – comme cela se fait déjà aux Etats-\n",
      "Unis – à des algorithmes le soin d’évaluer la dangerosité d’un \n",
      "détenu et donc l’opportunité d’une remise de peine. L’étape \n",
      "supplémentaire de ce que certains appellent la « justice pré-\n",
      "dictive » serait de confier à des systèmes le soin d’établir \n",
      "des décisions sur la base de l’analyse des données du cas \n",
      "à juger croisées aux données de jurisprudence.\n",
      "\n",
      "La délégation de tâches aux algorithmes : \n",
      "des situations contrastées\n",
      "\n",
      "Il  semble  d’emblée  assez  évident  que  les  implications \n",
      "éthiques et sociales potentielles du phénomène accru de \n",
      "délégation de tâches à des systèmes automatisés pré-\n",
      "sentent des degrés assez variés de sensibilité selon les \n",
      "tâches qu’il s’agit de déléguer et selon les modalités mêmes \n",
      "de cette délégation. \n",
      "\n",
      "Il est ainsi possible de faire un pas supplémentaire pour dis-\n",
      "tinguer les cas sur lesquels la réflexion doit se concentrer, \n",
      "au moyen d’une typologie du phénomène de délégation \n",
      "d’opérations à des systèmes automatisés, en fonction de \n",
      "deux critères : l’impact sur l’homme de l’opération qu’il s’agit \n",
      "de déléguer et le type de système à qui il est question de \n",
      "déléguer celle-ci.\n",
      "\n",
      "Le premier critère concerne le type d’impact et/ou l’ampleur \n",
      "de l’opération déléguée au système automatisé. Il peut s’agir \n",
      "d’une tâche routinière, mécanique et relativement anodine \n",
      "(par exemple, le classement par ordre alphabétique d’une \n",
      "série de fichiers informatiques). À l’opposé, cette tâche peut \n",
      "perdre son caractère anodin et s’avérer d’une grande com-\n",
      "plexité. Elle peut, surtout, prendre les aspects d’une décision \n",
      "et revêtir une importance vitale pour une personne ou pour \n",
      "un groupe, comme lorsqu’il s’agit d’établir une aide au dia-\n",
      "gnostic médical. Entre ces deux extrêmes se déploie un large \n",
      "spectre de situations contrastées. On y retrouverait les deux \n",
      "exemples évoqués ci-dessus ou encore celui de la voiture \n",
      "autonome, ce dernier ainsi que le cas d’APB étant relative-\n",
      "ment plus proches du cas du diagnostic médical automatisé \n",
      "que de l’autre bout du spectre.\n",
      "\n",
      "Le second critère concernerait quant à lui le type de système \n",
      "automatisé – algorithme classique ou algorithme de machine \n",
      "learning – à qui l’on délègue l’opération. Une autre façon de \n",
      "présenter ce critère est d’évoquer le degré d’autonomie du \n",
      "système en question, en particulier sa capacité ou non à \n",
      "élaborer ses propres critères de fonctionnement. De même, \n",
      "ce critère renvoie à la capacité ou non du système de pro-\n",
      "duire une explication satisfaisante des résultats qu’il fournit.\n",
      "\n",
      "Cette typologie souligne la grande diversité des situations \n",
      "impliquées par une réflexion sur les enjeux éthiques et \n",
      "sociaux des algorithmes et de l’intelligence artificielle. Elle \n",
      "met surtout en évidence l’étendue du spectre sur lequel peut \n",
      "\n",
      "    9  En toute rigueur, rappelons-le, ce n’est d’ailleurs généralement pas tant le recours à l’algorithme qui constitue le fait nouveau que son exécution sous la forme d’un programme \n",
      "\n",
      "informatique.\n",
      "\n",
      " 10  Événement de lancement du débat public, CNIL, 23 janvier 2017.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "27\n",
      "\n",
      "se situer le degré de gravité ou de sensibilité des enjeux \n",
      "liés à l’utilisation de tel ou tel algorithme.\n",
      "\n",
      "tion humaine sans aboutir à une déresponsabilisation de \n",
      "l’homme, à une perte d’autonomie ?\n",
      "\n",
      "La délégation de décisions critiques aux \n",
      "algorithmes: une déresponsabilisation ?\n",
      "\n",
      "Les décisions les plus cruciales (diagnostics médicaux, déci-\n",
      "sions judiciaires, décision d’ouvrir le feu dans un contexte \n",
      "de conflit armé etc.) qui pourraient être, voire commencent \n",
      "à être (à l’étranger notamment) déléguées à des systèmes \n",
      "automatisés sont – au moins dans certains cas – déjà clai-\n",
      "rement thématisées par la tradition juridique, en France. Seul \n",
      "un médecin est ainsi habilité à établir un diagnostic qui, autre-\n",
      "ment, relèverait de l’exercice illégal de la médecine. Il en va de \n",
      "même de la décision du juge, qui ne saurait en toute rigueur \n",
      "être déléguée à un système automatisé. Dans cette perspec-\n",
      "tive, ce type de système est présenté dans ces domaines \n",
      "comme une « aide » à la prise de décision. \n",
      "\n",
      "Cette clarté juridique ne résout cependant pas les pro-\n",
      "blèmes que soulève l’éventualité d’une délégation de ce \n",
      "type de décisions. Comment s’assurer que la prédiction et \n",
      "la recommandation fournies par les algorithmes ne soient \n",
      "effectivement qu’une aide à la prise de décision et à l’ac-\n",
      "\n",
      "Dans le domaine médical où la qualité de la prise de décision \n",
      "peut être plus facilement évaluée (ou, du moins, quantifiée), \n",
      "on peut logiquement se demander quelle marge d’autono-\n",
      "mie resterait au médecin face à la recommandation (en \n",
      "termes de diagnostic et de solution thérapeutique à pri-\n",
      "vilégier) qui serait fournie par un système d’« aide » à la \n",
      "décision extrêmement performant. On annonce en effet \n",
      "que l’intelligence artificielle serait supérieure à l’homme \n",
      "pour le diagnostic de certains cancers ou pour l’analyse \n",
      "de radiographies. Dans le cas où ces annonces s’avére-\n",
      "raient exactes, il pourrait donc devenir hasardeux pour un \n",
      "médecin d’établir un diagnostic ou de faire un choix thé-\n",
      "rapeutique autre que celui recommandé par la machine, \n",
      "laquelle deviendrait dès lors le décideur effectif. Dans ce \n",
      "cas, se pose alors la question de la responsabilité. Celle-ci \n",
      "doit-elle être reportée sur la machine elle-même, qu’il s’agi-\n",
      "rait alors de doter d’une personnalité juridique ? Sur ses \n",
      "concepteurs ? Doit-elle être encore assumée par le méde-\n",
      "cin ? Mais alors, si cela peut certes sembler résoudre le \n",
      "problème juridique, cela n’aboutit-il quand même pas à \n",
      "une déresponsabilisation de fait, au développement d’un \n",
      "sentiment d’irresponsabilité ? \n",
      "\n",
      "FOCUS\n",
      "\n",
      "Les défis éthiques d’une police prédictive \n",
      "La quête d’une prédiction du crime dans le temps et dans l’espace serait capable de prédire le crime dans \n",
      "le temps et dans l’espace, afin d’orienter l’action des patrouilles, fait l’objet d’un développement actif de \n",
      "logiciels algorithmiques. Aux Etats-Unis, « PredPol » s’appuie sur des modèles empruntés à la sismolo-\n",
      "gie pour évaluer l’intensité du risque à tel endroit et à tel moment. La start-up prétend ainsi intégrer la \n",
      "dimension « contagieuse » de la diffusion spatiotemporelle des délits.\n",
      "Ce potentiel prédictif s’est pourtant révélé limité, d’une part, car la contagion a un impact négligeable pour \n",
      "la détection de crimes comparativement aux répliques d’un séisme et, d’autre part, car la structure de la \n",
      "criminalité varie d’une année à l’autre. Pourtant, cela ne dissipe pas l’attrait de tels dispositifs consistant \n",
      "à permettre de « gérer, selon des critères gestionnaires, l’offre publique de vigilance quotidienne ». Très \n",
      "concrètement, « le carré prédictif reste rouge sur la carte tant que la police n’y a pas patrouillé, il tourne \n",
      "ensuite au bleu lors des premiers passages, puis il apparaît en vert lorsque le policier a passé le temps \n",
      "suffisant et optimal calculé selon les ressources disponibles »11.\n",
      "Une crainte majeure émerge : quid du risque que les préconisations de la machine soient appréhendées \n",
      "comme une vérité absolue, non soumise à la discussion quant à ses conséquences pratiques ? Dans la \n",
      "mesure où l’algorithme se repose sur les données issues des plaintes des victimes, une conséquence \n",
      "pratique constatée est celle d’une présence policière renforcée dans les zones où les publics portent \n",
      "plainte avec plus de fluidité, et ainsi un phénomène d’exclusion de l’offre de sécurité publique pour \n",
      "certaines populations (celles qui signalent moins). On peut imaginer, au contraire, que l’utilisation de \n",
      "ce type d’algorithme focalise l’attention policière sur certains types d’infractions au détriment d’autres.\n",
      "Dans tous les cas, une appréhension critique de ce type d’outil est une nécessité majeure. Quid également \n",
      "de la capacité à juger de l’efficacité de ces modèles ? Qu’un délit soit détecté par une patrouille orientée \n",
      "par le système, ou que ce ne soit pas le cas, le résultat pourrait facilement (mais faussement) être inter-\n",
      "prété comme un signe de l’efficacité de l’outil.\n",
      "\n",
      "11 Bilel Benbouzid, « A qui profite le crime ? Le marché de la prédiction du crime aux Etats-Unis », www.laviedesidees.fr \n",
      "\n",
      "\n",
      "28\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "Le cas de la médecine est particulièrement critique non \n",
      "seulement en raison de l’impact des décisions et recom-\n",
      "mandations sur les personnes mais aussi en raison du \n",
      "fait que la discussion implique ici des systèmes fondés \n",
      "sur la technologie du machine learning. Ceci implique que \n",
      "les logiques sous-jacentes des systèmes d’intelligence \n",
      "artificielle sont potentiellement incompréhensibles pour \n",
      "celui à qui ils sont proposés, autant d’ailleurs que pour les \n",
      "concepteurs du système. Le débat public organisé par la \n",
      "CNIL a d’ailleurs été l’occasion de constater une contro-\n",
      "verse sur ce point, à propos notamment du logiciel Watson \n",
      "d’IBM. Le discours d’IBM souligne que Watson fonctionne \n",
      "sur le mode de l’ « apprentissage supervisé ». Autrement dit, \n",
      "le système est accompagné pas à pas dans son appren-\n",
      "tissage, ce qui permettrait d’en contrôler la logique, par \n",
      "opposition à un apprentissage non supervisé qui reviendrait \n",
      "effectivement à laisser une pleine et entière autonomie à la \n",
      "machine pour déterminer ses critères de fonctionnement. \n",
      "IBM indique également contrôler le fonctionnement des \n",
      "systèmes avant de décider de conserver l’apprentissage \n",
      "réalisé. Au contraire, les chercheurs experts de ce domaine \n",
      "qui ont eu l’occasion de s’exprimer lors des différents débats \n",
      "organisés (et notamment la CERNA) ont régulièrement rap-\n",
      "pelé qu’en l’état actuel de la recherche les résultats fournis \n",
      "par les algorithmes de machine learning les plus récents \n",
      "n’étaient pas explicables. Cette explicabilité constitue d’ail-\n",
      "leurs l’objet de recherches en cours. Ils insistent également \n",
      "sur le fait qu’il est très difficile de contrôler effectivement \n",
      "un système de machine learning.\n",
      "\n",
      "On peut ainsi se demander si les algorithmes et l’intelli-\n",
      "gence artificielle ne conduisent pas à une forme de dilu-\n",
      "tion de figures d’autorité traditionnelles, de décideurs, de \n",
      "responsables, voire de l’autorité même de la règle de droit. \n",
      "Cette  évolution  est  parfois  explicitement  souhaitée. \n",
      "Certains, comme Tim O’Reilly, imaginent d’ores et déjà l’avè-\n",
      "nement d’une « réglementation algorithmique12» qui verrait \n",
      "la « gouvernance » de la cité confiée aux algorithmes : grâce \n",
      "aux capteurs connectés, lieux, infrastructures et citoyens \n",
      "communiqueraient en permanence des données traitées \n",
      "en vue de rationaliser et d’optimiser la vie collective selon \n",
      "des lois considérées comme « naturelles », émanant des \n",
      "choses mêmes, une « normativité immanente », comme \n",
      "l’expliquent Thomas Berns et Antoinette Rouvroy13. Sans \n",
      "doute faut-il remarquer ici que la tentation – révélée par ces \n",
      "discours – de se passer d’une normativité humaine et de \n",
      "préférer une normativité algorithmique est favorisée par les \n",
      "discours marchands. Ces derniers vantent l’ « objectivité » \n",
      "supposée des systèmes automatiques (par opposition à un \n",
      "jugement humain toujours faillible). Ils influent donc sur la \n",
      "tendance des utilisateurs à prendre le résultat produit par \n",
      "une machine pour une vérité incontestable, alors même qu’il \n",
      "\n",
      "est de part en part déterminé par des choix (de critères, de \n",
      "types de données fournies au système) humains14. \n",
      "\n",
      "L’impact des algorithmes sur la conception et l’application \n",
      "de la norme pourrait aussi prendre une autre forme. Le \n",
      "Conseil National des Barreaux, dans le rapport qu’il a remis \n",
      "à la CNIL, souligne ainsi qu’« il faut éviter que l’obsession \n",
      "de l’efficacité et de la prévisibilité qui motive le recours à \n",
      "l’algorithme nous conduise à concevoir les catégories et \n",
      "les règles juridiques non plus en considération de notre \n",
      "idéal de justice mais de manière à ce qu’elles soient plus \n",
      "facilement « codables » ». \n",
      "\n",
      "Il n’est pas exclu que cette évolution progressive vers des \n",
      "formes de « réglementation algorithmique » puisse pré-\n",
      "senter une sorte d’attrait pour les décideurs eux-mêmes. \n",
      "Déléguer des décisions à une machine – supposée neutre, \n",
      "impartiale, infaillible – peut être une façon d’éluder sa propre \n",
      "responsabilité, de s’exempter de la nécessité de rendre \n",
      "compte de ses choix. Le développement d’armes létales \n",
      "autonomes (robots tueurs) qui pourraient prendre elles-\n",
      "mêmes la décision de tuer sur le champ de bataille ou à \n",
      "des fins de maintien de l’ordre soulève la question avec une \n",
      "particulière acuité. L’acte de tuer, même considéré comme \n",
      "légitime, dans une situation de conflit international et face \n",
      "à un ennemi armé, ne doit-il pas rester sous le contrôle et \n",
      "la responsabilité directe de l’homme ? Sa difficulté et son \n",
      "caractère éventuellement traumatique pour celui-là même \n",
      "qui l’accomplit ne doivent-ils pas être considérés comme \n",
      "une garantie nécessaire pour éviter toute dérive ?\n",
      "\n",
      "Ces considérations ne concernent pas que les situations \n",
      "où des tâches ou des décisions sont déléguées à un algo-\n",
      "rithme apprenant. L’algorithme classique, déterministe, est \n",
      "également concerné. Les débats autour de l’algorithme \n",
      "d’APB en ont offert un bon exemple, sinon une manière \n",
      "de comprendre comment peut se mettre en place un tel \n",
      "processus de dépolitisation et de neutralisation de choix \n",
      "de société méritant pourtant de faire l’objet d’une discus-\n",
      "sion publique. La polémique s’est en effet concentrée sur \n",
      "l’algorithme lui-même, notamment à la suite de la révélation \n",
      "de la mise en œuvre du tirage au sort qu’il induisait pour \n",
      "certains candidats à des filières en tension. Or, l’algorithme \n",
      "n’est jamais que le reflet de choix politiques, de choix de \n",
      "société. En l’occurrence, le recours au tirage au sort pour \n",
      "l’attribution de places dans des filières en tension est le \n",
      "résultat d’un choix politique dont deux alternatives pos-\n",
      "sibles seraient – schématiquement – la sélection à l’entrée \n",
      "à l’université ou l’investissement pour faire correspondre le \n",
      "nombre de places disponibles dans les filières en question \n",
      "avec la demande. En d’autres termes, « code is law », pour \n",
      "reprendre la fameuse formule de Lawrence Lessig.\n",
      "\n",
      " 12  Tim O’Reilly, « Open data and algorithmic regulation », in Brett Goldstein (dir.), Beyond Transparency: Open Data and the Future of Civic Innovation, San Francisco, Code for \n",
      "\n",
      "America, 2013, pp. 289-301.\n",
      "\n",
      " 13  Rouvroy Antoinette, Berns Thomas, « Gouvernementalité algorithmique et perspectives d’émancipation. Le disparate comme condition d’individuation par la relation ? », \n",
      "\n",
      "Réseaux, 2013/1 (n° 177), p. 163-196.\n",
      "\n",
      " 14  La prétendue objectivité machinique n’est à ce titre qu’une subjectivité diluée et non assumée. \n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "29\n",
      "\n",
      "On ne saurait en effet considérer qu’un algorithme (entendu \n",
      "au sens large comme le système socio-technique dont il fait \n",
      "partie) puisse être « neutre », dans la mesure où il incorpore \n",
      "inévitablement des partis pris – que ceux-ci soient sociaux, \n",
      "politiques, éthiques ou moraux – et répond le plus souvent \n",
      "à des finalités qui incluent une dimension commerciale \n",
      "pour son auteur. L’exemple fréquemment évoqué du choix \n",
      "que pourrait être amené à faire l’algorithme d’une voiture \n",
      "sans chauffeur de sacrifier ou bien son occupant ou bien \n",
      "un piéton sur la route illustre la façon dont le recours à la \n",
      "technique, plus que de soulever certains problèmes moraux, \n",
      "a surtout pour effet de les déplacer : à un dilemme réglé \n",
      "en temps réel par une personne impliquée dans sa chair \n",
      "fait place un choix effectué par d’autres, ailleurs, bien en \n",
      "amont15. \n",
      "\n",
      "Au-delà de la finalité délibérément visée à travers la mise en \n",
      "place d’APB (efficacité administrative renforcée et harmo-\n",
      "nisation plus équitable de l’attribution de places dans l’en-\n",
      "seignement supérieur), force est de constater que celle-ci \n",
      "a pour effet induit l’escamotage de choix de société impli-\n",
      "qués par le paramétrage du système mais masqués par \n",
      "l’impartialité supposée de l’algorithme. Les responsables \n",
      "de la mise en œuvre de l’algorithme auquel est déléguée \n",
      "une prise de décision devraient donc chercher des moyens \n",
      "de contrer ce type d’effets (par exemple, par un effort d’in-\n",
      "formation du public concerné). Ils devraient en tout cas \n",
      "s’interdire de l’exploiter en se cachant derrière la machine \n",
      "ou même de s’en accommoder dans la mesure où il a ten-\n",
      "dance à neutraliser des conflits ou des débats légitimes.\n",
      "\n",
      "Les algorithmes \n",
      "\n",
      "et l’intelligence artificielle \n",
      "conduisent à une forme \n",
      "\n",
      "de dilution de figures d’autorité \n",
      "\n",
      "traditionnelles, \n",
      "\n",
      "de décideurs, de responsables, \n",
      "\n",
      "voire de l’autorité même \n",
      "\n",
      "de la règle de droit\n",
      "\n",
      "Il est d’ailleurs probable que céder à cette facilité ait pour \n",
      "contrepartie un sentiment d’inhumanité chez les personnes \n",
      "concernées. Ce sentiment est susceptible de se transfor-\n",
      "mer en rejet, en particulier si n’est prévue aucune possibilité \n",
      "de contacter l’organisme responsable et d’échanger pour \n",
      "«  trouver  des  solutions  ou  tout  simplement  pour  être \n",
      "écouté », ainsi que l’a souligné le médiateur de l’Éducation \n",
      "nationale16.\n",
      "\n",
      "Dans le cas d’un algorithme déterministe tel qu’évoqué ici, \n",
      "la dilution de la responsabilité n’est pourtant qu’apparente. \n",
      "Les choix et les décisions cruciales se trouvent tout simple-\n",
      "ment déplacés au stade du paramétrage de l’algorithme. \n",
      "\n",
      "Est-ce à dire que ceux qui maîtrisent le code informatique \n",
      "deviennent les véritables décideurs et que se profile le risque \n",
      "que le pouvoir se trouve concentré dans les mains d’une \n",
      "« petite caste de scribes » (Antoine Garapon, événement de \n",
      "lancement du débat, le 23 janvier 2017) ? Ce n’est certes \n",
      "pas ce qu’a donné à voir le cas d’APB. Suite à l’ouverture \n",
      "du code source des algorithmes de l’administration qu’a \n",
      "imposée la loi pour une République numérique, celui d’APB \n",
      "a été examiné par la mission Etalab. Il s’est avéré que ses \n",
      "développeurs avaient pris soin d’y documenter l’origine de \n",
      "chaque modification du paramétrage de l’algorithme, en \n",
      "l’occurrence les directives qu’ils avaient reçues de la part \n",
      "de l’administration. En somme, la traçabilité de la respon-\n",
      "sabilité a été organisée par les développeurs mêmes d’APB. \n",
      "Cet exemple ne doit cependant pas masquer le fait que la \n",
      "logique algorithmique a tendance à déporter la prise de \n",
      "décision vers les étapes techniques de conception d’un \n",
      "système (paramétrage, développement, codage), lequel ne \n",
      "fait ensuite que déployer automatiquement et sans faille \n",
      "les choix opérés initialement. La préoccupation d’Antoine \n",
      "Garapon évoquée précédemment ne saurait donc pas être \n",
      "écartée et appelle des réponses. Il est essentiel que ces \n",
      "étapes de conception ne s’autonomisent pas exagérément \n",
      "au point de devenir le lieu de la prise de décision.\n",
      "\n",
      "La question du lieu de la responsabilité et de la décision \n",
      "se pose en partie différemment dès lors qu’il s’agit de sys-\n",
      "tèmes de machine learning. Sans doute faut-il ici davantage \n",
      "penser en termes de chaîne de responsabilité, depuis le \n",
      "concepteur du système jusqu’à son utilisateur, en passant \n",
      "par celui qui va entraîner ce système apprenant. En fonction \n",
      "des données qui lui auront été fournies, ce dernier se com-\n",
      "portera différemment, en effet. On peut penser ici au cas \n",
      "du robot conversationnel Tay mis en place par Microsoft \n",
      "et suspendu au bout de 24 heures quand, alimenté par des \n",
      "données d’utilisateurs des réseaux sociaux, il avait com-\n",
      "mencé à tenir des propos racistes et sexistes. Reste qu’or-\n",
      "ganiser précisément la répartition de la responsabilité entre \n",
      "\n",
      " 15  Voir à ce sujet l’excellent site du MIT offrant une illustration pratique de ces dilemmes : http://moralmachine.mit.edu/\n",
      " 16  Le Monde, 29 juin 2016 : « Le médiateur de l’Education Nationale dénonce la solitude des familles face à APB ».\n",
      "\n",
      "\n",
      "30\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "ces différents maillons de la chaîne est un problème ardu. \n",
      "Au-delà, faut-il conditionner l’utilisation de l’intelligence \n",
      "artificielle à la capacité d’attribuer de façon absolument \n",
      "claire cette responsabilité ? On sait d’ores et déjà que des \n",
      "intelligences artificielles peuvent être plus « performantes » \n",
      "que l’homme pour réaliser certaines tâches, sans que l’on \n",
      "ait une claire compréhension du fonctionnement de ces \n",
      "systèmes et donc, aussi, des erreurs éventuelles qu’ils pour-\n",
      "raient commettre. Rand Hindi explique ainsi que « les IA \n",
      "font moins d’erreurs que les humains mais qu’elles font \n",
      "des erreurs là où des humains n’en auraient pas fait. C’est \n",
      "ce qui est arrivé avec l’accident de la voiture autonome de \n",
      "Tesla, qui ne serait jamais arrivé avec un humain ». Faut-il \n",
      "alors imaginer d’attribuer une personnalité juridique à ces \n",
      "systèmes ? Ou faire endosser la responsabilité à l’utilisa-\n",
      "teur lui-même (en l’occurrence, dans le domaine médical, \n",
      "au patient) ?\n",
      "\n",
      "Sans doute ne faut-il toutefois pas exagérer la spécificité \n",
      "du cas du machine learning. Imaginons une intelligence \n",
      "artificielle chargée de répartir les malades dans les ser-\n",
      "vices d’un hôpital et de fixer la fin de leur hospitalisation \n",
      "de la manière la plus « efficace » possible. Certainement, \n",
      "le système aurait une part d’opacité liée à son caractère \n",
      "apprenant. Mais, dans le même temps, les objectifs qui lui \n",
      "seraient assignés, ainsi que leur pondération (garantir le \n",
      "maximum de guérisons à long terme, minimiser le taux de \n",
      "réhospitalisations à brève échéance, rechercher la brièveté \n",
      "des séjours, etc.), seraient bien des choix explicitement \n",
      "faits par l’homme.\n",
      "\n",
      "Une question d’échelle : la délégation \n",
      "massive de décisions non critiques\n",
      "\n",
      "La réflexion éthique sur les algorithmes et l’intelligence \n",
      "artificielle doit-elle se cantonner à considérer les décisions \n",
      "cruciales, les secteurs où l’impact sur l’homme est incon-\n",
      "testable, comme la médecine, la justice, l’orientation sco-\n",
      "laire, voire l’automobile, avec ses implications en termes \n",
      "de sécurité ? Ne faut-il pas prendre en compte également \n",
      "les algorithmes à qui nous sommes amenés à déléguer \n",
      "progressivement de plus en plus de tâches et de déci-\n",
      "sions apparemment anodines mais qui, mises bout à bout, \n",
      "constituent l’étoffe de nos existences quotidiennes ? \n",
      "\n",
      "Simplement  par  leur  capacité  à  fonctionner  de  façon \n",
      "répétée, sur de longues durées et surtout à de très vastes \n",
      "échelles, les algorithmes peuvent avoir un impact considé-\n",
      "rable sur les personnes ou sur les sociétés. Par exemple, les \n",
      "critères de fonctionnement d’une banale application de gui-\n",
      "dage automobile, dès lors qu’ils sont utilisés par un nombre \n",
      "conséquent d’automobilistes qui s’en remettent implicite-\n",
      "\n",
      "ment à eux pour décider des itinéraires qu’ils empruntent, \n",
      "peuvent avoir des impacts importants sur le trafic urbain, \n",
      "la répartition de la pollution et à terme, peut-être, sur la \n",
      "forme même de la ville et de la vie urbaine. Le Laboratoire \n",
      "d’innovation numérique (LINC) de la CNIL l’explique ainsi : \n",
      "« Hormis la question de la captation des données person-\n",
      "nelles, se pose celle de la perte de contrôle de l’acteur public \n",
      "sur l’aménagement de l’espace public, sur la gestion des \n",
      "flux, et au-delà sur la notion même de service public et \n",
      "d’intérêt général. La somme des intérêts individuels des \n",
      "clients d’un Waze peut parfois entrer en contradiction avec \n",
      "les politiques publiques portées par une collectivité17 ». \n",
      "\n",
      "Cathy  O’Neil,  dans  son  ouvrage  Weapons  of  Math \n",
      "Destruction18, propose un exemple particulièrement évo-\n",
      "cateur. Elle imagine qu’elle pourrait modéliser les règles \n",
      "qu’elle suit implicitement pour composer les repas de ses \n",
      "enfants (diversité, présence de légumes verts mais dans \n",
      "des limites permettant de prévenir de trop fortes protesta-\n",
      "tions, relâchement des règles les dimanches et jours de fête, \n",
      "etc.). Un programme mettant en œuvre un tel algorithme \n",
      "ne poserait pas de problème tant qu’il ne serait utilisé pour \n",
      "générer automatiquement des repas que pour un nombre \n",
      "limité de personnes. Or, la caractéristique spécifique des \n",
      "algorithmes exécutés par des programmes informatiques \n",
      "est leur échelle d’application. Un tel programme, utilisé tel \n",
      "quel par des millions de personnes, aurait nécessairement \n",
      "des impacts puissants et potentiellement déstabilisateurs \n",
      "sur de grands équilibres sociaux et économiques (renché-\n",
      "rissement du prix de certaines denrées, effondrement de la \n",
      "production d’autres produits, uniformisation de la produc-\n",
      "tion, impact sur les professions de la filière agro-industrielle, \n",
      "etc.). C’est ici un aspect bien spécifique des algorithmes \n",
      "informatiques déployés aujourd’hui à l’heure d’Internet qui \n",
      "constitue le fait nouveau et que l’auteur met en évidence : \n",
      "leur échelle de déploiement. Sans doute cet aspect ne \n",
      "saurait-il être ignoré par ceux qui déploient des algorithmes \n",
      "susceptibles d’être utilisés à une large échelle.\n",
      "\n",
      "L’optimisation algorithmique comme \n",
      "écrasement du temps et de l’espace\n",
      "\n",
      "L’une des caractéristiques du fonctionnement algorithmique \n",
      "est son immédiateté et sa simplicité, du moins son unifor-\n",
      "mité et son caractère inexorable. Les algorithmes d’IA ont \n",
      "la capacité d’accomplir une tâche dans un temps presque \n",
      "immédiat (réduit au temps du seul calcul de la machine). \n",
      "Ils ont la capacité d’accomplir cette même tâche à une très \n",
      "large échelle spatiale mais de façon identique en tous lieux. \n",
      "À ce titre, ils peuvent présenter un grand attrait pour des \n",
      "administrations ou des entreprises soucieuses d’efficacité \n",
      "mais aussi de rationalité et d’homogénéité de leur action. \n",
      "\n",
      " 17  CNIL (LINC), La Plateforme d’une ville. Les données personnelles au cœur de la fabrique de la smart city, Cahier IP n°5, octobre 2017, p. 20.\n",
      " 18  Cathy O’Neil, Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown, 2016.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "31\n",
      "\n",
      "Or, cette caractéristique des algorithmes implique aussi \n",
      "une dimension potentiellement problématique : l’écrase-\n",
      "ment de la durée et de la dimension spatiale du processus \n",
      "délégué à la machine peut aussi constituer une perte, \n",
      "un appauvrissement de l’action. Les cas des algorithmes \n",
      "utilisés par l’administration ainsi que celui de la justice pré-\n",
      "dictive permettent de mieux saisir cette ambivalence, entre \n",
      "optimisation et appauvrissement de processus vidés de \n",
      "leur dimension spatiale.\n",
      "\n",
      "Ainsi, le déploiement d’un algorithme comme celui du logi-\n",
      "ciel APB peut certes être considéré comme garant pour l’ad-\n",
      "ministration d’une forme de simplicité et d’harmonisation \n",
      "de l’application des règles, là où le fonctionnement d’une \n",
      "chaîne administrative complexe et nombreuse peut don-\n",
      "ner prise à des différences d’interprétation et d’application. \n",
      "Pourtant, ce qui peut apparaître à première vue comme un \n",
      "manque d’efficacité ou comme le signe d’un fonctionne-\n",
      "ment parfois erratique ne peut-il pas être aussi considéré \n",
      "comme une source précieuse d’information pour les déci-\n",
      "deurs, via les retours d’expériences et les questionnements \n",
      "de ceux qui sont chargés d’appliquer les règles et peuvent \n",
      "en observer le déploiement et éventuellement les limites, \n",
      "au plus près du terrain ? \n",
      "\n",
      "De même, le colloque sur la justice prédictive organisé le \n",
      "19 mai 2017 par le Barreau de Lille, la Faculté de droit de \n",
      "l’Université catholique de Lille et la cour d’appel de Douai a \n",
      "vu certains participants souligner que « la connaissance des \n",
      "décisions rendues par les autres juridictions voisines ou par \n",
      "les autres magistrats contribuera à une certaine harmonie \n",
      "et évitera que l’issue d’un litige dépende de la question de \n",
      "savoir s’il est plaidé à Lille ou à Marseille ». L’idée repose \n",
      "ici sur la capacité des algorithmes à traiter les grandes \n",
      "masses de données de jurisprudence mises en open data \n",
      "\n",
      "et à mettre en évidence des disparités d’application de la loi \n",
      "dans différentes juridictions. Le dévoilement de ces dispa-\n",
      "rités dont le juge n’a pas lui-même conscience aurait pour \n",
      "conséquence une harmonisation de l’application de la loi \n",
      "sur le territoire national. Pourtant, est-on absolument cer-\n",
      "tain que, dans certaines limites, des formes de disparités \n",
      "régionales ne traduisent pas en fait un usage raisonné de \n",
      "la prudence du juge et l’adaptation intelligente et fine de \n",
      "celui-ci à des réalités sociales pouvant varier d’un lieu à \n",
      "l’autre ? Une forme de respiration de la loi, peut-être, à dis-\n",
      "tinguer de son application automatique et rigide ?\n",
      "\n",
      "On peut appliquer le même type de raisonnement à l’idée \n",
      "d’une justice prédictive qui, poussée à son extrême (une \n",
      "décision de justice rendue par une intelligence artificielle), \n",
      "éluderait l’apport de la délibération en commun et de ce \n",
      "qui peut s’y jouer à travers la confrontation d’individuali-\n",
      "tés partageant un objectif commun. La délibération de \n",
      "jurés et de magistrats n’est pas que le simple déploiement \n",
      "d’arguments préexistants à la manière dont un logiciel \n",
      "« exécute » un programme. La durée n’y est pas qu’un \n",
      "décor accessoire, une ressource dont il conviendrait de \n",
      "limiter la dépense : elle y est un acteur à part entière. \n",
      "Elle implique la capacité des jurés à évoluer au cours de \n",
      "l’échange d’arguments, à changer de positions, ainsi que \n",
      "le montre mieux que toute démonstration le film de Sidney \n",
      "Lumet, Douze hommes en colère. \n",
      "\n",
      "Il semble en tout cas souhaitable d’attirer l’attention des \n",
      "utilisateurs d’algorithmes et d’intelligence artificielle sur \n",
      "la nécessité de ne pas prendre en compte seulement les \n",
      "apports, mais aussi les inconvénients éventuels de ces \n",
      "technologies, leur caractère potentiellement ambivalent, \n",
      "et de réfléchir aux moyens de les contrer. \n",
      "\n",
      "Biais, discriminations et exclusion\n",
      "\n",
      "La propension des algorithmes et de l’intelligence artificielle \n",
      "à générer des biais pouvant conduire à leur tour à créer ou \n",
      "à renforcer des discriminations s’est imposée comme un \n",
      "sujet d’inquiétude et de questionnement. Le constat mérite \n",
      "d’autant plus d’être souligné que ces systèmes techniques \n",
      "peuvent également parfois nourrir une croyance en leur \n",
      "objectivité. Une objectivité d’autant plus précieuse qu’elle \n",
      "ferait souvent défaut aux humains. Tout algorithme est \n",
      "pourtant, en un sens, biaisé, dans la mesure où il est tou-\n",
      "jours le reflet – à travers son paramétrage et ses critères de \n",
      "fonctionnement, ou à travers les données d’apprentissage \n",
      "\n",
      "qui lui ont été fournies – d’un système de valeurs et de choix \n",
      "de société. Le débat autour des biais et des discriminations \n",
      "qu’ils peuvent générer n’est donc qu’un miroir grossissant \n",
      "mettant en valeur cette caractéristique essentielle dans ce \n",
      "qu’elle a de plus problématique.\n",
      "\n",
      "Plusieurs exemples ont récemment illustré de façon parti-\n",
      "culièrement nette et choquante ce type de biais. En 2015, \n",
      "un logiciel de reconnaissance faciale de Google a ainsi \n",
      "suscité une forte polémique. Un jeune couple d’Afro-Amé-\n",
      "ricains s’est rendu compte qu’une de ses photos avait été \n",
      "\n",
      "\n",
      "32\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "étiquetée sous le tag « gorille ». L’explication de ce dysfonc-\n",
      "tionnement réside dans le type de données avec lesquelles \n",
      "l’algorithme a été entraîné pour reconnaître des personnes. \n",
      "En l’occurrence, il est vraisemblable qu’il l’ait été au moyen \n",
      "essentiellement, voire exclusivement, de photographies de \n",
      "personnes blanches (d’autres exemples existent d’ailleurs \n",
      "de biais racistes de logiciels de reconnaissance d’image au \n",
      "détriment de personnes de type « asiatique »). En consé-\n",
      "quence, l’algorithme a considéré qu’une personne de cou-\n",
      "leur noire présentait plus de similitude avec l’objet « gorille »  \n",
      "qu’elle avait été entrainée à reconnaitre qu’avec l’objet \n",
      "« humain ».\n",
      "\n",
      "Notons d’ailleurs que des actes de malveillance volontaires \n",
      "de la part de personnes impliquées dans le processus d’en-\n",
      "traînement de ce type d’algorithmes ne sont pas exclus. \n",
      "Ainsi en a-t-il été pour le robot conversationnel Tay déve-\n",
      "loppé par Microsoft et qui s’est mis à proférer sur Twitter \n",
      "des propos racistes et sexistes après quelques heures de \n",
      "fonctionnement et d’entraînement au contact des propos \n",
      "que lui adressaient des internautes.\n",
      "\n",
      "Les biais des algorithmes peuvent aussi être des biais de \n",
      "genre. En 2015, trois chercheurs de l’Université Carnegie \n",
      "Mellon et de l’International Computer Science Institute \n",
      "\n",
      "FOCUS\n",
      "\n",
      "Des algorithmes contre la récidive ?  \n",
      "Les applications de justice prédictive font l’objet d’une attention publique toute particulière quant à leurs \n",
      "potentiels effets discriminatoires. Une polémique a éclaté autour de l’application COMPAS (Correctional \n",
      "Offender Management Profile for Alternative Sanction) visant à produire un score de risque de récidive \n",
      "pour les détenus ou accusés lors d’un procès. Bien que des outils d’analyse statistique de données aient \n",
      "déjà été déployés au sein des tribunaux américains depuis les années 1970, un tel calcul automatique \n",
      "sous la forme de score revêt un caractère nouveau pour la prise de décisions de libération conditionnelle.\n",
      "\n",
      "En d’autres termes, le travailleur social utilisant COMPAS a recours à une interface lui permettant de \n",
      "répondre, en collaboration avec le prévenu, à des questions du type « Que pense le prévenu de la police ? », \n",
      "« Quelles sont les caractéristiques des amis du prévenu ? », « Certains d’entre eux ont-ils déjà été condam-\n",
      "nés ? »19. Un score de risque est ainsi calculé et ajouté au dossier du prévenu.\n",
      "\n",
      "Le site ProPublica a accusé Nortphointe, société commercialisant COMPAS, de produire des scores biaisés \n",
      "et racistes20. Ce constat repose sur la confrontation des scores de récidive de détenus libérés avec l’ob-\n",
      "servation, ou non, d’une arrestation sur une période de deux ans. Le taux de faux positifs (c’est-à-dire un \n",
      "score élevé mais sans récidive effective observée) s’est révélé considérablement plus fort pour les anciens \n",
      "détenus d’origine afro-américaine que pour les individus blancs.\n",
      "\n",
      "ont mis en évidence la façon dont Adsense, la plateforme \n",
      "publicitaire de Google, générait un biais au détriment des \n",
      "femmes. À l’aide d’un logiciel baptisé Adfisher, ils ont créé \n",
      "17 000 profils dont ils ont ensuite simulé la navigation sur \n",
      "le Web afin de mener une série d’expériences. Ils ont ainsi \n",
      "constaté que les femmes se voyaient proposer des offres \n",
      "d’emploi moins bien rémunérées que celles adressées à \n",
      "des hommes, à niveau similaire de qualification et d’expé-\n",
      "rience. Il est apparu qu’un nombre restreint de femmes rece-\n",
      "vaient des annonces publicitaires en ligne leur proposant un \n",
      "emploi au revenu supérieur à 200 000 dollars annuels. Loin \n",
      "d’être anecdotique, « la publicité en ligne ciblée de Google \n",
      "est tellement omniprésente que l’information proposée \n",
      "aux personnes est susceptible d’avoir un effet tangible sur \n",
      "les décisions qu’elles prennent », souligne Anupam Datta, \n",
      "co-auteur de l’étude. \n",
      "\n",
      "Ici encore, les causes précises sont difficiles à établir. Il \n",
      "est bien sûr envisageable qu’un tel biais soit le fruit d’une \n",
      "volonté des annonceurs eux-mêmes : ceux-ci auraient alors \n",
      "délibérément choisi d’adresser des offres différentes aux \n",
      "hommes et aux femmes. Mais il est tout aussi possible \n",
      "que ce phénomène soit aussi le résultat d’une réaction de \n",
      "l’algorithme aux données qu’il a reçues. En l’occurrence, les \n",
      "hommes auraient pu avoir davantage tendance en moyenne \n",
      "à cliquer sur les publicités annonçant les emplois les mieux \n",
      "rémunérés tandis que les femmes auraient eu tendance à \n",
      "s’autocensurer, selon des mécanismes bien connus des \n",
      "sciences sociales. Dès lors, le biais sexiste de l’algorithme \n",
      "ne serait pas autre chose que la reproduction d’un biais \n",
      "préexistant dans la société.\n",
      "\n",
      "19  https://usbeketrica.com/article/un-algorithme-peut-il-predire-le-risque-de-recidive-des-detenus \n",
      "20 https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing \n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "33\n",
      "\n",
      "Troisième exemple, en avril 2016, il a été révélé qu’Ama-\n",
      "zon avait exclu d’un de ses nouveaux services (la livraison \n",
      "gratuite en un jour) des quartiers peuplés majoritairement \n",
      "de populations défavorisées à Boston, Atlanta, Chicago, \n",
      "Dallas, New York et Washington. À l’origine, un algorithme \n",
      "d’Amazon avait mis en évidence, en analysant les données \n",
      "à sa disposition, que les quartiers en question n’offraient \n",
      "guère de possibilités de profit pour l’entreprise. Même si \n",
      "l’objectif d’Amazon n’était assurément pas d’exclure de ses \n",
      "services des zones parce que leur population était majo-\n",
      "ritairement noire, tel s’avérait pourtant bien être le résultat \n",
      "de l’utilisation de cet algorithme : dans six grandes villes, \n",
      "il apparaît clairement que « l’aire de fourniture du service \n",
      "exclut les codes postaux à population majoritairement noire, \n",
      "à des degrés variés ». En conséquence, les citoyens noirs  \n",
      "ont environ deux fois moins de chances que les blancs de \n",
      "vivre dans des zones desservies par [le service d’Amazon en \n",
      "question]21 ». À Boston, alors que la ville entière avait accès \n",
      "au service, seuls trois codes postaux en étaient exclus, dans \n",
      "le quartier majoritairement noir de Roxbury. \n",
      "\n",
      "Comment expliquer ce phénomène, alors qu’Amazon a sou-\n",
      "ligné – à juste titre, sans aucun doute – n’avoir recouru à \n",
      "aucune donnée raciale pour alimenter l’algorithme ? Il a été \n",
      "opposé à Amazon que les quartiers concernés étaient préci-\n",
      "sément les mêmes que ceux qui avaient fait l’objet pendant \n",
      "des décennies de la pratique dite du « redlining », consistant \n",
      "pour les banques à refuser systématiquement d’accorder \n",
      "des prêts à des Afro-Américains, même solvables, en rai-\n",
      "son de la couleur de leur peau et de leur domiciliation dans \n",
      "des zones peuplées majoritairement par des minorités. Il \n",
      "est donc évident que l’algorithme d’Amazon a pour effet \n",
      "de reproduire des discriminations préexistantes, quand \n",
      "bien même aucun racisme intentionnel n’est ici à l’œuvre.\n",
      "\n",
      "Le paramétrage des algorithmes, c’est-à-dire la définition \n",
      "explicite des critères selon lesquels ils fonctionnent et \n",
      "opèrent des tris, sélectionnent et recommandent, peut \n",
      "bien sûr être la source de biais et de discrimination. Mais, \n",
      "comme le montrent les trois exemples évoqués ci-des-\n",
      "sus, ce sont bien les biais provoqués par les données four-\n",
      "nies aux systèmes qui soulèvent le défi le plus redoutable \n",
      "\n",
      "Inconscients chez ceux-là \n",
      "mêmes qui sélectionnent \n",
      "\n",
      "les données, les biais ne sont \n",
      "pas forcément sensibles pour \n",
      "les utilisateurs qui y sont sujets\n",
      "\n",
      "21  https://www.bloomberg.com/graphics/2016-amazon-same-day/\n",
      "\n",
      "LE SAVIEZ-VOUS ?\n",
      "\n",
      "À l’occasion du débat organisé le 24 juin 2017 \n",
      "par  le  Génotoul  (Toulouse),  Philippe  Besse, \n",
      "Professeur de mathématiques et de statistique \n",
      "à l’Université de Toulouse a souligné que nous \n",
      "ne sommes pas tous égaux devant la méde-\n",
      "cine personnalisée, car les bases de données \n",
      "utilisées  à  l’heure  actuelle  sont  largement \n",
      "biaisées : une étude a révélée qu’en 2009, 96 % \n",
      "des échantillons de ces bases ont des ancêtres \n",
      "européens (la démonstration porte sur 1,5 mil-\n",
      "lion d’échantillons). D’autres sources de biais \n",
      "sont l’âge (car toutes ces bases de données sont \n",
      "largement occupées par des personnes rela-\n",
      "tivement âgées) et le genre, plusieurs publi-\n",
      "cations récentes insistant sur l’importance \n",
      "de l’effet du genre sur le développement des \n",
      "maladies concernées. Dans ces bases, le chro-\n",
      "mosome X est largement sous représenté et le \n",
      "Y est quasiment absent. Philippe Besse conclut \n",
      "ainsi : « si vous êtes une femme d’origine afri-\n",
      "caine et jeune, je ne pense pas que la médecine \n",
      "personnalisée vous concerne ».\n",
      "\n",
      "aujourd’hui. Le caractère historique d’un jeu de données \n",
      "confère à celui-ci la capacité à reproduire des inégalités \n",
      "ou des discriminations préexistantes. Un algorithme qui \n",
      "chercherait à définir les profils à recruter sur la base des \n",
      "profils ayant correspondu aux trajectoires de carrière les \n",
      "plus réussies dans le passé d’une entreprise pourrait ainsi \n",
      "tout à fait exclure les femmes, soit que celles-ci aient fait \n",
      "l’objet d’une exclusion dans le passé, soit qu’elles aient \n",
      "eu tendance à interrompre leurs carrières davantage que \n",
      "leurs collègues masculins, par exemple. On notera d’ailleurs \n",
      "que, pour l’entreprise en question, l’utilisation irraisonnée \n",
      "d’un tel algorithme aurait pour conséquence de se priver \n",
      "de talents. Le problème éthique croiserait ici directement \n",
      "l’enjeu d’efficacité. \n",
      "\n",
      "Dès lors, l’opération même d’entraînement des algorithmes – \n",
      "à travers la sélection qu’elle suppose des données à prendre \n",
      "en compte – apparaît comme le cœur d’un enjeu éthique \n",
      "et juridique, et non pas seulement technique ou d’effica-\n",
      "cité. Cet enjeu recoupe en partie celui de la délégation de \n",
      "prises de décisions, abordé précédemment : choisir quelles \n",
      "données sont utilisées pour les phases d’apprentissage \n",
      "revient bien à prendre des décisions parfois lourdes de \n",
      "conséquences. En revanche, le caractère spécifique de \n",
      "l’enjeu abordé ici tient au fait qu’il s’agit de décisions et \n",
      "de choix qui peuvent être effectués de manière presque \n",
      "inconsciente (alors que le codage d’un algorithme classique \n",
      "\n",
      "\n",
      "34\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "et déterministe est toujours une opération délibérée). Celui \n",
      "qui entraîne un algorithme y insère d’une certaine façon sa \n",
      "propre vision du monde, ses valeurs ou, à tout le moins, \n",
      "des valeurs présentes plus ou moins directement dans les \n",
      "données tirées du passé. La chercheuse Kate Crawford, \n",
      "notamment, a ainsi mis en évidence l’endogamie sociale, \n",
      "raciale et de genre qui caractérise les milieux où se recrutent \n",
      "ceux qui entraînent aujourd’hui l’intelligence artificielle22.\n",
      "\n",
      "Tout ceci explique largement l’une des caractéristiques les \n",
      "plus problématiques de ces biais et des discriminations \n",
      "auxquelles ceux-ci peuvent donner lieu : ils sont souvent \n",
      "particulièrement difficiles à découvrir. Inconscients chez \n",
      "ceux-là mêmes qui sélectionnent les données, ils ne sont \n",
      "pas forcément sensibles pour les utilisateurs qui y sont \n",
      "sujets. Le caractère ciblé des offres d’emploi évoquées pré-\n",
      "cédemment fait que les femmes concernées n’avaient pas \n",
      "connaissance des offres d’emploi proposées aux hommes. \n",
      "C’est l’une des conséquences du phénomène d’« enferme-\n",
      "ment algorithmique », dont il sera question plus loin. Enfin, \n",
      "les systèmes d’intelligence artificielle font quant à eux des \n",
      "choix dont la logique (voire l’existence même) échappe à \n",
      "leurs concepteurs.\n",
      "\n",
      "En somme, les biais et les discriminations générées par \n",
      "les  algorithmes  soulèvent  aujourd’hui  deux  questions \n",
      "majeures. Faut-il d’abord considérer au moins dans certains \n",
      "\n",
      "cas que l’intelligence artificielle ne fait jamais que recon-\n",
      "duire des biais et des discriminations déjà existants dans \n",
      "la société ? En d’autres termes, les algorithmes ne seraient \n",
      "jamais ici que des « conducteurs » de biais, ils ne feraient \n",
      "que les répéter sans les créer eux-mêmes. On pourrait à \n",
      "tout le moins objecter à une telle position que l’échelle à \n",
      "laquelle ils se déploient et leur impact potentiel en font les \n",
      "lieux privilégiés pour la lutte contre les discriminations, que \n",
      "leur puissance, en somme, implique des obligations ren-\n",
      "forcées. Sans compter qu’il n’est pas exclu qu’ils puissent \n",
      "aussi avoir un effet démultiplicateur de ces biais.\n",
      "\n",
      "Deuxièmement, comment se donner les moyens de repé-\n",
      "rer effectivement ces biais, dont nous avons souligné le \n",
      "caractère parfois invisible ? Faut-il d’ailleurs distinguer entre \n",
      "des biais qui seraient acceptables et d’autres que la société \n",
      "ne pourrait pas tolérer (comme ceux évoqués plus haut) ? \n",
      "Enfin, comment lutter efficacement contre ces biais et s’as-\n",
      "surer que les algorithmes respectent les valeurs fonda-\n",
      "mentales élaborées démocratiquement par nos sociétés ?\n",
      "\n",
      "Il faut enfin souligner ici une dimension que nous verrons \n",
      "resurgir dans la suite de ce rapport : les impacts non pas \n",
      "seulement individuels (sur la personne), mais également \n",
      "collectifs que peuvent avoir les algorithmes. L’exemple de \n",
      "l’exclusion par un service d’Amazon de quartiers entiers \n",
      "en offre une illustration.\n",
      "\n",
      "Fragmentation algorithmique :  \n",
      "la personnalisation contre \n",
      "les logiques collectives\n",
      "\n",
      "L’omniprésence des algorithmes, notamment ceux liés à \n",
      "notre navigation sur le Web et sur les réseaux sociaux, est \n",
      "indissociablement liée à la dynamique de personnalisa-\n",
      "tion des contenus et des services. Cette personnalisation \n",
      "au service de l’individu recèle cependant une dimension \n",
      "problématique en portant potentiellement atteinte à des \n",
      "logiques proprement collectives sur lesquelles reposent \n",
      "nos sociétés, de la structuration de l’espace public démo-\n",
      "cratique aux mécanismes de mutualisation dans l’ordre \n",
      "économique. Alors que l’impact des algorithmes sur les \n",
      "personnes est un phénomène bien repéré et pris en compte \n",
      "\n",
      "par la loi depuis longtemps, ses impacts collectifs posent \n",
      "également question aujourd’hui.\n",
      "\n",
      "Enfermement algorithmique \n",
      "et perte de pluralisme culturel\n",
      "\n",
      "Le thème de l’enfermement algorithmique a fait l’objet de \n",
      "nombreuses discussions depuis l’ouvrage d’Eli Pariser sur \n",
      "la « bulle filtrante23 ». Il renvoie à l’idée selon laquelle l’ac-\n",
      "tivité indispensable jouée par les algorithmes en termes \n",
      "\n",
      "22  Kate Crawford, “Artificial Intelligence’s White Guy Problem”, The New York Times, 25 juin 2016.\n",
      "23 Eli Pariser, The Filter Bubble: What the Internet Is Hiding from You, New York, Penguin Press, 2011.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "35\n",
      "\n",
      "de classement et de filtrage d’une information devenue \n",
      "surabondante aurait pour effet indirect de nuire au plu-\n",
      "ralisme et à la diversité culturelle: en filtrant les informa-\n",
      "tions, en s’appuyant sur les caractéristiques de leurs profils,  \n",
      "les algorithmes augmenteraient la propension des indi-\n",
      "vidus à ne fréquenter que des objets, des personnes, des \n",
      "opinions, des cultures conformes à leurs propres goûts \n",
      "et à rejeter l’inconnu.\n",
      "\n",
      "Le thème de la bulle filtrante se pose à deux échelles, celle \n",
      "des individus et celle de la société dans son ensemble. \n",
      "\n",
      "À l’échelle de l’individu, le risque est que celui-ci se voie \n",
      "purement et simplement assimilé à un alter ego numérique \n",
      "constitué à partir de ses données et se trouve en quelque \n",
      "sorte enfermé dans une bulle de recommandations tou-\n",
      "jours conforme à ce profil. Les effets d’une offre culturelle \n",
      "et de contenus plus abondante que jamais auparavant se \n",
      "verraient ainsi paradoxalement neutralisés par un phéno-\n",
      "mène de limitation de l’exposition effective des individus \n",
      "à la diversité culturelle. Un tel phénomène pourrait d’ail-\n",
      "leurs se produire alors même que l’individu souhaiterait \n",
      "en principe une telle diversité. La Direction Générale des \n",
      "Médias et des Industries Culturelles (DGMIC) souligne ainsi \n",
      "que « la recommandation algorithmique est fondée sur la \n",
      "consommation réelle des utilisateurs plutôt que sur leurs \n",
      "désirs ou aspirations ».\n",
      "\n",
      "Il faut pourtant relever que d’importants spécialistes, cher-\n",
      "cheurs et praticiens du numérique contestent l’idée d’en-\n",
      "fermement algorithmique ou du moins invitent à poser la \n",
      "question de manière plus nuancée. Ainsi, selon Antoinette \n",
      "Rouvroy, « cette question de la bulle filtrante n’est pas propre \n",
      "aux algorithmes: nous sommes des êtres très prévisibles, \n",
      "aux comportements très réguliers, facilitant la possibilité de \n",
      "nous enfermer dans des bulles. Mais on ne nous enferme \n",
      "que si c’est rentable. Tout est une question de paramé-\n",
      "trage des algorithmes. Ils peuvent aussi, au contraire nous \n",
      "exposer à des éléments ou à des informations que nous \n",
      "n’aurions jamais cherché à consulter » (propos tenus le 23 \n",
      "janvier 2017 lors de l’événement de lancement du débat \n",
      "public à la CNIL). Il est vrai que l’on constate que cette \n",
      "potentialité n’est de fait guère exploitée. En effet, la consom-\n",
      "mation culturelle repose sur une structure duale de goûts : \n",
      "d’une part des liens forts « traduisant une préférence avérée \n",
      "pour un type de contenus bien identifié a priori », d’autre \n",
      "part des liens faibles « rendant compte d’une affinité non \n",
      "encore révélée pour un type de contenus restant à découvrir \n",
      "à posteriori24 ». Or, la plupart des algorithmes prédictifs des \n",
      "grandes plateformes culturelles (Netflix, Amazon, Spotify, \n",
      "etc.) se focalisent sur les liens forts. Aucune des grandes \n",
      "catégories d’algorithmes n’envisage la sérendipité comme \n",
      "variable essentielle aux choix de consommation.\n",
      "\n",
      "Les algorithmes \n",
      "\n",
      "augmenteraient la propension \n",
      "des individus à ne fréquenter \n",
      "que des objets, des personnes, \n",
      "\n",
      "des opinions, des cultures \n",
      "\n",
      "conformes à leurs propres goûts \n",
      "\n",
      "et à rejeter l’inconnu\n",
      "\n",
      "Dominique Cardon souligne quant à lui que « le numérique \n",
      "a apporté une diversité informationnelle jamais connue \n",
      "dans toute l’Histoire de l’Humanité. Il est absurde de dire \n",
      "que Facebook enferme les gens. Mais cela soulève des \n",
      "dangers : des gens curieux vont envoyer des signaux de \n",
      "curiosité et vont se voir incités en retour à la curiosité. En \n",
      "revanche, des gens donnant peu de traces de curiosité \n",
      "vont être dirigés vers moins de diversité. [...] Un risque \n",
      "existe que se produisent dans un certain contexte et pour \n",
      "un certain public, des pratiques sociales dans lesquelles \n",
      "l’algorithme ne sera pas un facteur d’enrichissement et \n",
      "de découverte, mais plutôt de reconduction du monde » \n",
      "(propos tenus le 23 janvier 2017 lors de l’événement de \n",
      "lancement du débat public à la CNIL). Enfin, la DGMIC \n",
      "estime que les incitations concurrentielles à la différencia-\n",
      "tion ainsi qu’« une vision libérale de l’individu considérant \n",
      "l’étendue du choix comme un facteur d’épanouissement »25  \n",
      "pourraient limiter les risques pesant sur la diversité en \n",
      "incitant les acteurs à se saisir de l’enjeu de l’enfermement \n",
      "et à lui apporter des réponses. \n",
      "\n",
      "À l’échelle de sociétés considérées dans leur ensemble, \n",
      "les formes de privation d’exposition des individus à l’al-\n",
      "térité, à des opinions différentes des leurs, notamment \n",
      "dans le registre politique, pourraient en tout cas consti-\n",
      "tuer, selon certains, un problème pour la qualité et la \n",
      "vitalité du débat public, pour la qualité et la diversité de \n",
      "l’information, terreaux du fonctionnement correct des \n",
      "démocraties. \n",
      "\n",
      "À l’horizon logique du phénomène, la personnalisation de \n",
      "l’information aurait pour conséquence une fragmentation \n",
      "extrême de l’espace public, la disparition d’un socle mini-\n",
      "mum d’informations partagées par l’ensemble du corps \n",
      "politique et permettant la constitution d’un véritable débat.\n",
      "\n",
      "24 Rapport du CSA Lab\n",
      "25  Natali HELBERGER, Kari KARPPINEN & Lucia D’ACUNTO, “Exposure diversity as a design principle for recommender systems”, Information, Communication & Society, 2016.\n",
      "\n",
      "\n",
      "36\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "À l’heure où une part croissante des citoyens utilisent les \n",
      "réseaux sociaux comme le principal (et parfois seul) moyen \n",
      "d’information26, l’enjeu est important pour la pérennité de la \n",
      "vie démocratique. Si la tendance à s’entourer de personnes \n",
      "partageant les mêmes idées et les mêmes valeurs n’est pas \n",
      "nouvelle, du moins la presse traditionnelle avec sa logique \n",
      "éditoriale permet-elle au lecteur d’avoir une plus claire \n",
      "conscience de l’orientation du contenu qu’il consomme.\n",
      "Les débats portant sur ce sujet font pourtant clairement res-\n",
      "sortir que les effets dénoncés sous la rubrique de la « bulle \n",
      "de filtre » ne sont pas fatalement et toujours produits par les \n",
      "algorithmes. Ils sont avant tout le résultat du paramétrage \n",
      "d’algorithmes que l’on pourrait tout aussi bien programmer \n",
      "autrement et à qui l’on pourrait, à l’inverse, donner comme \n",
      "objectif d’exposer les individus à une diversité culturelle, \n",
      "informationnelle, politique forte. \n",
      "\n",
      "Il est possible que la nature même du problème en ait ralenti \n",
      "la prise de conscience publique. À la limite, en effet, l’individu \n",
      "peut très bien vivre dans sa bulle informationnelle sans en \n",
      "prendre conscience. Le confort provoqué par l’absence de \n",
      "contradiction ou encore le biais de confirmation caractéri-\n",
      "sant l’esprit humain et que connaissent bien les sciences \n",
      "cognitives ne sont évidemment pas des facteurs propices \n",
      "à la remise en cause de l’enfermement algorithmique. \n",
      "Autrement dit, rien ne prédispose l’individu à s’apercevoir \n",
      "qu’il est pris dans une bulle informationnelle. Il n’est dès lors \n",
      "guère étonnant que les mises en cause de ce phénomène \n",
      "s’accompagnent souvent de récits relatant le moment de sa \n",
      "prise de conscience, un moment s’apparentant à un choc. \n",
      "C’est ainsi que les débats sur la bulle filtrante et ses effets \n",
      "politiques ont été notamment relancés à l’occasion de la \n",
      "campagne présidentielle américaine de 2016 ainsi que par \n",
      "celle du Brexit, quelques mois avant. Deux chocs électoraux \n",
      "à l’occasion desquels de nombreux internautes partisans \n",
      "d’Hillary Clinton ou opposants au Brexit ont été particuliè-\n",
      "rement frappés de constater des résultats que leurs fils \n",
      "d’actualité ne laissaient en rien présager. Plus récemment, \n",
      "en août 2017, la sociologue Zeynep Tufekci, spécialiste des \n",
      "mouvements de contestation en ligne a remarqué – parmi \n",
      "d’autres – que son fil d’information Facebook demeurait \n",
      "silencieux sur les événements de Ferguson au moment \n",
      "même où elle voyait le hashtag Ferguson se répandre sur \n",
      "Twitter.\n",
      "\n",
      "On peut considérer que l’absence de compréhension claire \n",
      "par les individus du fonctionnement des plateformes qu’ils \n",
      "utilisent pour s’informer, notamment, fait partie intégrante \n",
      "du problème. Une étude a ainsi montré que plus de 60% \n",
      "des utilisateurs de Facebook n’ont aucune idée de l’activité \n",
      "éditoriale que joue effectivement l’algorithme et croient que \n",
      "tous les posts de leurs amis et des pages qu’ils suivent \n",
      "\n",
      "apparaissent sur leur fil d’actualités27. En vérité, ils n’en \n",
      "voient que 20%, sélectionnés selon plusieurs facteurs : \n",
      "promotion publicitaire du post, interactions passées de \n",
      "l’utilisateur avec des posts considérés comme similaires \n",
      "– like, commentaire, partage-, nombre d’autres utilisateurs \n",
      "ayant fait de même, etc.\n",
      "\n",
      "L’usage fait des algorithmes par l’économie numérique à \n",
      "des fins de personnalisation du service et de l’expérience \n",
      "répond donc à une logique qui pose problème dès lors \n",
      "que l’on considère ses effets d’un point de vue, non plus \n",
      "seulement économique, mais aussi culturel ou politique. \n",
      "L’objet des grandes plateformes algorithmiques est la \n",
      "satisfaction d’un consommateur, d’un homo economicus. \n",
      "Les effets politiques et culturels à grande échelle de leurs \n",
      "algorithmes ne leur posent question que secondairement.\n",
      "\n",
      "Atomisation de la communauté politique\n",
      "\n",
      "Cet effet induit des algorithmes et de leur fonction de per-\n",
      "sonnalisation peut néanmoins devenir un levier direct pour \n",
      "certains acteurs qui cherchent à les exploiter à des fins \n",
      "d’influence, voire de manipulation. Les fake news, largement \n",
      "évoquées lors de la campagne menée par Donald Trump, \n",
      "si elles ne sont pas un produit direct des algorithmes, se \n",
      "diffusent et s’amplifient à l’intérieur des chambres d’écho \n",
      "constituées par les algorithmes des réseaux sociaux ou \n",
      "des moteurs de recherche. Plus directement encore, des \n",
      "logiciels de stratégie politique de plus en plus élaborés et \n",
      "appuyés sur un ciblage de plus en plus fin des électeurs \n",
      "conduisent à une fragmentation potentiellement sans pré-\n",
      "cédent d’un discours politique adressé désormais à des \n",
      "individus atomisés. Les pratiques de la société Cambridge \n",
      "Analytica, qui a travaillé pour le candidat Trump, repré-\n",
      "sentent la pointe de diamant de ces nouveaux usages \n",
      "des algorithmes à des fins électorales (voir encadré). La \n",
      "tendance à la fragmentation personnalisée du discours \n",
      "politique, appuyée sur la capacité croissante de l’IA à com-\n",
      "poser des messages en fonction des différents profils, pose \n",
      "aujourd’hui de sérieuses questions. Faut-il y voir une forme \n",
      "de manipulation ? Faut-il y poser des limites ? Faut-il consi-\n",
      "dérer ces pratiques comme le fruit inéluctable et diffici-\n",
      "lement régulable de l’évolution technologique et dès lors \n",
      "imaginer des contrepoids ? Si oui, lesquels ?\n",
      "\n",
      "On le voit, le thème de l’enfermement est l’envers de celui \n",
      "de la personnalisation algorithmique. Ceci explique qu’en-\n",
      "fermement et fragmentation puissent être aussi décelés \n",
      "dans des secteurs autres que celui de la consommation \n",
      "culturelle et des médias ou de la politique.\n",
      "\n",
      "26  Selon le Pew Research Center, 61% des “millenials” utilisent Facebook comme leur première source d’information sur la politique l’action gouvernementale (Pew Research \n",
      "\n",
      "Center, Millenials & Political News. Social Media – the Local TV for the Next Generation ?, juin 2015).\n",
      "\n",
      "27 http://www-personal.umich.edu/~csandvig/research/Eslami_Algorithms_CHI15.pdf\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "37\n",
      "\n",
      "FOCUS\n",
      "\n",
      "Algorithmes et stratégie électorale \n",
      "Les dernières élections présidentielles, aux États-Unis mais aussi en France, ont donné lieu à l’utilisation \n",
      "croissante des logiciels de stratégie électorale reposant sur la mise en œuvre d’algorithmes prédictifs \n",
      "d’analyse des données électorales. Loin des méthodes plus traditionnelles de campagne, des messages \n",
      "politiques très ciblés peuvent désormais être adressés aux électeurs. C’est aux Etats-Unis que l’on peut \n",
      "identifier les exemples les plus accomplis d’un tel profilage individuel. Dès les élections présidentielles \n",
      "de 2008 et 2012, les équipes électorales de Barack Obama disposaient de centaines de données sur la qua-\n",
      "si-totalité des électeurs. En 2016, grâce à l’analyse des données issues des réseaux sociaux et des courtiers \n",
      "en données, Cambridge Analytica aurait pu envoyer pour le compte du candidat Trump des milliers de \n",
      "messages extrêmement individualisés au cours d’une même soirée28. Si cette entreprise a par la suite tenu \n",
      "un discours tendant à minimiser ses premières affirmations, cette affaire n’en est pas moins révélatrice \n",
      "d’une tendance de fond susceptible de s’approfondir à l’avenir.\n",
      "\n",
      "En France, les principes de protection des données à caractère personnel limitent toutefois dans les faits le \n",
      "développement de tels logiciels de ciblage individuel, le consentement constituant un prérequis essentiel \n",
      "à une telle collecte. La CNIL a d’ailleurs rappelé, dans un communiqué de novembre 2016, les règles pour \n",
      "l’utilisation des données issues des réseaux sociaux à des fins de communication politique29. \n",
      "\n",
      "L’enfermement algorithmique, \n",
      "un enjeu transversal\n",
      "\n",
      "La question de l’enfermement algorithmique ne se limite \n",
      "pas aux secteurs de la culture, de l’information ou de la \n",
      "politique. En effet, l’intrication des fonctions de prédiction \n",
      "et de recommandation présentes dans les usages des sys-\n",
      "tèmes algorithmiques aujourd’hui modelés par l’écosys-\n",
      "tème numérique est susceptible de générer des prophéties \n",
      "auto-réalisatrices pouvant enfermer les individus dans un \n",
      "destin « prédit ».\n",
      "\n",
      "Une forme d’enfermement n’est-elle pas une conséquence \n",
      "possible de futurs usages des learning analytics et de l’adap-\n",
      "tative learning (ou éducation personnalisée) ? Sans remettre \n",
      "en cause les promesses de ces techniques, il est légitime \n",
      "de s’interroger sur les effets que pourraient avoir des sys-\n",
      "tèmes prétendant définir des parcours d’apprentissage sur \n",
      "la base du profil de chaque élève et de la prédiction élabo-\n",
      "rée à partir de l’application d’un modèle mathématique à \n",
      "ce profil. N’y a-t-il pas un risque que la prédiction devienne \n",
      "auto-réalisatrice et que l’élève se trouve assigné à un destin \n",
      "scolaire et professionnel dès lors que le diagnostic aura \n",
      "\n",
      "été posé ? Comme le souligne Roger-François Gauthier, \n",
      "« avec les learning analytics, la prédiction pourrait débou-\n",
      "cher sur un enfermement des élèves. En France, ce genre \n",
      "de problème suscite trop peu d’attention. Il faut pourtant \n",
      "faire en sorte que l’élève échappe au déterminisme et pour \n",
      "cela la question des valeurs inscrites dans les systèmes \n",
      "algorithmiques est fondamentale30 ». \n",
      "\n",
      "On peut, de la même façon, rattacher à l’idée d’enfermement \n",
      "algorithmique certains impacts possibles de l’utilisation des \n",
      "algorithmes dans le secteur des ressources humaines et \n",
      "du recrutement. Laurence Devillers évoque ainsi le risque \n",
      "de « normalisation des profils » que pourrait faire courir \n",
      "l’algorithme, du moins un usage non raisonné de l’algo-\n",
      "rithme, au recruteur. C’est en quelque sorte ce dernier qui \n",
      "serait victime ici d’enfermement dans des profils prédéfinis \n",
      "à l’avance, se privant de la part de sérendipité inhérente au \n",
      "processus de recrutement dans la mesure où celui-ci peut \n",
      "permettre de repérer des profils atypiques, non conformes \n",
      "aux critères définis a priori, mais finalement intéressants. \n",
      "Comment repérer de tels profils si une part croissante de \n",
      "la sélection des candidats se trouve déléguée à des sys-\n",
      "tèmes automatiques ?\n",
      "\n",
      "28  https://www.theguardian.com/politics/2017/feb/26/robert-mercer-breitbart-war-on-media-steve-bannon-donald-trump-nigel-farage \n",
      "29 https://www.cnil.fr/fr/communication-politique-quelles-sont-les-regles-pour-lutilisation-des-donnees-issues-des-reseaux \n",
      "30  Propos tenus à l’occasion du lancement du débat public, le 23 janvier 2017, à la CNIL.\n",
      "\n",
      "\n",
      "38\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "Démutualisation\n",
      "\n",
      "La personnalisation algorithmique soulève un enjeu spéci-\n",
      "fique au secteur de l’assurance. En effet, la dynamique de \n",
      "personnalisation des offres et des services ne conduit-elle \n",
      "pas à une remise en cause de la mutualisation, c’est-à-dire \n",
      "de la logique même de l’assurance et du pacte social sur \n",
      "lequel elle repose ? Que plusieurs individus acceptent de \n",
      "s’assurer, c’est-à-dire de mettre en commun leurs risques, \n",
      "suppose que ces risques leur demeurent au moins partiel-\n",
      "lement opaques. Je m’assure en ignorant lequel de moi ou \n",
      "de mon voisin contractera une maladie occasionnant de \n",
      "lourds frais de santé. La segmentation accrue que rendrait \n",
      "possible l’utilisation des masses de données générées par \n",
      "les comportements des individus en ligne (réseaux sociaux, \n",
      "notamment) ou hors-ligne (données issues de bracelets \n",
      "connectés, par exemple) tendrait à lever le « voile d’igno-\n",
      "rance31 » sous-tendant la mutualisation assurantielle et \n",
      "que contribue à maintenir une segmentation sommaire.\n",
      "\n",
      "Ces innovations ne déboucheront-elles pas sur de nou-\n",
      "velles formes de discrimination et d’exclusion ? Les indi-\n",
      "vidus jugés « à risque » pourraient se voir appliquer des \n",
      "tarifs plus élevés, voire même être victimes de décisions de \n",
      "refus d’assurance. À cela s’ajoute le fait que l’établissement \n",
      "d’une corrélation entre un comportement et le risque de \n",
      "survenue d’une pathologie pourrait aboutir à défavoriser \n",
      "les individus ayant des comportements jugés « à risque » \n",
      "(consommation de tabac, nourriture jugée trop grasse, trop \n",
      "\n",
      "sucrée, etc.). La question serait alors celle des limites à \n",
      "poser à ce qui peut apparaître comme une normalisation \n",
      "excessive des comportements des personnes lorsque \n",
      "ceux-ci seraient estimés « mauvais ». Les algorithmes, \n",
      "via les corrélations qu’ils établissent dans les données, \n",
      "finiraient par édicter la norme des comportements indivi-\n",
      "duels, une norme à laquelle on ne pourrait échapper qu’au \n",
      "prix d’un renchérissement de l’assurance. À la différence \n",
      "d’un mécanisme comme l’augmentation des prix du tabac \n",
      "(dont la consommation est considérée comme un coût \n",
      "pour la collectivité), de tels arbitrages échapperaient à la \n",
      "délibération collective et surgiraient des données mêmes. \n",
      "Par ailleurs, une telle approche évacuerait complètement \n",
      "les déterminants collectifs et sociaux des comportements \n",
      "pour ne plus mettre en exergue que la seule responsabilité \n",
      "des individus. Quant à d’autres facteurs de risque, liés à \n",
      "l’environnement de l’individu ou à son patrimoine génétique, \n",
      "ils seraient susceptibles de déboucher sur une discrimi-\n",
      "nation et une exclusion inévitables dans la mesure où les \n",
      "personnes concernées n’auraient aucune prise sur eux.\n",
      "\n",
      "Si la course aux « bons risques » pourrait donc être accrue \n",
      "entre les assureurs, il est cependant douteux que celle-ci \n",
      "soit favorable à ces derniers pris dans leur ensemble. \n",
      "L’assureur aurait intérêt à la mutualisation. Selon Florence \n",
      "Picard, de l’Institut des Actuaires, « plus il segmente fer-\n",
      "mement les groupes, plus il prend le risque de mettre fin à \n",
      "la mutualisation. Son but est que le risque soit maîtrisable: \n",
      "plus on segmente, plus on prend le risque de se tromper32  ».\n",
      "\n",
      "Entre limitation des mégafichiers \n",
      "et développement de l’intelligence \n",
      "artificielle : un équilibre à réinventer\n",
      "\n",
      "Le fonctionnement des algorithmes auxquels nous avons \n",
      "quotidiennement recours repose sur le traitement de nom-\n",
      "breuses données, dont une grande part de données person-\n",
      "nelles, traces numériques laissées par nos navigations en \n",
      "ligne, par l’utilisation de nos smartphones, de nos cartes \n",
      "de crédit, etc. La recherche d’une performance accrue des \n",
      "algorithmes est un facteur allant dans le sens d’une col-\n",
      "lecte croissante, d’un traitement et d’une conservation \n",
      "accrus de données à caractère personnel. \n",
      "\n",
      "On peut ainsi se demander si le développement de l’intelli-\n",
      "gence artificielle n’est pas susceptible, à un certain stade, \n",
      "d’entrer en tension avec les principes éthiques inscrits \n",
      "dans la législation depuis la loi Informatique et libertés. \n",
      "L’intelligence artificielle est grande consommatrice de don-\n",
      "nées ; elle a besoin d’une grande mémoire (autrement dit, \n",
      "de bases de données qu’elle va conserver sur une période \n",
      "aussi longue que possible). Les principes de la loi de 1978 \n",
      "renvoient, quant à eux, par le truchement du principe de \n",
      "finalité, à une minimisation de la collecte de données per-\n",
      "\n",
      "31  Antoinette Rouvroy déplace ainsi, en l’appliquant au domaine de l’assurance, le concept forgé par John Rawls pour établir une expérience de pensée destinée à envisager un \n",
      "\n",
      "problème moral. \n",
      "\n",
      "32  « Algorithmes et risques de discriminations dans le secteur de l’assurance », manifestation organisée par la Ligue des Droits de l’Homme le 15 septembre 2017.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "39\n",
      "\n",
      "sonnelles ainsi qu’à la limitation de la durée de conservation \n",
      "de ces données comme à des garanties nécessaires à la \n",
      "protection des personnes et de leurs libertés.\n",
      "\n",
      "Certes,  les  principes  de  la  loi  de  1978  (repris  dans  le \n",
      "Règlement  général  sur  la  protection  des  données,  qui \n",
      "entrera en application en mai 2018) constituent un équi-\n",
      "libre général, offrant une certaine souplesse à l’ensemble. \n",
      "Des mesures de sécurité renforcées peuvent dans une cer-\n",
      "taine mesure être considérées comme un contrepoids à \n",
      "une durée de conservation allongée des données. Il n’est \n",
      "pourtant pas certain que l’ampleur des transformations \n",
      "technologiques induites par le développement de l’intel-\n",
      "ligence artificielle ne remette pas en cause ce schéma.\n",
      "\n",
      "Par exemple, la médecine de précision semble lier ses \n",
      "progrès à la constitution de bases de données toujours \n",
      "plus larges, à la fois en termes de nombres d’individus \n",
      "concernés qu’en termes de nombre et de variété de données \n",
      "conservées sur chacun d’entre eux. L’épigénétique prétend \n",
      "ainsi croiser une approche par les données génétiques de \n",
      "l’individu à une approche prenant en compte les données \n",
      "environnementales, celles concernant le milieu, voire le \n",
      "mode de vie du « patient » (si tant est que cette notion ait \n",
      "encore un sens dans un contexte de plus en plus orienté \n",
      "vers la « prédiction »). La médecine de précision repose \n",
      "sur l’idée de profiler le plus finement possible ce dernier et \n",
      "la pathologie dont il est affecté afin de comparer ce profil \n",
      "\n",
      "à ceux d’autres individus au profil très proche, de façon \n",
      "à identifier le traitement le plus approprié à ce patient. \n",
      "À la limite, on pourrait aller jusqu’à considérer que l’objectif \n",
      "sanitaire poursuivi implique la constitution d’immenses \n",
      "bases de données. Or, rien n’indique où devrait s’arrêter la \n",
      "collecte de données : au dossier médical ? Au génome ? \n",
      "Aux données épigénétiques, c’est-à-dire environnementales \n",
      "(habitudes de vie, habitat, alimentation, etc.) ? En remontant \n",
      "à combien d’années ? Notons que ce type de problème \n",
      "n’est nullement propre à la médecine. Il se poserait sous un \n",
      "aspect proche dans le domaine de la sécurité, où l’impératif \n",
      "de repérage des suspects semble justifier une collecte de \n",
      "données toujours plus massives sur les individus.\n",
      "\n",
      "On voit bien que la question posée ici est celle de l’équi-\n",
      "libre à trouver entre protection des libertés (protection des \n",
      "données personnelles) et progrès médicaux. Il ne saurait \n",
      "être question d’y répondre ici, tant elle mériterait de faire \n",
      "l’objet d’une réflexion poussée. Celle-ci devrait d’ailleurs \n",
      "nécessairement  impliquer  une  évaluation  des  progrès \n",
      "effectivement à attendre de la médecine de précision. Ainsi \n",
      "Philippe Besse, professeur de mathématiques à l’Université \n",
      "de Toulouse, considère que les données mises à la dispo-\n",
      "sition de la recherche médicale dans le cadre du Système \n",
      "National des Données de Santé (SNDS) sont suffisantes \n",
      "pour accomplir des progrès que la complexité du vivant \n",
      "limitera de toute façon bien en-deçà de ce qu’annoncent \n",
      "certaines prophéties33. \n",
      "\n",
      "Qualité, quantité, pertinence : \n",
      "l’enjeu des données fournies à l’IA\n",
      "\n",
      "Les systèmes algorithmiques et l’intelligence artificielle \n",
      "reposent sur l’utilisation de données (personnelles ou non) \n",
      "qui leur sont fournies en entrée et qu’ils traitent pour pro-\n",
      "duire un résultat. Schématiquement, cette caractéristique \n",
      "soulève trois enjeux connexes mais distincts : celui de la \n",
      "qualité, celui de la quantité et celui de la pertinence des \n",
      "données fournies à ces systèmes.\n",
      "\n",
      "La question de la qualité des données utilisées par les \n",
      "algorithmes et l’IA est la plus simple. Il est facile de com-\n",
      "prendre que des données erronées ou tout simplement \n",
      "périmées impliqueront en bout de chaîne des erreurs ou \n",
      "des dysfonctionnements plus ou moins graves selon le \n",
      "domaine concerné, du simple envoi de publicités ciblées \n",
      "\n",
      "correspondant mal à mon profil réel jusqu’à une erreur de \n",
      "diagnostic médical. Assurer la qualité de la donnée entrante \n",
      "dans les systèmes algorithmiques et d’intelligence artifi-\n",
      "cielle constitue donc un enjeu appelé à prendre une impor-\n",
      "tance de plus en plus cruciale au fur et à mesure que ces \n",
      "machines vont être amenées à prendre une autonomie \n",
      "croissante. Or, assurer la qualité de la donnée est coûteux. \n",
      "La corruption des données peut être le résultat aussi bien \n",
      "d’un problème technique très matériel impliquant l’état \n",
      "des capteurs affectés à leurs collecte que d’un problème \n",
      "humain lié à l’intérêt de certains acteurs à biaiser les don-\n",
      "nées qu’ils sont chargés d’entrer dans le système. La tenta-\n",
      "tion de la négligence à cet égard doit être prise au sérieux, \n",
      "notamment dans des domaines où l’impact de données de \n",
      "\n",
      "33  Débat organisé par le Génotoul à Toulouse, le 24 juin 2017.\n",
      "\n",
      "\n",
      "40\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "mauvaise qualité pourrait n’être pas immédiatement sen-\n",
      "sible, comme dans le secteur du recrutement, par exemple. \n",
      "Les données des réseaux sociaux professionnels, parfois \n",
      "considérées comme une manne inépuisable, posent à cet \n",
      "égard des problèmes de fiabilité (liés à la tendance des \n",
      "individus à embellir leur CV ou au contraire à des absences \n",
      "de mise à jour). La confiance accordée par l’utilisateur au \n",
      "résultat produit par une machine jugée objective et plus \n",
      "performante que l’homme est un facteur supplémentaire \n",
      "pouvant favoriser la négligence.\n",
      "\n",
      "La quantité de données disponibles peut constituer un \n",
      "autre facteur néfaste à la qualité des résultats fournis par \n",
      "les systèmes algorithmiques et d’intelligence artificielle. \n",
      "Cathy O’Neil évoque ainsi l’exemple d’une collectivité ayant \n",
      "recouru aux États-Unis à un logiciel d’évaluation des ensei-\n",
      "gnants. L’utilisation de ce logiciel s’est notamment soldée \n",
      "par  le  licenciement  d’enseignants  dont  la  qualité  était \n",
      "pourtant de notoriété publique dans les communautés \n",
      "locales au sein desquelles ils évoluaient. L’une des raisons \n",
      "essentielles en est que l’algorithme utilisé pour évaluer la \n",
      "progression annuelle des élèves de chaque enseignant \n",
      "aurait besoin de bien plus que des données concernant \n",
      "tout au plus quelques dizaines d’élèves. Dans un cas où les \n",
      "variables susceptibles d’expliquer, à côté de la performance \n",
      "du professeur, les mauvais résultats d’un élève (difficultés \n",
      "relationnelles, problèmes familiaux, problèmes de santé, \n",
      "etc) sont si nombreuses, un nombre si limité de cas ne \n",
      "peut avoir aucune valeur statistique. La seule valeur de \n",
      "ce résultat est de donner le sentiment aux décideurs de \n",
      "prendre des décisions rationnelles, objectives et efficaces \n",
      "car s’autorisant du prestige de la machine.\n",
      "\n",
      "Cela ne signifie toutefois nullement que l’accumulation \n",
      "irréfléchie de données doive constituer un objectif en soi. \n",
      "Dans certains cas, en effet, la variété des données sera \n",
      "plus précieuse que leur simple quantité. Par exemple, les \n",
      "données de millions de véhicules suivant la même route \n",
      "seront moins utiles à l’algorithme d’une application GPS \n",
      "que des données en bien moins grand nombre de véhicules \n",
      "empruntant des itinéraires plus variés.\n",
      "\n",
      "Enfin, la question de la pertinence des données renvoie \n",
      "moins à la véracité de ces dernières qu’aux biais qui \n",
      "peuvent présider à leur collecte. Comme cela a été montré \n",
      "précédemment (Voir « Biais, discriminations et exclusion »), \n",
      "il peut être tout à fait exact que très peu de femmes aient \n",
      "mené à bien une carrière de haut niveau dans telle ou telle \n",
      "entreprise. En revanche, prendre ce résultat comme indi-\n",
      "catif de la capacité de femmes à accomplir à l’avenir de \n",
      "brillantes carrières dans cette même entreprise relève bien \n",
      "évidemment d’une approche biaisée. En l’occurrence, le jeu \n",
      "de données envisagé ici intègre des formes d’inégalités et/\n",
      "\n",
      "ou de discriminations. Ignorer ce type de biais reviendrait \n",
      "à perpétuer ou à laisser se perpétuer ces phénomènes. \n",
      "\n",
      "On voit à travers ces trois enjeux que les promesses des \n",
      "algorithmes ne peuvent être tenues qu’au prix d’une grande \n",
      "rigueur dans la collecte et le traitement des données utili-\n",
      "sées. Qu’une telle exigence de rigueur (et d’investissement \n",
      "matériel et humain) puisse ne pas être respectée par cer-\n",
      "tains acteurs représente un risque évident, alors même que \n",
      "les algorithmes sont souvent présentés comme sources \n",
      "d’une vérité « objective », « neutre ». Dans l’exemple de l’al-\n",
      "gorithme utilisé pour évaluer les professeurs aux États-Unis \n",
      "évoqué par Cathy O’Neil, la négligence méthodologique \n",
      "des concepteurs et promoteurs de l’algorithme a pour \n",
      "corollaire la confiance exagérée, dénuée d’esprit critique \n",
      "qu’accordent à ce dernier des utilisateurs dont l’attention \n",
      "se focalise sur la seule nécessité d’obtenir un quota de \n",
      "professeurs à éliminer du système. Pourtant, si assurer \n",
      "la qualité et la pertinence des données fournies aux algo-\n",
      "rithmes s’impose donc comme une exigence éthique, cette \n",
      "dernière constitue bien à terme une condition de l’utilité \n",
      "durable des algorithmes pour leurs utilisateurs et pour la \n",
      "société en général.\n",
      "\n",
      "ENQUÊTE\n",
      "\n",
      "La crainte devant les risques \n",
      "des algorithmes et de l’IA \n",
      "augmente avec l’âge*\n",
      "\n",
      "Les jeunes sont plus sensibles aux opportuni-\n",
      "tés portées par l’algorithme : 68,5 % des 18-24 \n",
      "ans  considèrent  que  les  opportunités  sur-\n",
      "passent les potentielles menaces. En revanche, \n",
      "seul 36 % des 55-64 ans estiment que les béné-\n",
      "fices sont plus importants que les risques.\n",
      "Certaines applications des algorithmes sont \n",
      "mieux acceptées chez les plus jeunes: 75 % des \n",
      "18-24 ans regardent favorablement des recom-\n",
      "mandations en vue d’achats en ligne (contre \n",
      "48 % pour l’ensemble du panel), 50 % en vue du \n",
      "choix de l’âme-sœur (contre 26 %).\n",
      "\n",
      "*  Enquête réalisée dans le cadre du débat public par \n",
      "l’association « Familles rurales », association fami-\n",
      "liale orientée vers les milieux ruraux, auprès de \n",
      "1076 de ses adhérents.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "41\n",
      "\n",
      "L’identité humaine au défi \n",
      "de l’intelligence artificielle\n",
      "\n",
      "L’autonomisation des machines, d’une part, l’hybridation \n",
      "croissante des humains avec la machine, d’autre part, \n",
      "questionnent l’idée d’une spécificité humaine irréductible. \n",
      "\n",
      "Des machines éthiques ? \n",
      "La première zone de porosité entre humains et machines \n",
      "s’établit autour de la question de l’idée de machine éthique. \n",
      "En effet, une façon radicale d’aborder les questions sou-\n",
      "levées  par  l’éventuelle  délégation  de  décisions  à  des \n",
      "machines autonomes (intelligence artificielle) est d’envi-\n",
      "sager que de rendre les machines « éthiques » serait une \n",
      "solution aux problèmes évoqués plus haut dans ce rapport. \n",
      "Une telle piste de réflexion est liée à la question de savoir \n",
      "s’il est même possible de formaliser une éthique34  afin de \n",
      "la programmer dans une machine. Autrement dit, peut-on \n",
      "automatiser l’éthique ? Ce problème est apparu au cours \n",
      "des débats comme l’un de ceux retenant particulièrement \n",
      "l’attention de la communauté des chercheurs en intelligence \n",
      "artificielle. Gilles Dowek (CERNA) l’a ainsi souligné lors de \n",
      "la journée d’étude organisée au Collège des Bernardins le \n",
      "20 septembre 2017.\n",
      "\n",
      "différents choix « éthiques » sont possibles. Dès lors que \n",
      "des dilemmes de ce type auraient été anticipés au stade \n",
      "du développement du système, il serait bien sûr possible \n",
      "de leur donner une réponse. Mais précisément, la spécifi-\n",
      "cité de l’éthique n’est-elle pas de concerner des situations \n",
      "inédites, impliquant éventuellement des conflits de valeurs \n",
      "dont la solution doit être élaborée par le sujet (pensons à \n",
      "Antigone, prise entre éthique familiale et éthique civique) ? \n",
      "N’est-elle pas de s’élaborer toujours en situation ? Dès lors \n",
      "l’hypothèse d’une formalisation de l’éthique n’est-elle pas \n",
      "quelque peu illusoire ? À tout le moins, elle implique une \n",
      "conception implicite de l’homme qui n’a rien d’évident. \n",
      "\n",
      "Retenons du moins que, pour l’heure, des expressions \n",
      "comme  «  éthique  des  algorithmes  »  ou  «  algorithmes \n",
      "éthiques » ne doivent pas être prises au pied de la lettre \n",
      "et comportent une part d’anthropomorphisme revenant à \n",
      "attribuer des capacités humaines à des machines. Certains \n",
      "considèrent qu’elles sont susceptibles de fausser un débat \n",
      "qui devrait se concentrer sur les exigences à l’égard des \n",
      "hommes qui conçoivent, entraînent, déploient et utilisent \n",
      "les systèmes algorithmiques et d’intelligence artificielle. \n",
      "\n",
      "Le fameux dilemme du tramway est très souvent évoqué à \n",
      "l’occasion de réflexions portant sur ce problème. On sait que \n",
      "ce dilemme met en scène un tramway sans freins dévalant \n",
      "une pente ; le tramway arrive devant un embranchement ; \n",
      "selon qu’il s’engage sur l’une ou l’autre des deux voies, \n",
      "il tuera une personne ou bien plusieurs. Dès lors, quelle \n",
      "devrait être la conduite d’une personne ayant la possibilité \n",
      "de manœuvrer l’aiguillage et donc de choisir, pour ainsi \n",
      "dire, l’un des deux scénarios possibles ? L’intérêt de cette \n",
      "expérience de pensée est qu’elle peut donner lieu à toute \n",
      "une gamme de variations : qu’en est-il si la personne seule \n",
      "attachée à l’une des deux voies se trouve être un proche \n",
      "parent ? Si les personnes sur l’autre voie se trouvent être \n",
      "5 ou bien 100 ? \n",
      "\n",
      "On voit aisément comment ce dilemme peut être adapté \n",
      "à l’hypothèse de voitures autonomes qui seraient mises \n",
      "en circulation prochainement : selon quels principes une \n",
      "voiture placée dans une situation de dilemme éthique de ce \n",
      "type devrait-elle « choisir » de se comporter ? Le dilemme \n",
      "du tramway a l’intérêt de mettre en évidence le fait que \n",
      "\n",
      "Elles ne constitueraient alors qu’une métaphore commode \n",
      "mais à ne pas entendre littéralement. À l’inverse, comme \n",
      "le rappelle par exemple Gilles Dowek, on peut considérer \n",
      "comme légitime le recours à ce type de métaphores dans \n",
      "la mesure où elles reviennent à prendre acte de l’autonomie \n",
      "croissante de ces systèmes et de la nécessité de formali-\n",
      "ser, autant que faire se peut, une éthique et de la program-\n",
      "mer dans des algorithmes. Quoi qu’il en soit, même si une \n",
      "éthique en tant que telle pouvait être encodée dans une \n",
      "machine (c’est-à-dire si cette dernière avait la possibilité \n",
      "de ne pas seulement répondre d’une certaine façon à une \n",
      "situation éthique envisagée à l’avance lors de son déve-\n",
      "loppement mais bien d’aborder des situations nouvelles \n",
      "en leur appliquant un raisonnement éthique), le choix du \n",
      "type d’éthique à encoder resterait bien, en dernière analyse, \n",
      "du ressort de l’homme. Le vrai enjeu est alors de s’assurer \n",
      "que les choix éthiques faits au stade du développement ne \n",
      "font pas l’objet d’une confiscation par « une petite caste de \n",
      "scribes » (Antoine Garapon). L’échelle de déploiement des \n",
      "algorithmes à l’heure du numérique en fait une question \n",
      "démocratique essentielle.\n",
      "\n",
      "34  C’est-à-dire une règle générale d’évaluation de la conduite à adopter face à toute situation – éthique déontique ou éthique conséquentialiste – ou un corpus de règles \n",
      "\n",
      "remplissant la même fonction – éthique kantienne, éthique bouddhiste, etc.\n",
      "\n",
      "\n",
      "42\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "LES ENJEUX ÉTHIQUES\n",
      "\n",
      "L’hybridation de l’homme et de la machine : \n",
      "repenser l’identité humaine ?\n",
      "\n",
      "Une  façon  d’envisager  la  question  éthique  appliquée \n",
      "aux algorithmes et à l’intelligence artificielle peut être de \n",
      "confronter ces derniers à l’affirmation – présente à l’article \n",
      "premier de la loi Informatique et libertés – selon laquelle \n",
      "l’informatique  «  ne  doit  pas  porter  atteinte  à  l’identité \n",
      "humaine ».\n",
      "\n",
      "Les pages précédentes ont abordé des problèmes liés à \n",
      "la façon dont l’homme agence son action avec des arte-\n",
      "facts, question ancienne mais renouvelée par l’émergence \n",
      "d’artefacts dotés d’une « autonomie » croissante à l’heure \n",
      "des algorithmes et de l’intelligence artificielle35. Ces propos \n",
      "soulignent en effet que le développement de ces technolo-\n",
      "gies, selon la manière dont il s’opérera, peut affecter l’une \n",
      "des composantes de l’identité et de la dignité humaines, \n",
      "à savoir sa liberté et sa responsabilité. La montée en puis-\n",
      "sance d’une forme d’ « autonomie » machinique doit bien \n",
      "sûr être fortement nuancée. Gérard Berry, professeur au \n",
      "Collège de France et titulaire de la chaire « Algorithmes, \n",
      "machines et langages » rappelle ainsi : « un jour, nous dit-on, \n",
      "les machines parleront et seront autonomes, le numérique \n",
      "donnera naissance à une nouvelle forme de vie. La date pour \n",
      "l’autonomie des machines et leur capacité de parole créa-\n",
      "tive, personne ne la donne, et je ne la connais pas, loin de \n",
      "là. Surtout, de quelle vie parlons-nous ?36 ». Néanmoins, on \n",
      "pourrait se demander si la trajectoire technologique d’ores \n",
      "et déjà à l’œuvre ne devra pas conduire à questionner la \n",
      "pertinence de la notion même d’ « identité humaine », dans \n",
      "la mesure où celle-ci implique une séparation étanche entre \n",
      "humain et non-humain. La question du « droit des robots » \n",
      "d’ores et déjà soulevée par des juristes et récemment exa-\n",
      "minée par le Parlement européen (rapport Delvaux) a pour \n",
      "horizon ce brouillage possible des frontières de l’humain. À \n",
      "de tels arguments post-humanistes, la tradition humaniste \n",
      "pourrait certes rétorquer que l’autonomie machinique n’est \n",
      "\n",
      "Le développement de \n",
      "\n",
      "ces technologies peut affecter \n",
      "\n",
      "l’une des composantes de l’identité \n",
      "et de la dignité humaines, à savoir \n",
      "\n",
      "sa liberté et sa responsabilité\n",
      "\n",
      "aujourd’hui qu’un leurre, une métaphore destinée à styliser \n",
      "un objet complexe et masquant finalement une respon-\n",
      "sabilité et une action humaines certes diluées, éclatées, \n",
      "mais bien réelles.\n",
      "\n",
      "Si une première hybridation entre l’homme et la machine \n",
      "s’opère au plan de l’action, la réflexion devra aussi néces-\n",
      "sairement s’élargir à l’avenir pour prendre en compte l’hy-\n",
      "bridation physique parfois annoncée entre algorithmes, \n",
      "humains, voire animaux (avec l’adjonction d’implants intel-\n",
      "ligents et communicants). Cette hybridation physique est \n",
      "une étape supplémentaire de l’évolution déjà à l’œuvre dans \n",
      "l’interaction permanente qui nous lie d’ores et déjà à une \n",
      "foule de processus algorithmiques.\n",
      "\n",
      "Enfin, ce thème d’une subversion éventuelle de la frontière \n",
      "entre l’homme et les choses (ou plutôt, entre l’homme et la \n",
      "machine) trouve déjà une réalité extrêmement concrète au \n",
      "plan phénoménologique dans certaines tentatives récentes \n",
      "d’applications de la robotique qui s’illustrent d’abord dans \n",
      "la forme humaine donnée aux robots. On pense ici au robot \n",
      "Pepper de la firme Aldebaran, destiné à être déployé dans \n",
      "des espaces commerciaux pour interagir avec les clients. \n",
      "Surtout, et ceci concerne directement le sujet des algo-\n",
      "rithmes et de l’intelligence artificielle, tout un champ de \n",
      "recherche vise à créer des robots empathiques capables \n",
      "de percevoir les émotions des humains (par l’analyse du \n",
      "visage, de la voix, etc.) de façon à s’adapter à leur interlo-\n",
      "cuteur. La première question posée par ces recherches \n",
      "est évidemment celle de la limite entre, d’une part, les \n",
      "apports bénéfiques d’une intelligence artificielle capable \n",
      "de comprendre et de s’adapter aux états émotionnels de ses \n",
      "interlocuteurs et, d’autre part, une forme de manipulation \n",
      "appuyée sur une ingénierie technique capable d’exploiter les \n",
      "vulnérabilités affectives des personnes37. La seconde ques-\n",
      "tion, connexe à la première, est celle de savoir dans quelle \n",
      "mesure la capacité d’illusion propre à ces technologies et \n",
      "l’asymétrie qui existera entre ces robots et les personnes \n",
      "dont ils analyseront les émotions les rendent moralement \n",
      "acceptables ? Sherry Turckle, professeure au MIT, souligne \n",
      "ainsi que les êtres humains ont une grande propension à \n",
      "attribuer aux robots une subjectivité et une sensibilité38. \n",
      "Or, la tentation est forte pour des sociétés vieillissantes de \n",
      "confier de plus en plus le soin des personnes âgées à ce \n",
      "type de robots. En France, Serge Tisseron développe une \n",
      "réflexion critique sur ces technologies39 . Quelles que soient \n",
      "les réponses apportées à ces questions, il semble essentiel \n",
      "qu’elles n’occultent nullement la dimension politique et de \n",
      "choix de société que recèle le fait de recourir aux robots plu-\n",
      "tôt que d’investir dans d’autres types de ressources (temps, \n",
      "ressources en personnel, etc.) pour l’accompagnement des \n",
      "membres vulnérables de nos sociétés.\n",
      "\n",
      "35  La question de l’hybridation entre l’homme et des artefacts n’est pas nouvelle : les algorithmes participent au modelage de notre identité de la même façon que – \n",
      "\n",
      "Socrate le remarquait déjà dans le Phèdre de Platon – l’écriture affecte notre capacité de mémorisation et constitue un artefact muet, incapable de la moindre explication. \n",
      "Que l’idée d’une « identité humaine » strictement distincte des objets soit remise en cause n’implique ainsi pas nécessairement une nouveauté radicale.\n",
      "\n",
      "36 Gérard Berry, « Non, l’intelligence artificielle ne menace pas l’humanité ! », interview donnée au Point, 18 mai 2015. \n",
      "37  Une problématique très similaire à celle soulevée par les logiciels de communication politique censés adapter le message du candidat aux attentes de chaque individu ciblé \n",
      "\n",
      "et profilé.\n",
      "\n",
      "38  Sherry Turckle, Seuls ensemble, Paris, L’Echappée, 2015 [2012].\n",
      "39  Serge Tisseron, Le Jour où mon robot m’aimera. Vers l’empathie artificielle, Paris, 2015.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "43\n",
      "\n",
      "ENQUÊTE\n",
      "\n",
      "Algorithmes et IA : un objet mal connu des Français\n",
      "Un sondage mené par l’IFOP pour la CNIL en janvier 2017 (auprès d’un échantillon de 1001 personnes, \n",
      "représentatif de la population française âgée de 18 ans et plus) a permis d’estimer le niveau de notoriété \n",
      "des algorithmes au sein de la population française.\n",
      "\n",
      "83 %\n",
      "\n",
      "des Français \n",
      "ont déjà entendu\n",
      "parler des\n",
      "algorithmes\n",
      "\n",
      "Les algorithmes sont présents dans l’esprit des Français mais de façon assez confuse. \n",
      "Si 83 % des Français ont déjà entendu parler des algorithmes, ils sont plus de la moitié \n",
      "à ne pas savoir précisément de quoi il s’agit (52 %). Leur présence est déjà appréhendée \n",
      "comme massive dans la vie de tous les jours par 80 % des Français qui considèrent, à \n",
      "65%, que cette dynamique va encore s’accentuer dans les années qui viennent.\n",
      "\n",
      "Quelles réponses ?\n",
      "\n",
      "De la réflexion éthique à la régulation des algorithmes\n",
      "\n",
      "P.43\n",
      "\n",
      "Ce que la loi dit déjà sur les algorithmes et l’intelligence artificielle\n",
      "\n",
      "P.45\n",
      "\n",
      "Les limites de l’encadrement juridique actuel \n",
      "\n",
      "P.46\n",
      "\n",
      "Faut-il interdire les algorithmes et l’intelligence artificielle dans certains secteurs ?\n",
      "\n",
      "P.47\n",
      "\n",
      "Deux principes fondateurs pour le développement des algorithmes \n",
      "\n",
      "et de l’intelligence artificielle : loyauté et vigilance\n",
      "\n",
      "P.48\n",
      "\n",
      "Des principes d’ingénierie : intelligibilité, responsabilité, intervention humaine\n",
      "\n",
      "P.51\n",
      "\n",
      "Des principes aux recommandations pratiques\n",
      "\n",
      "P.53\n",
      "\n",
      "\n",
      "44\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "Quelles réponses ?\n",
      "\n",
      "De la réflexion éthique à la régulation \n",
      "des algorithmes\n",
      "\n",
      "Faut-il réguler les algorithmes ? \n",
      "\n",
      "La question se trouve depuis quelques mois fréquemment \n",
      "évoquée aussi bien dans la presse généraliste que parmi \n",
      "les experts du numérique et des politiques publiques. \n",
      "Elle ne constitue que le prolongement de la question de \n",
      "la régulation du numérique lui-même. On le sait, l’univers \n",
      "numérique s’est constitué en partie en opposition à l’idée \n",
      "même de normes, du moins de normes juridiques. De la \n",
      "contre-culture américaine des années 1960 à la mise en \n",
      "avant par les entreprises numériques de la nécessité de \n",
      "ne pas entraver l’innovation par un système de normes \n",
      "inadaptées à un univers fondamentalement nouveau, cette \n",
      "méfiance à l’égard de la régulation trace comme un fil rouge. \n",
      "Ce courant de pensée a trouvé une de ses manifestations \n",
      "les plus claires dans la fameuse Déclaration d’indépendance \n",
      "du cyberespace de John Perry Barlow en 1996. Il se heurte \n",
      "depuis de nombreuses années aux efforts déployés par \n",
      "les acteurs étatiques pour soumettre l’univers numérique \n",
      "au droit commun, parfois de manière mécanique, parfois \n",
      "en mettant en œuvre de véritables innovations juridiques. \n",
      "\n",
      "De nombreux acteurs expriment aujourd’hui l’idée qu’il ne \n",
      "faudrait pas réguler les algorithmes et l’intelligence artifi-\n",
      "cielle. Ces derniers soulignent en effet qu’il serait trop tôt \n",
      "pour imposer des règles qui s’avéreraient nécessairement \n",
      "inadaptées et vouées à être rendues rapidement caduques \n",
      "par des évolutions techniques progressant désormais à un \n",
      "rythme incommensurable à celui de l’invention juridique. \n",
      "\n",
      "Une telle position néglige à vrai dire une réalité juridique \n",
      "aussi massive que parfois inaperçue : les algorithmes et \n",
      "leurs usages se trouvent d’ores et déjà encadrés, direc-\n",
      "tement ou indirectement, par de nombreuses règles juri-\n",
      "diques. Il est vrai que ces règles, comme on le verra, se \n",
      "trouvent en fait dispersées dans divers lois et codes, à la \n",
      "mesure de la transversalité du numérique. \n",
      "\n",
      "Par ailleurs, des sondages effectués à l’occasion du débat \n",
      "public initié par la CNIL ont mis en évidence une attente de \n",
      "règles et de limites en matière d’algorithmes et d’intelligence \n",
      "artificielle. Ces règles et ces limites peuvent être conçues \n",
      "autrement que comme des normes contraignantes, par \n",
      "exemple sous la forme de « chartes » adoptées par une \n",
      "entreprise, par une profession, par une branche. C’est ce \n",
      "que montre par exemple le sondage réalisé par la CFE-CGC \n",
      "auprès de 1263 de ses adhérents40. \n",
      "\n",
      "La création par le Parlement d’une mission de réflexion \n",
      "confiée à la CNIL sur les enjeux éthiques et de société \n",
      "soulevés par l’évolution des technologies numériques s’ins-\n",
      "crit dans ce contexte. Elle traduit évidemment un souci de \n",
      "réflexion sur les limites, sur les normes – quelle que soit \n",
      "la nature de ces dernières – à imposer à des nouveautés \n",
      "techniques. Elle traduit tout autant une volonté de la part \n",
      "de la puissance publique de ne pas céder à la tentation \n",
      "de réguler trop vite et de manière inadaptée. À cet égard, \n",
      "considérer que l’émergence et la diffusion de technologies \n",
      "nouvelles implique une réflexion sur ses limites ne signifie \n",
      "nullement que la loi soit systématiquement la forme adap-\n",
      "tée à l’imposition de ces limites. C’est en tout cas ce qu’a \n",
      "considéré la CNIL en souhaitant ouvrir la réflexion de la façon \n",
      "la plus large possible, non seulement aux acteurs publics \n",
      "mais aussi aux praticiens, professionnels et grand public.\n",
      "\n",
      "Formuler des recommandations impliquait donc d’abord \n",
      "d’explorer  les  grands  développements  des  innovations \n",
      "considérées et les enjeux éthiques et de société soulevés \n",
      "par ceux-ci. Les pages précédentes y ont été consacrées. \n",
      "Les pages suivantes viseront à faire le point sur les grands \n",
      "principes susceptibles de répondre à ces enjeux ainsi que sur \n",
      "les recommandations concrètes envisageables aujourd’hui.\n",
      "\n",
      "40  À la question « La définition d’une charte éthique autour de l’usage des algorithmes dans le recrutement et la gestion RH vous semble-t-elle une priorité ? », 92% ont répondu \n",
      "\n",
      "positivement.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "45\n",
      "\n",
      "Ce que la loi dit déjà sur les algorithmes \n",
      "et l’intelligence artificielle\n",
      "\n",
      "Tous les défis identifiés dans le présent rapport ne sont \n",
      "pas nouveaux. \n",
      "\n",
      "droits de l’homme, ni à la vie privée, ni aux libertés indivi-\n",
      "duelles ou publiques ». \n",
      "\n",
      "La Commission Tricot, dont le rapport a constitué la base \n",
      "de la loi de 1978 sur la protection des données à caractère \n",
      "personnel, en avait déjà identifié certains à l’issue d’une \n",
      "réflexion qui, au-delà du traitement des données, portait \n",
      "sur les défis soulevés par l’informatisation de l’État et de la \n",
      "société française. Le risque de discrimination ou d’exclusion \n",
      "des personnes mais également le risque d’une confiance \n",
      "excessive accordée à l’ordinateur étaient d’emblée claire-\n",
      "ment identifiés, à côté des enjeux directement liés à la \n",
      "capacité de collecter et de stocker de grandes quantités \n",
      "de données. Les débats portant sur la nécessité ou non \n",
      "de « réguler les algorithmes » ignorent en fait purement et \n",
      "simplement le fait que les algorithmes sont encadrés par \n",
      "la loi (loi Informatique et Libertés, notamment, mais pas \n",
      "seulement) depuis une quarantaine d’années. \n",
      "\n",
      "Les débats portant sur \n",
      "la nécessité ou non de \n",
      "\n",
      "« réguler les algorithmes » \n",
      "\n",
      "ignorent le fait que les \n",
      "\n",
      "algorithmes sont encadrés \n",
      "\n",
      "par la loi depuis \n",
      "\n",
      "une quarantaine d’années\n",
      "\n",
      "Aboutissement du travail de la Commission Tricot, la loi \n",
      "Informatique et Libertés de 1978 contient en effet un certain \n",
      "nombre de dispositions que l’on peut, de façon schéma-\n",
      "tique, rattacher à trois principes, eux-mêmes abrités sous \n",
      "un principe général contenu dans l’article 1 : « l’informatique \n",
      "doit être au service de chaque citoyen. Son développement \n",
      "doit s’opérer dans le cadre de la coopération internationale. \n",
      "Elle ne doit porter atteinte ni à l’identité humaine, ni aux \n",
      "\n",
      "Ces trois principes se trouvent relayés dans le Règlement \n",
      "européen  sur  la  protection  des  données  personnelles \n",
      "(RGPD) entrant en vigueur en mai 2018. Ils sont les sui-\n",
      "vants :\n",
      "\n",
      "Premièrement, la loi encadre l’utilisation des données per-\n",
      "sonnelles nécessaires au fonctionnement des algorithmes, \n",
      "au-delà même du traitement algorithmique à proprement \n",
      "parler. Autrement dit, elle encadre les conditions de collecte \n",
      "et de conservation des données41, ainsi que l’exercice de \n",
      "leurs droits par les personnes (droit à l’information, droit \n",
      "d’opposition, droit d’accès, droit de rectification) afin de \n",
      "protéger leur vie privée et leurs libertés.\n",
      "\n",
      "Deuxièmement, la loi Informatique et Libertés interdit \n",
      "qu’une machine puisse prendre seule (sans intervention \n",
      "humaine) des décisions emportant des conséquences \n",
      "cruciales pour les personnes (décision judiciaire, décision \n",
      "d’octroi de crédit, par exemple)42.\n",
      "\n",
      "Troisièmement, la loi prévoit le droit pour les personnes \n",
      "d’obtenir, auprès de celui qui en responsable, des informa-\n",
      "tions sur la logique de fonctionnement de l’algorithme43.\n",
      "\n",
      "Au-delà de la loi Informatique et Libertés, d’autres disposi-\n",
      "tions légales plus anciennes constituent de fait un cadre \n",
      "et une série de limites à l’utilisation des algorithmes dans \n",
      "certains secteurs, dans la mesure même où ils régulent \n",
      "ces secteurs44. La question de la collusion algorithmique \n",
      "qui se pose aujourd’hui aux régulateurs de la concurrence, \n",
      "par exemple, ne se pose pas dans un vide juridique : elle a \n",
      "plutôt trait à l’effectivité de la règle de droit et à la néces-\n",
      "sité d’inventer de nouveaux moyens de prouver l’existence \n",
      "d’ententes illégales45.\n",
      "\n",
      "Les dispositions juridiques interdisant différentes formes \n",
      "de discrimination, élaborées dans le sillage de l’article 7 \n",
      "de la Déclaration universelle des droits de l’homme, s’ap-\n",
      "pliquent naturellement aux algorithmes46.\n",
      "\n",
      "41  Principes de finalité, de proportionnalité, de sécurité, de limitation de la durée de conservation des données.\n",
      "42  Article 10 de la loi de 1978. Article 22 du RGPD.\n",
      "43  Article 39 de la loi de 1978. L’article 15.1 (h) du Règlement européen sur la protection des données personnelles (RGPD) prévoit que la personne peut obtenir du responsable \n",
      "\n",
      "de traitement des informations concernant “the existence of automated decision making including profiling referred to in Article 20(1) and (3) and at least in those cases, \n",
      "meaningful information about the logic involved, as well as the significance and the envisaged consequences of such processing for the data subject”. Les limites juridiques \n",
      "posées par le RGPD portent notamment sur « le profilage » (pas de décision basée uniquement sur un traitement sauf exceptions).\n",
      "\n",
      "44  On pourrait envisager, en forçant un peu le raisonnement, l’application du code de la santé publique (qui réprime l’exercice illégal de la médecine par toute personne non \n",
      "\n",
      "titulaire d’un diplôme) à des dispositifs d’intelligence artificielle dans le domaine médical. On pourrait imaginer qu’une telle disposition aussi puisse fonder l’interdiction de \n",
      "l’établissement d’un diagnostic par un algorithme seul. L’origine de cette législation, au début du XIXe siècle, renvoie à la préoccupation des autorités de lutter contre le  \n",
      "« charlatanisme ». Les critiques des promesses excessives portées par certaines entreprises y verront sans doute un écho plaisant à la situation actuelle.\n",
      "\n",
      "45  http://internetactu.blog.lemonde.fr/2017/02/11/comment-prouver-les-pratiques-anticoncurrentielles-a-lheure-de-leur-optimisation-algorithmique/ \n",
      "46  « Tous sont égaux devant la loi et ont droit sans distinction à une égale protection de la loi. Tous ont droit à une protection égale contre toute discrimination qui violerait la \n",
      "\n",
      "présente Déclaration et contre toute provocation à une telle discrimination ».\n",
      "\n",
      "\n",
      "46\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "Les limites de l’encadrement juridique actuel\n",
      "\n",
      "Un  certain  nombre  des  enjeux  soulevés  par  les  algo-\n",
      "rithmes constituent cependant à ce jour un angle mort du \n",
      "droit et des différentes dispositions juridiques évoquées \n",
      "précédemment.\n",
      "\n",
      "Focalisation sur les algorithmes traitant \n",
      "des données personnelles et absence  \n",
      "de prise en compte des effets collectifs \n",
      "des algorithmes\n",
      "\n",
      "En premier lieu ces dispositions ne concernent les algo-\n",
      "rithmes que dans la mesure où ils utilisent pour fonctionner \n",
      "des données à caractère personnel et où leurs résultats \n",
      "s’appliquent directement à des personnes. C’est notamment \n",
      "le cas de la loi Informatique et libertés, la seule parmi celles \n",
      "évoquées qui vise directement les algorithmes (mentionnés \n",
      "comme « traitement automatisés de données à caractère \n",
      "personnel »). Or, bien des algorithmes n’utilisent pas de \n",
      "données à caractère personnel. C’est par exemple le cas \n",
      "des algorithmes boursiers. Les impacts de ces algorithmes \n",
      "traitant des données non personnelles sont tout aussi sus-\n",
      "ceptibles que les autres de soulever des questions. Si les \n",
      "algorithmes boursiers relèvent d’un secteur par ailleurs \n",
      "fortement encadré, d’autres exemples peuvent permettre \n",
      "de comprendre les impacts que peuvent avoir des algo-\n",
      "rithmes ne traitant pas des données à caractère person-\n",
      "nel. Celui, déjà évoqué au début de ce rapport (Voir « Une \n",
      "question d’échelle : la délégation massive de décisions non \n",
      "critiques »), de l’algorithme imaginé par Cathy O’Neil pour \n",
      "composer les repas de ses enfants lui permet de mettre \n",
      "en lumière les enjeux spécifiques liés à l’échelle de l’impact \n",
      "des algorithmes exécutés par des systèmes informatiques. \n",
      "On pourrait imaginer également un algorithme établissant \n",
      "les menus des cantines scolaires selon certains critères \n",
      "(optimisation du coût des denrées, qualité nutritionnelle, \n",
      "etc.) et qui pourrait être utilisé à l’échelle d’un pays. Un tel \n",
      "algorithme, sans traiter de données personnelles, serait \n",
      "susceptible d’avoir des impacts sociaux et économiques \n",
      "du fait même de son échelle de déploiement. Or, la loi n’a \n",
      "jusqu’ici pas pris en compte cette dimension nouvelle.\n",
      "\n",
      "En second lieu, les dispositions légales évoquées pré-\n",
      "cédemment concernent les effets des algorithmes sur \n",
      "les personnes, dans une perspective individualiste. En \n",
      "revanche, elles ne visent pas directement leurs effets \n",
      "\n",
      "sur  des  collectifs.  Nous  pensons  ici  par  exemple  aux \n",
      "impacts des algorithmes utilisés à des fins de marketing \n",
      "électoral sur le fonctionnement démocratique même (Voir : \n",
      "« Atomisation de la communauté politique »). Si l’on peut \n",
      "considérer que la loi Informatique et libertés constitue de \n",
      "fait un facteur limitant de tels impacts47, ce n’est cependant \n",
      "que de manière indirecte, sans que ce soit son objectif \n",
      "premier.\n",
      "\n",
      "Les limites de l’effectivité du droit\n",
      "\n",
      "Un autre type de limites de l’encadrement des algorithmes \n",
      "et de l’IA identifiable dans les dispositions juridiques évo-\n",
      "quées a trait à l’effectivité même de ces dernières et des \n",
      "principes qu’elles ont vocation à mettre en œuvre. Dans \n",
      "un univers numérique caractérisé par une fluidité et une \n",
      "omniprésence  des  capteurs  rendant  difficile  l’exercice \n",
      "des droits ainsi que par une forte asymétrie entre ceux \n",
      "qui contrôlent algorithmes et données et les personnes, ces \n",
      "dernières rencontrent des difficultés à exercer leurs droits \n",
      "(par exemple, le droit d’obtenir une intervention humaine \n",
      "dans le cadre d’une décision prise sur le fondement d’un \n",
      "traitement algorithmique, ou encore le droit d’obtenir une \n",
      "information sur la logique sous-tendant le fonctionnement \n",
      "de l’algorithme). \n",
      "\n",
      "La prise en compte de cette réalité s’est traduite par une \n",
      "série de réflexions récentes, dont certaines se sont tra-\n",
      "duites dans de nouvelles dispositions légales. Le Règlement \n",
      "européen sur la protection des données à caractère per-\n",
      "sonnel (entrée en application en mai 2018) apporte plu-\n",
      "sieurs réponses à cette question de l’effectivité du droit \n",
      "dans l’univers numérique, y compris en ce qui concerne \n",
      "les algorithmes48. Par ailleurs, la loi pour une République \n",
      "numérique (adoptée en octobre 2016) s’est inscrite dans \n",
      "cette même perspective de renforcement de l’effectivité \n",
      "de principes préexistants. \n",
      "D’une  part,  elle  a  renforcé  l’obligation  faite  à  ceux  qui \n",
      "déploient des algorithmes d’en informer les personnes \n",
      "concernées. D’autre part, elle prévoit que les codes sources \n",
      "des algorithmes utilisés par l’administration sont des docu-\n",
      "ments communicables, approfondissant ainsi (à l’exception \n",
      "notable du secteur privé) le droit d’obtenir des informations \n",
      "sur la logique mise en œuvre par un algorithme présent \n",
      "dans la loi de 1978. \n",
      "\n",
      "47  La loi Informatique et libertés limite conditionne notamment au consentement des personnes l’enrichissement de profils individuels par des données collectées sur les réseaux \n",
      "\n",
      "sociaux.\n",
      "\n",
      "48  L’article 14.1a du Règlement européen, par exemple, renforce le droit à l’information, en prévoyant une information claire et intelligible fournie spontanément par le responsable \n",
      "\n",
      "du traitement algorithmique.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "47\n",
      "\n",
      "Faut-il interdire les algorithmes \n",
      "et l’intelligence artificielle dans \n",
      "certains secteurs ?\n",
      "\n",
      "La question de savoir s’il faut interdire les algorithmes et \n",
      "l’intelligence artificielle dans certains secteurs ou pour \n",
      "certains usages ne saurait être éludée d’une réflexion sur \n",
      "les enjeux éthiques soulevés par ces technologies. Rand \n",
      "Hindi évoquait ainsi lors de l’événement de lancement du \n",
      "débat organisé à la CNIL le 23 janvier 2017 la question de \n",
      "savoir s’il faudrait refuser d’automatiser certains métiers \n",
      "pour des raisons éthiques.\n",
      "\n",
      "Le caractère particulièrement sensible d’un certain nombre \n",
      "de secteurs et des décisions qui y sont prises les désigne \n",
      "assez logiquement comme étant ceux où la question de \n",
      "telles interdictions pourrait se poser. Ainsi, le secteur mili-\n",
      "taire a récemment fait l’objet d’une pétition internationale \n",
      "demandant que soient bannies les armes autonomes. La \n",
      "médecine ou la justice constituent d’autres domaines où \n",
      "la question pourrait être posée. Certes, comme cela a été \n",
      "rappelé, la législation prévoit d’ores et déjà que le diagnostic \n",
      "du médecin ou la décision du juge ne puissent faire l’objet \n",
      "d’une automatisation. Devant le caractère toujours incer-\n",
      "tain de la frontière entre délégation et aide à la décision, \n",
      "la question d’un rappel solennel de ces principes pourrait \n",
      "être posée.\n",
      "\n",
      "Certains secteurs à la sensibilité moins immédiatement \n",
      "évidente font également l’objet de demandes d’interdiction. \n",
      "Ainsi, Serge Tisseron a récemment pris position contre le \n",
      "ciblage personnalisé dans le domaine publicitaire et culturel, \n",
      "accusé de « condamner chaque spectateur à tourner en \n",
      "rond dans ce qu’il connaît de ses goûts et ce qu’il ignore \n",
      "de ses a priori » et de contribuer à « réduire les données \n",
      "dont la majorité des humains disposent pour se faire une \n",
      "opinion sur le monde49».\n",
      "\n",
      "Enfin, l’interdiction appliquée à tel ou tel usage des algo-\n",
      "rithmes pourrait porter sur les données utilisées, à l’image \n",
      "du moratoire mis en place par les assureurs français dès \n",
      "1994 sur le recours aux données génétiques, relayé en 2002 \n",
      "par la loi Kouchner. Dans ce même secteur, une limitation \n",
      "du recours aux données ne serait-il pas une solution pos-\n",
      "sible (légale ou mise en place par les acteurs eux-mêmes) \n",
      "pour maintenir le « voile d’ignorance indispensable » à la \n",
      "pérennité de la mutualisation du risque ?\n",
      "\n",
      "LE REGARD DU CITOYEN\n",
      "\n",
      "Les participants à la concertation citoyenne \n",
      "organisée  par  la  CNIL  à  Montpellier  le  14 \n",
      "octobre 2017 (voir « L’organisation du débat \n",
      "public sur les enjeux éthiques des algorithmes \n",
      "et de l’intelligence artificielle ») ont identifié \n",
      "un certain nombre d’enjeux éthiques soulevés \n",
      "par les algorithmes et l’intelligence artificielle. \n",
      "Si leur positionnement révèle des inquiétudes \n",
      "et une conscience des risques, leur attitude \n",
      "générale ne traduit guère d’hostilité de prin-\n",
      "cipe à ce que des algorithmes et des outils d’in-\n",
      "telligence artificielle se déploient dans notre \n",
      "quotidien, sous réserve que des réponses soient \n",
      "apportées.\n",
      "Parmi  les  avantages  mentionnés  dans  les \n",
      "différents ateliers de la journée de concerta-\n",
      "tion, figurent la personnalisation du diagnos-\n",
      "tic médical, la fluidification de processus de \n",
      "recrutement qui deviendraient plus neutres, la \n",
      "simplification de la répartition des étudiants \n",
      "par rapport à l’offre de formation (APB) ou \n",
      "encore l’utilité des filtres sur les plateformes en \n",
      "ligne pour gérer « la multitude d’informations ». \n",
      "Beaucoup voient positivement les capacités \n",
      "nouvelles d’analyse des données : 63% consi-\n",
      "dèrent ainsi utile de « partager les données \n",
      "pour le bien commun ».\n",
      "La montée en compétence des participants au \n",
      "cours de la journée de concertation se traduit \n",
      "par un certain accroissement de la conscience \n",
      "des risques : 32% des participants les consi-\n",
      "déraient comme « plutôt source d’erreur » à \n",
      "l’issue de la journée alors qu’ils n’étaient que \n",
      "23% ex-ante. Une évolution certes modérée à \n",
      "l’issue d’une journée consacrée aux enjeux \n",
      "éthiques mais qui s’accompagne aussi d’une \n",
      "forme de scepticisme quant à la possibilité d’un \n",
      "encadrement effectif des algorithmes : « est-ce \n",
      "que la loi sera suffisante pour tout contrôler ? \n",
      "Ne sera-t-on pas toujours dans la correction \n",
      "après dérive ? ».\n",
      "\n",
      "49 http://www.huffingtonpost.fr/serge-tisseron/les-publicites-ciblees-cest-la-betise-assuree-interdisons-les_a_23220999/ \n",
      "\n",
      "\n",
      "48\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "Deux principes fondateurs pour le \n",
      "développement des algorithmes et de \n",
      "l’intelligence artificielle : loyauté et vigilance\n",
      "\n",
      "La réflexion sur les enjeux éthiques soulevés par les algo-\n",
      "rithmes et l’IA a pour horizon deux dimensions distinctes \n",
      "mais articulées : les principes et les moyens concrets de \n",
      "rendre ceux-ci effectifs.\n",
      "\n",
      "Le législateur avait inscrit à l’article 1 de la loi Informatique \n",
      "et Libertés que « l’informatique doit être au service de \n",
      "chaque citoyen ». Il s’agit aujourd’hui d’établir les principes \n",
      "permettant d’atteindre cet objectif général et de garantir \n",
      "que l’intelligence artificielle soit au service de l’homme, \n",
      "qu’elle l’augmente plutôt que de prétendre le supplanter.\n",
      "\n",
      "Les principes inscrits dans la loi Informatique et Libertés \n",
      "et que l’on a rappelés précédemment correspondent-ils \n",
      "toujours aux enjeux qui ont été identifiés et à cet objectif \n",
      "général ? Faut-il en promouvoir de nouveaux ? Outre le \n",
      "constat que ces principes ne couvrent pas la totalité du \n",
      "champ des algorithmes et de l’IA, la circulation dans le \n",
      "débat public d’une série de notions représentant autant \n",
      "d’exigences à l’égard des algorithmes (loyauté, redevabilité, \n",
      "intelligibilité, explicabilité, transparence, etc.) signale à l’évi-\n",
      "dence le sentiment d’une inadéquation, voire d’inquiétudes.\n",
      "\n",
      "Au terme du débat public, sont ici présentés une série de \n",
      "principes. Parmi ces derniers, deux en particulier, celui de \n",
      "loyauté et celui de vigilance, apparaissent comme tout par-\n",
      "ticulièrement fondateurs.\n",
      "\n",
      "Le principe de loyauté\n",
      "\n",
      "Un principe formulé par le Conseil d’État\n",
      "Dans son étude annuelle de 2014 sur le numérique et les \n",
      "droits fondamentaux, le Conseil d’État a ainsi formulé \n",
      "trois recommandations invitant à « repenser les principes \n",
      "fondant la protection des droits fondamentaux ». Parmi \n",
      "celles-ci, la première portait sur un principe d’ « autodé-\n",
      "termination informationnelle » garantissant la maîtrise de \n",
      "l’individu sur la communication et l’utilisation de ses don-\n",
      "nées personnelles et depuis introduit dans la loi pour une \n",
      "République numérique. La troisième portait, elle, sur le prin-\n",
      "cipe de « loyauté », appliqué non pas à tous les algorithmes \n",
      "mais, de manière plus restreinte, aux « plateformes50 ». \n",
      "Selon le Conseil d’État, « la loyauté consiste à assurer de \n",
      "\n",
      "bonne foi le service de classement ou de référencement, \n",
      "sans chercher à l’altérer ou à le détourner à des fins étran-\n",
      "gères à l’intérêt des utilisateurs51 ». \n",
      "\n",
      "Parmi les obligations des plateformes envers leurs utilisa-\n",
      "teurs découlant du principe de loyauté tel que défini par le \n",
      "Conseil d’État figurent notamment, d’une part, la pertinence \n",
      "des critères de classement et de référencement mis en \n",
      "œuvre par la plateforme au regard de l’objectif de meilleur \n",
      "service rendu à l’utilisateur et, d’autre part, l’information \n",
      "sur les critères de classement et de référencement mis \n",
      "en œuvre. La première obligation pose donc une limite à \n",
      "la liberté d’établissement des critères de l’algorithme par \n",
      "la plateforme. La deuxième obligation fait de l’information \n",
      "sur la logique de fonctionnement de l’algorithme une obli-\n",
      "gation incombant à la plateforme (ce n’est pas seulement \n",
      "un droit que l’utilisateur peut choisir ou non de mobiliser).\n",
      "\n",
      "Avec la loyauté ainsi définie, on accorde par ailleurs moins \n",
      "un droit aux utilisateurs qu’on impose une obligation à \n",
      "l’égard des responsables de traitement.\n",
      "\n",
      "D’une  certaine  façon,  le  principe  de  loyauté  se  trouve \n",
      "sous une forme embryonnaire dans la loi Informatique et \n",
      "Libertés de 1978. En effet, le droit à l’information qui s’y \n",
      "trouve affirmé apparaît comme une exigence première de \n",
      "loyauté à l’égard de la personne concernée quant au fait \n",
      "même qu’un algorithme traite ses données. À cela s’ajoute \n",
      "le droit pour toute personne d’interroger le responsable du \n",
      "fonctionnement de l’algorithme pour obtenir des informa-\n",
      "tions quant à la logique suivie par celui-ci ainsi que l’obli-\n",
      "gation de recueillir le consentement de la personne dont \n",
      "les données sont traitées. L’affirmation même de ces droits \n",
      "dans la loi de 1978 suppose que ces informations soient \n",
      "fournies de manière « loyale » et que le comportement de \n",
      "l’algorithme y corresponde effectivement. \n",
      "\n",
      "L’intérêt du principe de loyauté tel qu’il est envisagé par le \n",
      "Conseil d’État réside dans la notion d’ « intérêt des utilisa-\n",
      "teurs ». En effet, il ne s’agit pas simplement que l’algorithme \n",
      "dise ce qu’il fait et fasse ce qu’il dise : le principe de loyauté \n",
      "limite aussi la liberté que le responsable de l’algorithme a \n",
      "de déterminer les critères de fonctionnement de ce dernier. \n",
      "D’autre part, alors que dans la loi Informatique et Libertés, \n",
      "\n",
      "50  Il s’agissait de « soumettre [les plateformes] à une obligation de loyauté envers leurs utilisateurs (les non professionnels dans le cadre du droit de la consommation et les \n",
      "\n",
      "professionnels dans le cadre du droit de la concurrence) ». Les plateformes apparaissent comme des acteurs classant un contenu qu’il n’a pas lui-même mis en ligne.\n",
      "\n",
      "51 Le Numérique et les droits fondamentaux, 2014, p.273 et 278-281\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "49\n",
      "\n",
      "l’information est un droit qui peut éventuellement être mobi-\n",
      "lisé par l’individu auprès du responsable de l’algorithme, \n",
      "avec le principe de loyauté, cette information doit d’emblée \n",
      "être diffusée à destination de la communauté des utilisa-\n",
      "teurs52. Il n’est pas question ici de droit des utilisateurs \n",
      "mais d’obligation des plateformes algorithmiques. Dans \n",
      "cette mesure, la loyauté semble à même de constituer une \n",
      "réponse au problème de l’asymétrie entre les responsables \n",
      "des algorithmes et les utilisateurs.\n",
      "\n",
      "La notion de loyauté a notamment fait l’objet de réflexions \n",
      "complémentaires menées par le CNNUM. Celui-ci a en effet \n",
      "initié dans son rapport Ambition numérique (2015) une \n",
      "proposition tendant à créer une « agence de notation de la \n",
      "loyauté des algorithmes » appuyée sur un réseau ouvert de \n",
      "contributeurs, et ce dans un double objectif : rendre acces-\n",
      "sible via un point d’entrée unique toute une série d’informa-\n",
      "tions déjà rassemblées par les différents acteurs ainsi que \n",
      "les outils existants et ouvrir un espace de signalement de \n",
      "pratiques problématiques ou de dysfonctionnements. Cette \n",
      "initiative pourrait, sous une forme ou sous une autre, parti-\n",
      "ciper à une meilleure connaissance citoyenne des enjeux, \n",
      "à une meilleure symétrie entre utilisateurs et plateformes \n",
      "algorithmiques, à une meilleure circulation des bonnes pra-\n",
      "tiques pour les entreprises ainsi qu’à un repérage facilité \n",
      "des pratiques litigieuses par le régulateur.\n",
      "\n",
      "Un principe à élargir pour prendre en compte les effets \n",
      "collectifs des algorithmes\n",
      "Toutefois, par rapport à la définition fournie par le Conseil \n",
      "d’État, on peut estimer souhaitable d’élargir le principe, \n",
      "au-delà des seules plateformes, à tous les algorithmes53. \n",
      "Par exemple, un algorithme d’aide à la décision en matière \n",
      "médicale, ne devrait-il pas faire l’objet d’une interdiction \n",
      "de recourir, ou du moins d’accorder une place excessive, \n",
      "à un critère lié à l’optimisation de l’occupation des lits d’un \n",
      "hôpital ?\n",
      "\n",
      "Dès lors, le principe de loyauté des algorithmes aurait aussi \n",
      "l’intérêt de concerner des algorithmes ou des enjeux que ne \n",
      "touchent pas la législation sur la protection des données \n",
      "personnelles. Il concernerait en effet aussi les algorithmes \n",
      "ne procédant pas à un profilage de leurs utilisateurs à des \n",
      "fins de personnalisation de leurs résultats (par exemple, il \n",
      "voudrait pour un moteur de recherche qui ne fournirait pas \n",
      "des résultats profilés). \n",
      "\n",
      "On pourrait enfin considérer l’opportunité de reprendre la \n",
      "proposition du Conseil d’État en élargissant, ou du moins \n",
      "en précisant la notion d’« intérêt des utilisateurs », de façon \n",
      "à prendre en compte non seulement la dimension com-\n",
      "merciale et économique de cet intérêt, mais également \n",
      "sa dimension collective. Il s’agirait de considérer que les \n",
      "\n",
      "critères de l’algorithme doivent aussi ne pas entrer trop \n",
      "frontalement en opposition avec certains grands intérêts \n",
      "collectifs, liés notamment au troisième enjeu éthique évo-\n",
      "qué précédemment. Ces intérêts collectifs peuvent être \n",
      "entendus de deux façons. D’une part, il peut s’agir de l’intérêt \n",
      "de catégories, de segments constitués par la logique même \n",
      "du big data et de l’analyse algorithmique (des groupes ad \n",
      "hoc, constitués par le croisement de certains traits), qui sont \n",
      "susceptibles de faire l’objet de formes de discriminations. \n",
      "Ces catégories font l’objet des réflexions actuelles portant \n",
      "sur la notion de « group privacy54 ». D’autre part, cet intérêt \n",
      "collectif peut-être pensé comme celui d’une société tout \n",
      "entière. Par exemple, l’exposition à la diversité culturelle ou \n",
      "d’opinions pourrait être considérée comme liée à « l’intérêt \n",
      "des utilisateurs », entendus certes comme consommateurs \n",
      "mais aussi comme citoyens et parties prenantes d’une \n",
      "collectivité (il conviendrait d’ailleurs d’évoquer directement \n",
      "« l’intérêt des utilisateurs et des citoyens »).\n",
      "\n",
      "Les critères de l’algorithme \n",
      "\n",
      "doivent ne pas entrer \n",
      "\n",
      "trop frontalement \n",
      "\n",
      "en opposition avec certains \n",
      "grands intérêts collectifs\n",
      "\n",
      "Le principe de loyauté des algorithmes, s’il constitue à l’évi-\n",
      "dence une réponse à d’importants enjeux, se heurte avec \n",
      "la montée en puissance des algorithmes de « machine \n",
      "learning » à une sérieuse difficulté. Ces algorithmes, on \n",
      "l’a  vu,  peuvent  se  comporter  de  façon  problématique \n",
      "pour les droits des personnes, y compris à l’insu de leurs \n",
      "concepteurs (biais et discriminations cachés liés aux cor-\n",
      "rélations effectuées par le système). La notion de loyauté \n",
      "des concepteurs d’algorithmes (ce que l’on entend habituel-\n",
      "lement de fait par le vocable « loyauté des algorithmes ») \n",
      "perd une part de sa portée dès lors que l’algorithme se \n",
      "comporte d’une façon qui reste opaque à ces mêmes \n",
      "concepteurs. Il faudrait pouvoir parler, au sens propre, \n",
      "de loyauté des algorithmes (mais cela a-t-il un sens ?) ou \n",
      "bien s’assurer que l’algorithme ne se comportera pas d’une \n",
      "façon non souhaitable, sans que l’on soit bien en mesure \n",
      "de préciser a priori ce que l’on entend par ce « non souhai-\n",
      "table ». Autrement dit, un algorithme loyal ne devrait pas \n",
      "avoir pour effet de susciter, de reproduire ou de renforcer \n",
      "quelque discrimination que ce soit, fût-ce à l’insu de ses \n",
      "\n",
      "52  « Sans méconnaître le secret industriel, les plateformes devraient expliquer à leurs utilisateurs la logique générale de leurs algorithmes et, le cas échéant, la manière dont les \n",
      "\n",
      "utilisateurs peuvent les paramétrer. »\n",
      "\n",
      "53  Précisons – pour couper court à toute inutile querelle sémantique – que l’emploi de l’expression de « loyauté des algorithmes » ne revient pas à anthropomorphiser un fait \n",
      "\n",
      "technique (l’algorithme) mais est un raccourci pratique pour désigner la loyauté de ceux qui conçoivent et déploient l’algorithme.\n",
      "\n",
      "54  Brent Mittelstadt, From individual to group privacy in Big Data analytics, B. Philos. Technol. (2017) 30: 475. https://doi.org/10.1007/s13347-017-0253-7 \n",
      "\n",
      "\n",
      "50\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "concepteurs. Cette dernière piste est donc plus large que \n",
      "les premières réflexions évoquées plus haut sur la notion \n",
      "de loyauté, développées avant tout en référence à des pré-\n",
      "occupations d’ordre commerciales, concurrentielles, dans \n",
      "la perspective du développement de pratiques résolument \n",
      "déloyales destinées à obtenir un avantage en manipulant \n",
      "l’algorithme.\n",
      "\n",
      "Le principe de vigilance \n",
      "\n",
      "Si le principe de loyauté apparaît comme un principe subs-\n",
      "tantiel fondateur, le principe de vigilance constitue quant à \n",
      "lui un principe plus méthodologique qui doit orienter la façon \n",
      "dont nos sociétés modèlent les systèmes algorithmiques.\n",
      "\n",
      "L’un des défis identifiés consiste dans le caractère mouvant \n",
      "et évolutif des algorithmes à l’heure du machine learning. \n",
      "Cette caractéristique est renforcée par l’échelle inédite de \n",
      "l’impact potentiel des algorithmes exécutés par des pro-\n",
      "grammes informatiques et donc de l’application d’un même \n",
      "modèle. Ceci accroît l’imprévisibilité, le caractère évolutif \n",
      "et potentiellement surprenant des algorithmes et de leurs \n",
      "effets. Comment donc appréhender et encadrer un objet \n",
      "instable, susceptible de générer des effets nouveaux au fur \n",
      "et à mesure de son déploiement et de son apprentissage, \n",
      "des effets imprévisibles au départ ?\n",
      "\n",
      "La promotion d’un principe d’« obligation de vigilance » \n",
      "pourrait être une façon d’aborder ce défi en prévoyant la \n",
      "prise en compte par les concepteurs et ceux qui déploient \n",
      "l’intelligence artificielle de cette caractéristique inédite. Par \n",
      "ailleurs, ce principe d’obligation de vigilance viserait aussi \n",
      "à contrebalancer le phénomène de confiance excessive \n",
      "et de déresponsabilisation dont on a vu qu’il était favorisé \n",
      "par le caractère de boîte noire des algorithmes et de l’IA. \n",
      "\n",
      "Enfin, ce principe de vigilance doit avoir une signification \n",
      "collective. Plus que d’algorithmes, sans doute faudrait-il par-\n",
      "ler de systèmes algorithmiques, de complexes et longues \n",
      "« chaînes algorithmiques » composées de multiples acteurs \n",
      "(du développeur à l’utilisateur final, en passant par la société \n",
      "ayant collecté les données utilisées pour l’apprentissage, \n",
      "\n",
      "le professionnel qui réalise cet apprentissage, par celui qui \n",
      "a acheté une solution de machine learning qu’il va ensuite \n",
      "déployer, etc.). Ce phénomène – semblable à celui qui peut \n",
      "se développer le long d’une chaîne de sous-traitance – favo-\n",
      "rise la dilution du sentiment de responsabilité, voire simple-\n",
      "ment de la conscience des impacts que peuvent générer \n",
      "ces outils. Par exemple, le data scientist, s’il occupe une \n",
      "position essentielle, en amont de la chaîne algorithmique, \n",
      "ne saurait détenir toutes les clés et ne possède pas néces-\n",
      "sairement la vision d’ensemble de l’action collective dont il \n",
      "forme le premier maillon. Le Conseil National des Barreaux, \n",
      "dans le rapport remis à la CNIL, souligne pour sa part que \n",
      "« le sens de l’éthique du lieu de mise en œuvre du pro-\n",
      "gramme peut être très différent de celui du concepteur du \n",
      "programme ». En outre, l’informatique porte en elle-même \n",
      "le risque du développement d’une confiance exagérée dans \n",
      "une machine souvent perçue comme infaillible et exempte \n",
      "des biais charriés par l’action et le jugement humains. La \n",
      "commission Tricot, dans les années 1970, soulignait déjà ce \n",
      "risque. Plusieurs des intervenants du débat public l’ont men-\n",
      "tionné cette année. Au total, donc, le développement des \n",
      "systèmes algorithmiques va de pair avec une érosion des \n",
      "vigilances individuelles. Or, il ne saurait être question de lais-\n",
      "ser se développer ce type d’indifférence face aux impacts \n",
      "possibles des algorithmes et de l’intelligence artificielle. \n",
      "Il est nécessaire d’organiser la vigilance collective, aussi \n",
      "bien à l’égard de phénomènes connus dont il s’agit d’éviter \n",
      "l’apparition qu’à l’égard de phénomènes ou d’impacts qui \n",
      "n’ont pas nécessairement pu être envisagés initialement \n",
      "mais dont l’échelle et le caractère évolutif des nouveaux \n",
      "algorithmes rendent la survenue toujours possible.\n",
      "\n",
      "Le développement  \n",
      "\n",
      "des systèmes algorithmiques \n",
      "va de pair avec une érosion \n",
      "des vigilances individuelles\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "51\n",
      "\n",
      "Des principes d’ingénierie : intelligibilité, \n",
      "responsabilité, intervention humaine\n",
      "\n",
      "Intelligibilité, transparence, \n",
      "responsabilité\n",
      "\n",
      "Face à l’opacité des systèmes algorithmiques, la transpa-\n",
      "rence est une exigence très souvent affirmée, non sans \n",
      "lien d’ailleurs avec le principe de loyauté. Selon le Conseil \n",
      "national du numérique, « ce principe implique première-\n",
      "ment et d’une manière générale la transparence du com-\n",
      "portement de la plateforme, condition pour s’assurer de \n",
      "la conformité entre la promesse affichée du service et les \n",
      "pratiques réelles. Dans les relations entre professionnels, il \n",
      "s’applique aux conditions économiques d’accès aux plate-\n",
      "formes et aux conditions d’ouverture des services à des \n",
      "tiers55 ». L’opacité en question concerne autant la collecte \n",
      "que le traitement des données par ces systèmes et donc le \n",
      "rôle que ceux-ci jouent dans un certain nombre de prises de \n",
      "décisions. Les algorithmes ne sont pourtant pas opaques \n",
      "seulement à l’égard de leurs utilisateurs finaux ou à ceux \n",
      "dont ils traitent les données. De plus en plus, avec l’affirma-\n",
      "tion du machine learning, les concepteurs mêmes de ces \n",
      "algorithmes probabilistes perdent la capacité à comprendre \n",
      "la logique des résultats produits. C’est donc à un double \n",
      "niveau que se pose la question de l’opacité. La transparence \n",
      "exigée face à cette situation appelle des réponses légales \n",
      "et de procédure mais elle soulève aussi un enjeu technique. \n",
      "\n",
      "L’idée de transparence des algorithmes est considérée \n",
      "par beaucoup comme excessivement simplificatrice et \n",
      "finalement insatisfaisante : une transparence assimilée \n",
      "à la publication pure et simple d’un code source laisse-\n",
      "rait l’immense majorité du public, non spécialisé, dans \n",
      "l’incompréhension de la logique à l’œuvre. Par ailleurs, \n",
      "du moins en ce qui concerne le secteur privé, l’idée de \n",
      "transparence entre en tension avec le droit de la propriété \n",
      "intellectuelle, les algorithmes s’apparentant à un secret \n",
      "industriel dont la divulgation pourrait mettre en danger un \n",
      "modèle économique. \n",
      "\n",
      "Enfin, des entreprises peuvent avancer de bonnes raisons \n",
      "de ne pas dévoiler le code source, ni les critères comman-\n",
      "dant  le  fonctionnement  d’un  algorithme.  Ainsi  Google \n",
      "cherche-t-il à éviter que les résultats fournis par l’algo-\n",
      "rithme de son moteur de recherche, PageRank, ne soient \n",
      "faussés par des acteurs qui seraient à même d’en exploiter \n",
      "la logique à leur profit.\n",
      "\n",
      "De nombreux spécialistes proposent ainsi de préférer, à la \n",
      "transparence, l’exigence d’intelligibilité ou d’explicabilité des \n",
      "algorithmes. Plus que d’avoir accès directement au code \n",
      "source, l’essentiel serait d’être à même de comprendre la \n",
      "logique générale de fonctionnement de l’algorithme. Cette \n",
      "logique devrait pouvoir être comprise par tous et donc énon-\n",
      "cée verbalement et non sous la forme de lignes de code. \n",
      "C’est ainsi la position de Daniel Le Métayer, de l’Institut \n",
      "national de recherche en informatique et en automatique \n",
      "(INRIA), pour qui l’intelligibilité passe à travers le question-\n",
      "nement sur la logique globale de l’algorithme ainsi que sur \n",
      "des résultats particuliers. C’est la position de Dominique \n",
      "Cardon : « Que doit-on rendre transparent dans l’algorithme ? \n",
      "Est-ce la technique statistique employée ? Faut-il rendre \n",
      "le code visible? Même si c’est utile, il y a des raisons pour \n",
      "qu’il ne soit pas obligatoirement dévoilé. Par exemple, dans \n",
      "le marché du « search engine optimization », des acteurs \n",
      "cherchent à influer sur les résultats de l’algorithme : cela \n",
      "permet de comprendre l’une des raisons pour lesquelles \n",
      "Google ne rend pas son code public. Rendre transparent \n",
      "un calculateur, cela doit avant tout être un travail pédago-\n",
      "gique, pour essayer de faire comprendre ce qu’il fait. Ce \n",
      "qui est essentiel, ce n’est pas que le code soit transparent, \n",
      "c’est que l’on comprenne ce qui rentre et ce qui sort de \n",
      "l’algorithme ainsi que son objectif. C’est cela qui doit être \n",
      "transparent » (CNIL, événement de lancement du débat \n",
      "public, 23 janvier 2017).\n",
      "\n",
      "L’idée  d’intelligibilité  (ou  explicabilité),  comme  celle  de \n",
      "transparence, s’articule de toute façon avec le principe de \n",
      "loyauté, dont on peut considérer qu’elle est finalement une \n",
      "condition de déploiement.\n",
      "\n",
      "Enfin, l’introduction d’une obligation de redevabilité ou \n",
      "d’organisation de la responsabilité pourrait constituer une \n",
      "réponse au phénomène de dilution de la responsabilité \n",
      "qu’ont tendance à favoriser les algorithmes et l’intelligence \n",
      "artificielle. Il s’agirait de prévoir que le déploiement d’un \n",
      "système algorithmique doit nécessairement donner lieu \n",
      "à une attribution explicite des responsabilités impliquées \n",
      "par son fonctionnement.\n",
      "\n",
      "55 https://cnnumerique.fr/wp-content/uploads/2015/11/CNNum_Fiche_Loyaute-des-plateformes.pdf\n",
      "\n",
      "\n",
      "52\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "Repenser l’obligation d’intervention \n",
      "humaine dans la prise de décision \n",
      "algorithmique ?\n",
      "\n",
      "On a vu que la loi de 1978 avait posé un principe d’interdic-\n",
      "tion de toute prise de décision entraînant des effets juri-\n",
      "diques à l’égard d’une personne sur le seul fondement d’un \n",
      "traitement automatisé de données à caractère personnel \n",
      "(autrement dit : sur le seul fondement du résultat fourni \n",
      "par un algorithme analysant des données personnelles). \n",
      "Ce principe est repris dans le Règlement européen sur la \n",
      "protection des données à caractère personnel. Néanmoins, \n",
      "l’un et l’autre de ces textes, immédiatement après avoir \n",
      "affirmé ce principe, le vident en grande partie de sa subs-\n",
      "tance par l’adjonction d’exceptions très larges56.\n",
      "\n",
      "Il semble par ailleurs que le recours des juridictions à l’article \n",
      "10 de la loi de 1978 (dont il est ici question) soit devenu \n",
      "moins fréquent et que l’interprétation dudit article soit deve-\n",
      "nue moins stricte au cours des quarante dernières années57. \n",
      "Une évolution de la Loi Informatique et Libertés interve-\n",
      "nue en 2004 a d’ailleurs facilité de fait la prise de décision \n",
      "automatisée, dans le secteur bancaire (credit scoring) par \n",
      "exemple : si l’intervention humaine dans le processus est \n",
      "toujours requise, celle-ci prend la forme d’un droit pour \n",
      "la personne concernée de demander à ce que, en cas de \n",
      "décision défavorable, celle-ci soit réexaminée par une per-\n",
      "sonne. Intervention humaine, donc, mais a posteriori et \n",
      "seulement sur demande.\n",
      "\n",
      "Sans que le terme implique un jugement de valeur, il semble \n",
      "que l’on puisse parler d’une forme de « dérive » ou d’évo-\n",
      "lution du seuil de tolérance de la société à l’égard de la \n",
      "prise de décisions automatisée depuis les années 1970. \n",
      "L’évolution du droit et de la jurisprudence seraient le reflet \n",
      "de cette évolution. Ne faut-il pas dès lors revisiter le principe \n",
      "interdisant la prise de décision par une machine seule et \n",
      "impliquant donc la nécessaire intervention humaine ? Le \n",
      "revisiter pour accueillir les nouveaux usages de l’IA, sans \n",
      "toutefois y renoncer ?\n",
      "\n",
      "Dans son étude annuelle de 2014, le Conseil d’État sou-\n",
      "lignait la nécessité d’assurer l’effectivité de l’intervention \n",
      "humaine. Il est possible de considérer qu’assurer l’effec-\n",
      "tivité de l’intervention humaine à l’échelle de chaque déci-\n",
      "sion prise revient de fait à empêcher ou à limiter certaines \n",
      "applications des algorithmes et de l’IA. En effet, quand \n",
      "l’automatisation a pour fonction d’optimiser et d’accélérer \n",
      "un processus en remplaçant l’homme, une intervention \n",
      "humaine réellement effective pour chaque décision risque \n",
      "d’être dissuasive. On pourrait en fait poser ainsi la question : \n",
      "comment  faire  assurer  par  des  machines  des  tâches \n",
      "auparavant accomplies par l’intelligence humaine (c’est \n",
      "la définition de l’IA) sans évacuer l’homme ? Une façon \n",
      "d’y répondre consiste à avancer que l’on pourrait envisa-\n",
      "ger l’effectivité de l’intervention humaine autrement qu’à \n",
      "l’échelle de chaque décision individuelle. On pourrait, par \n",
      "exemple, assurer que des formes de délibération humaine \n",
      "et contradictoire encadrent et accompagnent l’utilisation \n",
      "des algorithmes en examinant et en interrogeant le para-\n",
      "métrage mais aussi tous les effets – directs et indirects – \n",
      "du système. Cette supervision pourrait ainsi porter, non \n",
      "pas sur chaque décision individuelle, mais de loin en loin \n",
      "sur des séries plus ou moins nombreuses de décisions. \n",
      "\n",
      "La protection des libertés serait dès lors pensée moins \n",
      "en termes individuels que collectifs. On voit d’ailleurs ici \n",
      "comment une telle piste s’articulerait aussi avec l’idée \n",
      "d’une obligation de vigilance évoquée précédemment. Ce \n",
      "passage d’une interprétation individuelle à une interpréta-\n",
      "tion collective de l’obligation d’assurer une forme d’inter-\n",
      "vention humaine dans la décision automatisée pourrait \n",
      "faire l’objet d’une modulation en fonction de la sensibilité \n",
      "des applications considérées et de la configuration de la \n",
      "balance avantages/risques (par exemple, dans la santé, \n",
      "faut-il considérer que la sensibilité des enjeux dépasse \n",
      "les gains et justifie donc un maintien de l’obligation de \n",
      "garantir une intervention humaine pour chaque décision ?).\n",
      "\n",
      "Comment faire assurer par des machines \n",
      "\n",
      "des tâches auparavant accomplies par \n",
      "l’intelligence humaine (c’est la définition \n",
      "\n",
      "de l’IA) sans évacuer l’homme ?\n",
      "\n",
      "56  Sur ce point dans le RGPD, voir par exemple : Wachter, Sandra, Brent Mittelstadt, et Luciano Floridi. « Why a Right to Explanation of Automated Decision-Making Does Not Exist in \n",
      "\n",
      "the General Data Protection Regulation ». Social Science Research Network, décembre 2016\n",
      "\n",
      "57  Voir par exemple la délibération de la CNIL sur le projet GAMIN, en 1981 : la Commission rejeta alors ce projet du ministère de la santé. Même les garanties pourtant données par \n",
      "le ministère pour assurer une intervention humaine effective dans la détection de mineurs à risques psycho-sociaux dont il était question furent repoussées. On peut pourtant \n",
      "se demander à la lecture du dossier si la position de la CNIL serait aujourd’hui la même, alors qu’il nous semble qu’une certaine accoutumance s’est opérée à l’idée de voir des \n",
      "algorithmes intervenir de plus en plus fortement dans des domaines de plus en plus importants. Par exemple, la décision d’éliminer des candidats sur le fondement d’un seul \n",
      "traitement automatisé ne paraît guère relever de la science-fiction ni même probablement de ce que beaucoup dans notre société sont prêts à accepter.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "53\n",
      "\n",
      "Des principes aux recommandations \n",
      "pratiques\n",
      "\n",
      "Comment donner une effectivité concrète aux principes \n",
      "abordés précédemment ? Les pages suivantes listent les \n",
      "principales recommandations qui ont émergé du débat \n",
      "public organisé par la CNIL de janvier à octobre 2017, com-\n",
      "plété par la consultation de rapports déjà émis par diverses \n",
      "institutions en France et à l’étranger (entre autres, l’OPECST, \n",
      "la CERNA, le CNNUM, le Conseil d’État, la CGE, la Maison \n",
      "Blanche, France IA, INRIA, AI Now).\n",
      "\n",
      "cielle sont des objets socio-techniques complexes, modelés \n",
      "et manipulés par de longues et complexes chaînes d’ac-\n",
      "teurs. C’est donc tout au long de la chaîne algorithmique \n",
      "(du concepteur à l’utilisateur final, en passant par ceux \n",
      "qui entraînent les systèmes et par ceux qui les déploient) \n",
      "qu’il faut agir, au moyen d’une combinaison d’approches \n",
      "techniques et organisationnelles. Les algorithmes sont \n",
      "partout : ils sont donc l’affaire de tous. \n",
      "\n",
      "Une idée générale qui émane de la plupart des réflexions est \n",
      "que les solutions impliquent nécessairement une palette \n",
      "d’actions diversifiées concernant différents acteurs (les \n",
      "concepteurs d’algorithmes, les professionnels, les entre-\n",
      "prises, la puissance publique, la société civile, l’utilisateur \n",
      "final). Les systèmes algorithmiques et d’intelligence artifi-\n",
      "\n",
      "La loi ne saurait être le seul levier, la solution passant \n",
      "nécessairement par une mobilisation de tous les acteurs. \n",
      "Un certain nombre des recommandations formulées ci- \n",
      "dessous ne précisent d’ailleurs pas si c’est la loi ou l’initiative \n",
      "spontanée des différents acteurs qui devrait être privilégiée \n",
      "pour les mettre en œuvre.\n",
      "\n",
      "LE REGARD DU CITOYEN\n",
      "\n",
      "Les participants à la concertation citoyenne organisée par la CNIL à Montpellier le 14 octobre 2017 (voir \n",
      "« L’organisation du débat public sur les enjeux éthiques des algorithmes et de l’intelligence artificielle ») \n",
      "ont formulé des recommandations. Ces dernières recoupent en grande partie celles recueillies ailleurs \n",
      "dans le cadre du débat public.\n",
      "•  Le souhait que l’humain garde le contrôle sur le développement des algorithmes apparaît prioritaire \n",
      "(95% d’avis favorables), une délégation excessive des décisions aux algorithmes et à l’IA étant jugée pré-\n",
      "judiciable. Le constat des participants rejoint l’idée d’un principe de vigilance précédemment évoqué : \n",
      "97% souhaitent « garder la dimension humaine, garder une dose de subjectivité, ne pas de désinvestir \n",
      "totalement » et 91% considèrent que « l’utilisateur devrait être dans une posture d’apprenant à chaque \n",
      "usage d’un algorithme afin d’en cerner les limites et être exigeant vis-à-vis des développeurs à chaque \n",
      "fois que cela est nécessaire ». Dans le champ de la médecine par exemple, certains citoyens pensent \n",
      "qu’une partie des décisions devrait toujours être discutée en collège. \n",
      "•  L’adaptation de la formation des concepteurs d’algorithmes est une option ayant émergé dans plusieurs \n",
      "groupes de travail, et ayant fait l’objet d’un quasi-consensus : 97% des participants considèrent que « les \n",
      "développeurs doivent intégrer dans leurs pratiques une certaine éthique et résister aux demandes ten-\n",
      "tantes du marché qui peuvent affecter cette dimension ». 94% en appellent ainsi au développement de \n",
      "chartes éthiques et 56% souhaiteraient que des experts associés issus des sciences humaines et sociales \n",
      "permettent aux développeurs de mieux mesurer l’impact de leur travail sur la société. La formation \n",
      "concerne également les utilisateurs d’algorithmes : 82% des personnes présentes sont favorables à une \n",
      "obligation de formation continue des médecins utilisant des systèmes d’aide à la décision. Plus généra-\n",
      "lement, ce besoin de savoir et de comprendre se matérialise par une forte demande pour plus d’éducation \n",
      "au numérique tout au long de la vie. Notamment afin de lutter contre les inégalités face à ces objets, \n",
      "l’intégralité des citoyens revendiquent une « éducation populaire au numérique » et le « développement \n",
      "de programmes scolaires pour une « alphabétisation » au numérique tant sur l’objet que sur les enjeux ».\n",
      "\n",
      "\n",
      "54\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "LE REGARD DU CITOYEN (suite)\n",
      "\n",
      " •  La nécessité de disposer de droits renforcés en matière d’information, de transparence et d’explication \n",
      "quant à la logique de fonctionnement de l’algorithme a également été vigoureusement affirmée dans \n",
      "chacun des groupes de travail. C’est déjà la possibilité d’être informé dès qu’un algorithme est déployé \n",
      "qui semble être exigée par les participants : 88% des participants estiment en effet qu’un employeur qui \n",
      "utilise un algorithme devrait impérativement l’indiquer aux candidats. La mise à disposition des codes \n",
      "source est jugée souhaitable par 78% d’entre eux, bien qu’elle soit considérée comme insuffisante pour \n",
      "comprendre les résultats produits par un algorithme. Dans le cas d’APB par exemple, un accompagne-\n",
      "ment plus effectif pour comprendre les ressorts de son utilisation est demandé par 78% des citoyens \n",
      "présents. 85% voient d’ailleurs dans l’expérience des utilisateurs un matériau précieux pour « améliorer \n",
      "l’ergonomie de la procédure ». Lorsqu’un critère de l’algorithme repose sur des choix politiques (le tirage \n",
      "au sort, par exemple), il convient également de ne pas l’occulter mais bien au contraire de le rendre lisible \n",
      "(selon 94% des participants). Notons que si un désir de transparence se manifeste, il n’est pas unanime \n",
      "et s’accompagne d’une lucidité voire d’un fatalisme sur l’hypothèse qu’elle puisse suffire.\n",
      "•  Un effort étatique de régulation pour identifier les biais, « éviter les abus, établir des statistiques et impo-\n",
      "ser un agrément » pourrait constituer une solution selon une écrasante majorité des participants (97%). \n",
      "Beaucoup préconisent la création d’un organisme indépendant pour effectuer des tests scientifiques \n",
      "sur les algorithmes, « à l’image des médicaments avant la mise en vente sur le marché » (84%). Sur le \n",
      "long terme, s’assurer régulièrement que l’algorithme soit « toujours en phase avec les objectifs visés » \n",
      "constitue également une idée ayant émergé des débats (63% y sont favorables). L’intervention du légis-\n",
      "lateur est également vivement souhaitée (94%) afin de mieux intégrer l’éthique dans les lois « à travers \n",
      "des chartes et des règles déontologiques, des formations, des concertations ».\n",
      "•  L’importance pour la société civile de s’organiser face à ces objets technologiques nouveaux a aussi été \n",
      "avancée par certains des participants à travers notamment le rôle du tissu associatif (associations de \n",
      "patients dans le champ de la santé), la protection nécessaire des lanceurs d’alerte, ou encore le soutien \n",
      "apporté à des réseaux alternatifs aux plateformes du web dont les algorithmes utilisés poseraient question.\n",
      "•  Enfin, les échanges ont démontré un fort attachement à la protection des données à caractère personnel \n",
      "et à la protection de la vie privée. La question de savoir à qui appartiennent nos données et quels sont \n",
      "les usages qui en sont faits a été jugée prioritaire dans certains groupes de travail, sur la santé notam-\n",
      "ment, ou encore sur l’emploi (inquiétude sur la possibilité que des algorithmes analysent des données \n",
      "qui seraient collectées en dehors de l’entreprise).\n",
      "\n",
      "RECOMMANDATION  1\n",
      "Former à l’éthique tous les maillons  \n",
      "de la « chaîne algorithmique » : \n",
      "concepteurs, professionnels, citoyens\n",
      "\n",
      "Formation des citoyens\n",
      "Le citoyen est l’un des acteurs centraux des systèmes algo-\n",
      "rithmiques. D’une part car les algorithmes ont un impact \n",
      "croissant sur son existence. D’autre part, parce qu’il est \n",
      "particulièrement bien placé pour en identifier les éventuels \n",
      "dérives. Lui fournir les clés de compréhension lui permet-\n",
      "\n",
      "tant d’aborder de manière confiante, active et éclairée ces \n",
      "nouvelles technologies est une nécessité qui correspond \n",
      "par ailleurs à une demande de sa part, ainsi que l’a rappelé \n",
      "fortement la concertation citoyenne organisée à Montpellier \n",
      "par la CNIL le 14 octobre 2017.\n",
      "\n",
      "L’impératif de constituer une « nouvelle littératie » numérique \n",
      "à intégrer dès l’école et jusqu’à l’université fait l’objet d’un \n",
      "large consensus. Des acteurs comme le CNNUM ont déjà \n",
      "développé des réflexions à cet égard58. Cette littératie numé-\n",
      "rique comprendrait évidemment une culture algorithmique \n",
      "dont les fondements peuvent d’ailleurs être posés très tôt, \n",
      "par des exercices qui n’impliquent pas nécessairement le \n",
      "recours à un matériel numérique.\n",
      "\n",
      "58 https://cnnumerique.fr/education-2/ \n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "55\n",
      "\n",
      "La diffusion de cette culture algorithmique très largement \n",
      "dans la population peut être également favorisée par l’en-\n",
      "couragement aux initiatives de médiation numérique dans \n",
      "les territoires. Autrement dit, une forme d’éducation popu-\n",
      "laire numérique incluant une dimension d’appropriation \n",
      "aux données et aux algorithmes. Citons par exemple les \n",
      "initiatives de la FING  (Info Lab), de la Péniche à Grenoble \n",
      "(Coop-Infolab), de Pop School à Lille.\n",
      "\n",
      "Formation des concepteurs d’algorithmes\n",
      "Les concepteurs d’algorithmes (développeurs, program-\n",
      "meurs, codeurs, data scientists, ingénieurs) forment le pre-\n",
      "mier maillon de la chaîne algorithmique. Ils occupent à ce \n",
      "titre une position particulièrement sensible. La technicité \n",
      "de leurs métiers est par ailleurs susceptible de rendre leurs \n",
      "actions opaques (et donc difficilement contrôlables) aux \n",
      "autres acteurs. Il est capital qu’ils aient une conscience \n",
      "aussi  claire  que  possible  des  implications  éthiques  et \n",
      "sociales de leurs actions, et du fait même que ces dernières \n",
      "peuvent recouvrir la dimension de choix de société qu’ils ne \n",
      "sauraient être légitimes à arbitrer seuls. Or, l’organisation \n",
      "concrète du travail et de l’économie tend à segmenter les \n",
      "tâches et à favoriser la tendance que peuvent avoir les \n",
      "individus à ignorer les implications de leur activité au-delà \n",
      "de leur silo. Par conséquent, il est nécessaire que leur for-\n",
      "mation même mette les concepteurs des algorithmes en \n",
      "capacité de saisir ces implications parfois très indirectes \n",
      "sur les personnes mais aussi sur la société, qu’elle les res-\n",
      "ponsabilise en éveillant leur vigilance.\n",
      "\n",
      "L’intégration, dans la formation des ingénieurs et data \n",
      "scientists, de l’approche des sciences humaines et sociales \n",
      "(sociologie, anthropologie, gestion, histoire des sciences \n",
      "et des techniques, sciences de l’information et de la com-\n",
      "munication, philosophie, éthique) sur ces questions peut \n",
      "à cet égard avoir des effets positifs. \n",
      "\n",
      "Le développement de ces mêmes enseignements béné-\n",
      "ficierait de l’intégration des approches techniques et des \n",
      "sciences humaines et sociales au sein de laboratoires \n",
      "interdisciplinaires.\n",
      "Certaines initiatives vont déjà dans ce sens. Citons par \n",
      "exemple le cas de l’ENSC (École nationale supérieure de \n",
      "cognitique, à Bordeaux), grande école intégrant les sciences \n",
      "humaines et sociales au cursus de formation de ses ingé-\n",
      "nieurs ou encore le laboratoire Costech (Connaissance, \n",
      "organisation  et  systèmes  techniques),  à  l’Université \n",
      "Technique de Compiègne (UTC).\n",
      "\n",
      "Enfin, il est essentiel de favoriser la diversification cultu-\n",
      "relle, sociale et de genre des professions impliquées dans \n",
      "la conception des algorithmes afin de garantir que l’intel-\n",
      "ligence artificielle ne favorise pas des formes d’ethnocen-\n",
      "\n",
      "trisme. La féminisation de ces métiers devrait notamment \n",
      "commencer par un effort d’ouverture des filières de forma-\n",
      "tion aux femmes.\n",
      "\n",
      "Formation des professionnels utilisateurs \n",
      "d’algorithmes\n",
      "Pour considérer l’ensemble de la chaîne de déploiement \n",
      "des algorithmes, il est nécessaire d’envisager également \n",
      "la formation des professionnels appelés à utiliser ces sys-\n",
      "tèmes dans le cadre de leur activité. Il s’agirait notamment \n",
      "de les armer contre le risque de déresponsabilisation, de \n",
      "perte d’autonomie que peut développer le recours à des \n",
      "outils fonctionnant parfois comme des boîtes noires pré-\n",
      "sentées comme étant d’une efficacité imparable. Prévenir le \n",
      "développement d’une confiance excessive en sensibilisant \n",
      "aux dimensions éthiques d’une prise de décision qui ne \n",
      "doit pas exclure l’intervention humaine et en développant \n",
      "l’esprit critique s’avère crucial dans des secteurs particu-\n",
      "lièrement sensibles, comme peuvent l’être la médecine, le \n",
      "recrutement, la justice, et peut-être dès maintenant surtout \n",
      "le marketing, où les catégories antisémites récemment \n",
      "générées par les algorithmes apprenants de Facebook sont \n",
      "venus illustrer la réalité des risques. Cette formation devrait \n",
      "notamment inclure, dans une optique pluridisciplinaire, la \n",
      "prise en compte des enjeux spécifiques que posent ces \n",
      "outils à chaque secteur. Un médecin qui utilise un système \n",
      "d’aide au diagnostic recourant à l’intelligence artificielle, \n",
      "par exemple, devrait être rendu spécifiquement attentif au \n",
      "développement possible de biais et capable d’une réflexivité \n",
      "à la hauteur de l’outil qu’il maniera et des conséquences \n",
      "de ses erreurs. \n",
      "On pourrait ainsi imaginer la création de sorte de « permis \n",
      "d’utiliser les algorithmes et l’IA » dans certains secteurs, \n",
      "acquis grâce à des modules de formations spécifiques que \n",
      "délivreraient universités et écoles spécialisées.\n",
      "\n",
      "Sensibilisation des acteurs publics à la nécessité \n",
      "d’un usage équilibré et « symétrique » des algorithmes\n",
      "De même, il serait souhaitable de sensibiliser les acteurs \n",
      "publics à la nécessité d’un déploiement équilibré et symé-\n",
      "trique des algorithmes. Alors que ces derniers sont de \n",
      "plus en plus utilisés pour lutter la fraude et à des fins de \n",
      "contrôle, laisser se développer dans le public la perception \n",
      "erronée selon laquelle ils ne peuvent servir qu’au contrôle et \n",
      "à des finalités répressives (par ailleurs utiles aux individus \n",
      "mêmes) risquerait de générer une forme de défiance qui \n",
      "serait à terme néfaste à leur déploiement et à l’exploitation \n",
      "de leurs avantages. Il serait donc hautement souhaitable \n",
      "que les responsables administratifs et politiques soient \n",
      "convaincus de l’utilité d’exploiter les potentialités des algo-\n",
      "rithmes qui apparaissent immédiatement favorables aux \n",
      "personnes et permettent d’améliorer l’accès aux droits \n",
      "(détection du non-recours aux aides sociales)59.\n",
      "\n",
      "59 Dans une évaluation des politiques publiques en faveur de l’accès aux droits sociaux, les députés Gisèle Biémouret et M. Jean-Louis Costes proposaient en 2016 de « mettre \n",
      "les outils de lutte contre la fraude au service de la diminution du non recours aux droits sociaux ». Voir : Rapport d’information du comité d’évaluation et de contrôle des politiques \n",
      "publiques sur l’évaluation des politiques publiques en faveur de l’accès aux droits sociaux.\n",
      "\n",
      "\n",
      "56\n",
      "\n",
      "RECOMMANDATION 2\n",
      "Rendre les systèmes algorithmiques \n",
      "compréhensibles en renforçant les droits \n",
      "existants et en organisant la médiation \n",
      "avec les utilisateurs\n",
      "\n",
      "L’opacité, pour les personnes, des algorithmes qui les pro-\n",
      "filent et de la logique à laquelle ceux-ci obéissent, pour leur \n",
      "attribuer un crédit bancaire par exemple, n’est pas sans \n",
      "trouver de premiers éléments de réponse dans le droit \n",
      "existant. De même, on a vu que celui-ci contient depuis \n",
      "longtemps des dispositions ouvrant la voie à une première \n",
      "forme d’intelligibilité et de transparence60.\n",
      "\n",
      "En revanche, de nombreux diagnostics convergent pour \n",
      "souligner l’insuffisance de ces dispositions pour résorber \n",
      "de manière effective l’opacité des systèmes algorithmiques \n",
      "et assurer intelligibilité, transparence et loyauté. Instaurer \n",
      "pour les responsables des systèmes une obligation de com-\n",
      "munication (et non pas sur la seule demande formulée par \n",
      "les personnes concernées) claire et compréhensible des \n",
      "informations permettant de comprendre la logique de fonc-\n",
      "tionnement d’un algorithme serait une façon de répondre \n",
      "à cet enjeu. Elle a d’ailleurs été d’ores et déjà prévue dans \n",
      "la loi pour une République numérique pour les algorithmes \n",
      "déployés par les administrations publiques61.\n",
      "\n",
      "On peut également considérer qu’il serait souhaitable que \n",
      "cet impératif (qu’il soit fixé par la loi ou librement adopté \n",
      "par les acteurs) concerne aussi les algorithmes n’impli-\n",
      "quant pas le traitement des données personnelles de leurs \n",
      "utilisateurs, dans la mesure où ceux-ci sont susceptibles \n",
      "d’avoir des impacts collectifs significatifs, même si ceux-ci \n",
      "ne portent pas directement sur des personnes (voir notam-\n",
      "ment « Les limites de l’encadrement juridique actuel des \n",
      "algorithmes » et « Le principe de loyauté »).\n",
      "\n",
      "Une telle obligation, inscrite dans la loi, pourrait opportuné-\n",
      "ment être prolongée par des initiatives privées enclenchant \n",
      "une dynamique vertueuse. Pour les acteurs du web ayant \n",
      "des sites sur lesquels les personnes disposent d’un compte \n",
      "auquel elles peuvent se connecter, l’information sur leur \n",
      "« profil », les données traitées et inférées et la logique de \n",
      "l’algorithme pourraient être accessibles dans cet espace. \n",
      "Les personnes pourraient par ce biais corriger et actualiser \n",
      "aisément leur profil et les données les concernant.\n",
      "\n",
      "Cette évolution du droit pourrait être relayée par le déve-\n",
      "loppement de bonnes pratiques par les acteurs, à l’aide \n",
      "d’outils de droit souple.\n",
      "\n",
      "Le problème de l’opacité des algorithmes tient aussi au fait \n",
      "que les responsables des systèmes algorithmiques ne \n",
      "sont pas, dans l’immense majorité des cas, concrètement \n",
      "joignables ou accessibles pour fournir ces informations et \n",
      "explications. Ceci implique également une irresponsabilité \n",
      "de systèmes auxquels les utilisateurs se trouvent dans \n",
      "l’impossibilité de demander des comptes. Il est donc néces-\n",
      "saire d’organiser une forme de « joignabilité » des systèmes \n",
      "algorithmiques, notamment en identifiant systématique-\n",
      "ment au sein de chaque entreprise ou administration une \n",
      "équipe responsable du fonctionnement d’un algorithme dès \n",
      "lors que celui-ci traite les données de personnes physiques. \n",
      "Il est en outre nécessaire de communiquer délibérément et \n",
      "de façon claire l’identité et les coordonnées de cette per-\n",
      "sonne ou de cette équipe de façon à ce qu’elle puisse être \n",
      "contactée aisément et qu’elle ait les moyens de répondre \n",
      "rapidement aux demandes reçues.\n",
      "\n",
      "La joignabilité devrait être aussi accompagnée d’un effort \n",
      "résolu pour organiser la médiation et le dialogue entre les \n",
      "systèmes et la société, conformément aux idées dévelop-\n",
      "pées par la Fondation Internet Nouvelle Génération (FING) \n",
      "dans le cadre de l’initiative « NosSystèmes ». La FING \n",
      "constate en effet que « joindre le responsable technique \n",
      "ne suffit pas ». Elle propose ainsi, par exemple, la mise en \n",
      "place d’équipes dédiées à la qualité du dialogue usager \n",
      "ainsi que d’un « pourcentage médiation ». Alors que les \n",
      "algorithmes permettent des économies d’échelle, prendre \n",
      "en compte le pourcentage du budget d’un projet consacré \n",
      "à l’effort de médiation (mise en place d’outils de visualisa-\n",
      "tion, équipe de médiation, partenariat, contrôle de la bonne \n",
      "compréhension de l’information, etc.) pourrait permettre \n",
      "– via des procédures de certification – de valoriser et de \n",
      "conférer un avantage concurrentiel (en termes d’image \n",
      "aux yeux des consommateurs) aux systèmes vertueux.\n",
      "\n",
      "RECOMMANDATION 3\n",
      "Travailler le design des systèmes \n",
      "algorithmiques au service de la liberté \n",
      "humaine\n",
      "\n",
      "Plus  que  l’algorithme  seul,  voire  le  programme  exécu-\n",
      "tant l’algorithme, c’est à l’ensemble du système algorith-\n",
      "mique qu’il s’agit de s’intéresser pour en comprendre et en \n",
      "contrôler les effets. De nombreuses réflexions récentes \n",
      "mettent en avant l’importance de prendre en compte le \n",
      "design des systèmes algorithmiques, c’est-à-dire l’interface \n",
      "entre la machine et son utilisateur.\n",
      "\n",
      "60 Notamment l’article 39 de la Loi Informatique et libertés, organisant le droit d’accès.\n",
      "61 L’article 14.1a du Règlement européen va dans ce sens en prévoyant une telle information.\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLEQUELLES RÉPONSES ?\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "57\n",
      "\n",
      "Il convient ainsi d’agir sur le design pour contrer le caractère \n",
      "de « boîtes noires » que peuvent avoir les algorithmes dès \n",
      "lors qu’ils se présentent comme des systèmes opaques \n",
      "présentant des résultats sans mise en perspective de leurs \n",
      "propres limites ni présentation de la manière dont ils sont \n",
      "construits mais parés du prestige de la neutralité et de \n",
      "l’infaillibilité si facilement prêtées à la machine.\n",
      "\n",
      "en la dévoilant, la pratique de l’astroturfing, c’est-à-dire la \n",
      "manipulation à leur avantage par des groupes très orga-\n",
      "nisés des réseaux sociaux pour imposer certains thèmes \n",
      "à l’ordre du jour de la scène politique nationale. Il parti-\n",
      "cipe ainsi à un rééquilibrage dans l’utilisation des algo-\n",
      "rithmes, dans le but de préserver un accès démocratique \n",
      "à l’information.\n",
      "\n",
      "À l’inverse, il s’agit de promouvoir un design propre à renfor-\n",
      "cer l’autonomie et la réflexivité des personnes, à remédier \n",
      "aux situations d’asymétrie que peuvent établir les algo-\n",
      "rithmes à leur détriment, à leur permettre de prendre des \n",
      "décisions informées et de manière lucide.\n",
      "\n",
      "Par exemple, la mise en place de systèmes de visualisation \n",
      "permettant de redonner plus de contrôle à l’utilisateur en \n",
      "lui donnant une meilleure information va dans ce sens. Des \n",
      "outils de visualisation peuvent permettre à des individus \n",
      "de comprendre pourquoi des recommandations leur ont \n",
      "été proposées voire, encore mieux, de générer en retour \n",
      "des recommandations plus appropriées. Les individus \n",
      "se trouvent par-là même placés dans une posture active. \n",
      "Il s’agit de donner à l’individu la main sur une partie au \n",
      "moins des critères qui déterminent la réponse fournie par \n",
      "l’algorithme, lui permettant éventuellement de tester diffé-\n",
      "rentes réponses en fonction de paramétrages différents. \n",
      "Un exemple d’outil de visualisation a été fourni au cours \n",
      "du débat public par la présentation du « Politoscope62 ». \n",
      "Développé par l’Institut des Systèmes Complexes de Paris-\n",
      "Île de France, le politoscope permet au grand public de \n",
      "plonger dans des masses de données et de voir l’activité \n",
      "et la stratégie des communautés politiques sur les réseaux \n",
      "sociaux et notamment sur Twitter. Il aide à contrebalancer, \n",
      "\n",
      "À travers le design, c’est toute la relation entre l’homme \n",
      "et la machine qui peut être modifiée, dans le sens d’une \n",
      "responsabilisation de l’homme et d’une augmentation de \n",
      "sa capacité à prendre des décisions éclairées, au lieu d’une \n",
      "confiscation au profit de la machine de sa capacité à faire \n",
      "des choix. C’est en somme au principe de vigilance évoqué \n",
      "plus haut qu’il s’agit ici de donner corps.\n",
      "\n",
      "Le concept de « jouabilité » récemment proposé par la FING \n",
      "dans le cadre de son expédition « NosSystèmes » pour-\n",
      "rait également constituer un principe régissant le design \n",
      "de systèmes algorithmiques vertueux, mis au service de \n",
      "l’individu et de sa capacité d’agir dans toute sa plénitude. \n",
      "Il s’agit de permettre aux utilisateurs de « jouer » avec les \n",
      "systèmes en en faisant varier les paramètres. Permettre \n",
      "par exemple aux utilisateurs d’APB de pouvoir le tester « à \n",
      "blanc » en voyant les résultats fournis en fonction de dif-\n",
      "férents choix avant d’entrer leurs vœux définitifs. On pour-\n",
      "rait ainsi imaginer également qu’un moteur de recherches \n",
      "sur internet permette à ses utilisateurs de lancer plusieurs \n",
      "recherches en faisant varier les critères. L’idée de jouabi-\n",
      "lité repose sur le fait que toucher et manipuler est la clé \n",
      "d’une compréhension directe, bien davantage sans doute \n",
      "que l’accès à un code source indéchiffrable pour la grande \n",
      "majorité d’entre nous.\n",
      "\n",
      "À travers le design, \n",
      "c’est toute la relation \n",
      "\n",
      "entre l’homme et la machine \n",
      "\n",
      "qui peut être modifiée, \n",
      "\n",
      "dans le sens d’une\n",
      "\n",
      "responsabilisation de l’homme \n",
      "\n",
      "et d’une augmentation \n",
      "de sa capacité à prendre \n",
      "des décisions éclairées\n",
      "\n",
      "RECOMMANDATION 4\n",
      "Constituer une plateforme nationale \n",
      "d’audit des algorithmes\n",
      "\n",
      "Développer l’audit des algorithmes de manière à contrôler \n",
      "leur conformité à la loi et leur loyauté est une solution fré-\n",
      "quemment évoquée pour assurer leur loyauté, leur respon-\n",
      "sabilité et, plus largement, leur conformité à la loi.\n",
      "\n",
      "Développer l’audit des algorithmes signifie d’abord dévelop-\n",
      "per la capacité de la puissance publique à assurer ce der-\n",
      "nier. L’audit des algorithmes n’est pas une réalité nouvelle. \n",
      "La Commission des sanctions de l’Autorité des marchés \n",
      "financiers s’est ainsi appuyée sur l’analyse de l’algorithme \n",
      "« Soap » pour rendre sa décision du 4 décembre 2015 à \n",
      "\n",
      "62 https://politoscope.org/ \n",
      "\n",
      "\n",
      "58\n",
      "\n",
      "l’égard des sociétés Euronext Paris SA et Virtu Financial \n",
      "Europe Ltd. De même, la CNIL dispose, pour son activité de \n",
      "contrôle, des compétences d’auditeurs des systèmes d’in-\n",
      "formation. L’Autorité de la concurrence doit aussi appuyer \n",
      "de plus en plus son activité sur une capacité à auditer les \n",
      "algorithmes. \n",
      "\n",
      "Il est donc essentiel que la puissance publique se donne \n",
      "autant que possible les moyens d’ouvrir le code source d’al-\n",
      "gorithmes déterministes. Or, ces moyens s’avèrent de plus \n",
      "en plus insuffisants face à un besoin croissant. La CNIL se \n",
      "trouve ainsi désormais sollicitée par d’autres régulateurs \n",
      "sectoriels dépourvus de toute capacité d’audit. Un travail \n",
      "de recensement des ressources de l’État, des différents \n",
      "besoins ainsi qu’une mise en réseau des compétences \n",
      "et des moyens au moyen d’une plateforme nationale est \n",
      "donc aujourd’hui une nécessité.\n",
      "\n",
      "Une telle plateforme devrait aussi avoir pour fonction de \n",
      "relever le défi que soulève le développement du machine \n",
      "learning. Celui-ci conduit certains à souligner que l’exa-\n",
      "men des codes sources s’avère peu réaliste dès lors qu’il \n",
      "s’agit d’analyser des millions de lignes de code. Or, auditer \n",
      "ne signifie pas nécessairement ouvrir les codes sources. \n",
      "Cela peut aussi prendre la forme de contrôles ex post des \n",
      "résultats produits par les algorithmes, de tests aux moyens \n",
      "de profils fictifs, etc. Ces techniques d’audit reposant sur la \n",
      "rétro-ingénierie doivent faire l’objet d’un effort de recherche \n",
      "significatif (cf. recommandation suivante).\n",
      "\n",
      "Opérationnellement, la mise en œuvre de ces audits pourrait \n",
      "être assurée par un corps public d’experts des algorithmes \n",
      "qui contrôleraient et testeraient les algorithmes (en vérifiant \n",
      "par exemple qu’ils n’opèrent pas de discrimination). Une \n",
      "autre solution pourrait consister, notamment face à l’am-\n",
      "pleur du secteur à contrôler, à ce que la puissance publique \n",
      "homologue des entreprises d’audit privées sur la base \n",
      "d’un référentiel. Certaines initiatives privées ont d’ailleurs \n",
      "d’ores et déjà vu le jour. Par exemple, Cathy O’Neil, plusieurs \n",
      "fois citée dans ce rapport, a créé la société «  Online Risk \n",
      "Consulting & Algorithmic Auditing », une entreprise dont \n",
      "l’objectif est d’aider les entreprises à identifier et à corriger \n",
      "les préjugés des algorithmes qu’elles utilisent.\n",
      "\n",
      "Indépendamment même d’une obligation de recourir à la \n",
      "procédure d’audit, il est souhaitable que les entreprises \n",
      "et les administrations se tournent vers des solutions de \n",
      "type « label ». Ces labels pourraient alimenter une dyna-\n",
      "mique vertueuse. D’une part, ils garantiraient la non-dis-\n",
      "crimination et la loyauté des algorithmes. D’autre part, ils \n",
      "offriraient aussi une visibilité aux efforts en vue de la mise \n",
      "en place d’un design ainsi qu’en vue de la mise en place \n",
      "\n",
      "d’une information proactive et adaptée, conformément aux \n",
      "recommandations précédentes, donc, et au-delà même \n",
      "des strictes obligations légales.\n",
      "\n",
      "RECOMMANDATION 5\n",
      "Encourager la recherche de solutions \n",
      "techniques pour faire de la France \n",
      "le leader de l’IA éthique\n",
      "\n",
      "Favoriser l’explication sur le fonctionnement \n",
      "et la logique des algorithmes. \n",
      "Fournir aux régulateurs, aux entreprises et aux citoyens \n",
      "des outils robustes pour contrôler, maîtriser et surveiller \n",
      "les impacts des algorithmes et de l’intelligence artificielle, \n",
      "pour en comprendre la logique de fonctionnement devrait \n",
      "constituer un axe croissant des politiques de recherche. \n",
      "\n",
      "Le développement de techniques de rétro-ingénierie pour \n",
      "« tester » le caractère non discriminatoire, la capacité à \n",
      "pré-traiter les données pour réduire les risques de dis-\n",
      "crimination en identifiant et résolvant les biais des jeux \n",
      "d’apprentissage63, la  génération d’explications en langage \n",
      "naturel par les machines algorithmiques recourant à l’ap-\n",
      "prentissage automatique des résultats qu’elles produisent \n",
      "mériteraient de faire l’objet d’un investissement significatif. \n",
      "\n",
      "En France, le projet TransAlgo, conduit par INRIA, a d’ores \n",
      "et déjà pour objectif de catalyser la dynamique sur ces \n",
      "questions à travers l’élaboration d’une plateforme scien-\n",
      "tifique. Le projet Algodiv (recommandation algorithmique \n",
      "et diversité des informations du web) vise quant à lui à \n",
      "apporter des réponses aux questions posées par la notion \n",
      "d’enfermement : les algorithmes nuisent-ils à la diversité \n",
      "et à la sérendipité ? Ces projets ont en somme pour but de \n",
      "fournir une meilleure compréhension d’un certain nombre \n",
      "de problèmes évoqués dans le présent rapport. \n",
      "\n",
      "Des initiatives visant à articuler interdisciplinarité, recherche \n",
      "de pointe et développement d’outils devraient être soute-\n",
      "nues en France, à l’instar de celle du Professeur Katharina \n",
      "Anna Zweig en Allemagne qui a créé en 2017 le labora-\n",
      "toire « Algorithmic Accountability Lab ». Ce dernier, outre \n",
      "une activité d’analyse appuyée sur les sciences dures, les \n",
      "sciences techniques et les sciences humaines (conformé-\n",
      "ment à l’idée que les systèmes algorithmiques ne peuvent \n",
      "être compris, prédits et contrôlés que dans le contexte de \n",
      "leur application), vise à développer un design transparent, \n",
      "éthique et responsable des systèmes automatisés d’aide \n",
      "à la décision. Il propose en outre des outils didactiques \n",
      "\n",
      "63 La construction d’un jeu de données non-biaisées a fait cette année l’objet d’un projet mené par l’association Open Law, partenaire du débat public animé par la CNIL.\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLEQUELLES RÉPONSES ?\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "QUELLES RÉPONSES ?\n",
      "\n",
      "59\n",
      "\n",
      "concernant les risques et promesses des ADM64 pour, à la \n",
      "fois, le grand public et les preneurs de décision65. \n",
      "\n",
      "Un autre exemple est fourni par la constitution récente aux \n",
      "États-Unis de l’Institut de recherche AI Now (au sein de la \n",
      "New York University) dont l’objet est d’examiner les impli-\n",
      "cations sociales de l’intelligence artificielle. L’implication \n",
      "dans cette structure du « Partnership on AI », initiative \n",
      "notamment d’Amazon, Apple, Google, IBM et Microsoft \n",
      "amène toutefois à souligner l’attention toute particulière \n",
      "qui devrait être attachée à la composition de telles institu-\n",
      "tions. Comme l’a récemment souligné l’ancienne universi-\n",
      "taire Cathy O’Neil, l’importance de l’implication du monde \n",
      "de la recherche dans le travail d’élucidation des impacts \n",
      "sociaux de l’IA tient aussi à la valeur toute particulière de \n",
      "la liberté académique66.\n",
      "\n",
      "Développer des infrastructures de recherche \n",
      "respectueuses des données personnelles\n",
      "Le développement d’une IA respectueuse des données \n",
      "constitue un enjeu croissant alors que les citoyens en \n",
      "Europe, mais aussi plus largement dans le monde entier, \n",
      "se montrent de plus en plus soucieux de la protection de \n",
      "leurs données personnelles et aux risques générés. Diverses \n",
      "pistes peuvent ici être évoquées dans la perspective de la \n",
      "construction d’un nouvel équilibre, fondé sur un renforce-\n",
      "ment symétrique des capacités d’accès des chercheurs \n",
      "à d’importants jeux de données et de la sécurité de ces \n",
      "mêmes données\n",
      "\n",
      "Tout d’abord le développement d’espaces sécurisés pour \n",
      "l’accès à des données à des fins de recherche et d’en-\n",
      "traînement des algorithmes d’intelligence artificielle. Par \n",
      "exemple, des travaux comme ceux conduits dans le cadre \n",
      "du projet OPAL, participent de cette dynamique. Ce pro-\n",
      "jet vise à bâtir une infrastructure sur laquelle les données \n",
      "d’opérateurs téléphoniques sont stockées et peuvent être \n",
      "analysées en toute sécurité au moyen d’algorithmes cer-\n",
      "tifiés mis à disposition des utilisateurs et enrichissables \n",
      "par la communauté. Avec de tels systèmes, les données ne \n",
      "sont pas directement accessibles à ceux qui les exploitent, \n",
      "garantissant la protection des personnes. La certification \n",
      "des algorithmes qui peuvent être utilisés pour analyser \n",
      "ces jeux de données a une fonction de filtrage éthique des \n",
      "données, ce qui permet notamment de faire face aux défis \n",
      "posés en termes de « group privacy67 ».\n",
      "\n",
      "Des bases à la main d’acteurs publics tels que le CASD \n",
      "(Centre d’Accès Sécurisé aux Données) utilisées pour la \n",
      "mise à disposition de bases de données de l’administra-\n",
      "tion à des fins de recherche constituent également une \n",
      "piste à suivre.\n",
      "\n",
      "Lancer une grande cause nationale participative \n",
      "pour dynamiser la recherche en IA \n",
      "La capacité à disposer de très vastes quantités de don-\n",
      "nées constitue l’un des fondements du développement \n",
      "d’une recherche en IA. Contrairement à une image trop \n",
      "souvent répandue, les législations française et européenne \n",
      "proposent un cadre suffisamment ouvert pour soutenir \n",
      "une recherche et une politique industrielle ambitieuses en \n",
      "la matière. Au-delà des possibilités évoquées ci-dessus, \n",
      "la création par le Règlement européen de protection des \n",
      "données (RGPD) d’un « droit à la portabilité », qui permet \n",
      "aux personnes de récupérer leurs données conservées par \n",
      "des acteurs privés, ouvre de grandes opportunités encore \n",
      "largement inconnues.\n",
      "\n",
      "La puissance publique pourrait jouer un rôle moteur dans \n",
      "la concrétisation de ces dernières. Elle pourrait ainsi lan-\n",
      "cer une grande cause nationale ou un grand projet de \n",
      "recherche fondé sur des données issues de la contribution \n",
      "de citoyens exerçant leur droit à la portabilité auprès des \n",
      "acteurs privés et rebasculant leurs données pour un projet \n",
      "au service d’une cause d’intérêt général. L’Etat se porterait \n",
      "garant du respect des libertés par le projet et pourrait, par \n",
      "exemple, soutenir la mise en place d’un tableau de bord \n",
      "(sur le modèle du projet « NosSystèmes » de la FING) à la \n",
      "main des personnes. Au-delà de ce seul projet, la puissance \n",
      "publique amorcerait ainsi les potentialités ouvertes par la \n",
      "création du droit à la portabilité.\n",
      "\n",
      "Les acteurs privés pourraient naturellement apporter leurs \n",
      "propres jeux de données à ce projet et participer à cette \n",
      "grande cause nationale.\n",
      "\n",
      "RECOMMANDATION 6\n",
      "Renforcer la fonction éthique au sein  \n",
      "des entreprises\n",
      "\n",
      "Identifier de possibles irrégularités ou effets néfastes en \n",
      "amont du déploiement d’algorithmes aux impacts signifi-\n",
      "catifs, mais également assurer un rôle de veille en continu \n",
      "pour identifier les problèmes émergents, imperceptibles ou \n",
      "inaperçus au départ, en apportant un contrepoint à la pers-\n",
      "pective des opérationnels s’avère aujourd’hui une fonction \n",
      "essentielle des entreprises. Il s’agit aussi de développer \n",
      "une vision générale de chaînes algorithmiques dont on a \n",
      "souligné la tendance à la segmentation et à la comparti-\n",
      "mentation des fonctions et des préoccupations. Du même \n",
      "impératif participe la nécessité d’organiser des formes de \n",
      "dialogue entre opérationnels, personnalités extérieures à \n",
      "\n",
      "64 Algorithmic Decision Making Systems.\n",
      "65  Plusieurs projets ont déjà émergé de ce laboratoire, notamment, le projet de « dons-de-données » (en allemand « Datenspende Projekte »  \n",
      "\n",
      "https://datenspende.algorithmwatch.org/), dans lequel plus de 4000 utilisateurs ont observé, pendant plusieurs mois avant et jusqu’à l’élection parlementaire allemande, \n",
      "les résultats de recherches Google concernant les 16 principaux candidats. L’idée sous-jacente de ce projet est de mesurer l’impact de la personnalisation par Google \n",
      "des résultats de recherches afin de confirmer ou d’infirmer la théorie appelée « filter bubble ».\n",
      "\n",
      "66 https://www.nytimes.com/2017/11/14/opinion/academia-tech-algorithms.html\n",
      "67  Des projets précédents ont montré que l’usage de données anonymisées était susceptible de générer des usages problématiques du point de vue éthique (ciblage de groupes \n",
      "\n",
      "de population – et non pas forcément d’individus – sur une base ethnique dans des contextes de conflit, segmentation actuarielle, etc.).\n",
      "\n",
      "\n",
      "60\n",
      "\n",
      "Assurer un rôle de veille \n",
      "en continu pour identifier \n",
      "les problèmes émergents, \n",
      "\n",
      "imperceptibles ou\n",
      "inaperçus au départ \n",
      "s’avère aujourd’hui \n",
      "\n",
      "une fonction essentielle \n",
      "\n",
      "des entreprises\n",
      "\n",
      "l’entreprise, acteurs et communautés impliquées par le \n",
      "fonctionnement des algorithmes ainsi que chercheurs en \n",
      "sciences humaines et sociales.\n",
      "\n",
      "Plusieurs modalités de mise en œuvre de cet impératif \n",
      "pourraient être envisagées.\n",
      "\n",
      "Une solution pourrait consister dans le déploiement de \n",
      "comités d’éthique au sein des entreprises déployant des \n",
      "algorithmes aux impacts significatifs. La composition et \n",
      "les modalités d’intervention de tels comités constituent un \n",
      "point essentiel. Publicité ou non des comptes rendus, publi-\n",
      "cité ou non de la composition du comité, degré éventuel \n",
      "d’indépendance: la palette des options possibles est large.\n",
      "\n",
      "L’attribution de cet impératif à la fonction RSE ou aux déon-\n",
      "tologues pourrait également être envisagée.\n",
      "\n",
      "Cette animation de la fonction de réflexion éthique dans le \n",
      "secteur privé pourrait aussi prendre la forme de réseaux \n",
      "constitués par secteurs ou branches professionnelles pour \n",
      "assurer la diffusion de bonnes pratiques ainsi que le repé-\n",
      "rage précoce de problèmes émergents. On pourrait d’ail-\n",
      "leurs même considérer que des comités éthiques sectoriels \n",
      "puissent organiser une forme de veille éthique en lieu et \n",
      "place de comités installés au niveau de chaque entreprise, \n",
      "ce qui constituerait néanmoins une garantie moindre.\n",
      "\n",
      "Ce travail en réseau devrait avoir pour objectif la constitution \n",
      "et la tenue à jour de référentiels éthiques sectoriels (chartes \n",
      "éthiques, codes de conduite, chartes de déontologie etc.), \n",
      "mais également la révision des codes d’éthique profession-\n",
      "nels préexistants pour prendre en compte l’introduction \n",
      "des algorithmes et des systèmes d’IA.\n",
      "\n",
      "Ces réflexions devraient en retour déboucher sur l’intégra-\n",
      "tion, dans les chartes de déontologie des entreprises, d’un \n",
      "chapitre dédié aux enjeux soulevés par les algorithmes \n",
      "(en explicitant par exemple les limites à ne pas franchir en \n",
      "concevant les paramètres des systèmes, des obligations \n",
      "de qualité et d’actualisation des jeux de données utilisés \n",
      "pour entraîner les algorithmes, etc.).\n",
      "\n",
      "Les diverses possibilités évoquées dans les paragraphes \n",
      "précédents ont pour but de souligner que la formule exacte \n",
      "à retenir mériterait sans doute de faire l’objet de débats \n",
      "spécifiques et que, à l’évidence, plusieurs positions peuvent \n",
      "exister.\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLEQUELLES RÉPONSES ?\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "CONCLUSION\n",
      "\n",
      "61\n",
      "\n",
      "CONCLUSION\n",
      "\n",
      "Les principes et les recommandations formulés à l’issue \n",
      "de ce rapport constituent le résultat de la synthèse par la \n",
      "CNIL des échanges et des réflexions menés à l’occasion \n",
      "du débat public national qu’elle a animé, grâce au soutien \n",
      "de soixante partenaires, de janvier à octobre 2017. \n",
      "\n",
      "Les recommandations ont été formulées de façon très \n",
      "large,  mobilisant  tout  le  spectre  possible  des  acteurs \n",
      "publics ou privés. Les défis soulevés par les algorithmes \n",
      "appellent une mobilisation, une attention et un question-\n",
      "nement de la part de l’ensemble des acteurs de la société \n",
      "civile (citoyens, entreprises, associations) pour piloter un \n",
      "monde complexe. Il ne s’agissait donc pas d’avancer que \n",
      "le véhicule à privilégier pour les appliquer ne pouvait être \n",
      "que la loi. Au contraire, la plupart des recommandations \n",
      "sont  susceptibles  d’être  interprétées  comme  pouvant \n",
      "donner  lieu,  ou  bien  à  une  traduction  juridique  contrai-\n",
      "gnante, ou bien à une appropriation volontaire de la part \n",
      "des acteurs, plusieurs degrés étant envisageables entre \n",
      "ces deux extrêmes. \n",
      "\n",
      "Deux principes fondateurs ressortent de cette réflexion. \n",
      "Il  convient  d’y  insister  tout  particulièrement,  tant  ils \n",
      "sont susceptibles de subsumer quelques-uns des défis \n",
      "éthiques majeurs soulevés par l’intelligence artificielle.\n",
      "\n",
      "D’une part, un principe substantiel, le principe de loyauté \n",
      "des algorithmes, dans une formulation approfondissant \n",
      "celle déjà élaborée par le Conseil d’Etat (voir section « Le \n",
      "principe de loyauté »). Cette formulation intègre en effet \n",
      "une dimension de loyauté envers les utilisateurs, non pas \n",
      "seulement en tant que consommateurs, mais également \n",
      "en tant que citoyens, voire envers des collectifs, des com-\n",
      "munautés dont l’existence pourrait être affectée par des \n",
      "algorithmes, que ceux-ci d’ailleurs traitent des données \n",
      "personnelles ou pas. \n",
      "\n",
      "D’autre part, un principe plus méthodologique : le prin-\n",
      "cipe de vigilance. Ce principe de vigilance doit être en-\n",
      "tendu, non comme une vague incantation mais comme \n",
      "une réponse étayée à trois enjeux centraux de la socié-\n",
      "té  numérique.  Premièrement,  le  caractère  évolutif  et \n",
      "imprévisible  des  algorithmes  à  l’ère  de  l’apprentissage \n",
      "automatique  (machine  learning).  Deuxièmement,  le  ca-\n",
      "ractère très compartimenté des chaînes algorithmiques, \n",
      "induisant segmentation de l’action, indifférence aux im-\n",
      "pacts  générés  par  le  système  algorithmique  dans  son \n",
      "ensemble,  dilution  des  responsabilités.  Troisièmement, \n",
      "enfin, le risque d’une confiance excessive accordée à la \n",
      "machine, jugée – sous l’effet d’une forme de biais cogni-\n",
      "\n",
      "tif humain – infaillible et exempte de biais. À travers le \n",
      "principe  de  vigilance,  l’objectif  poursuivi  est  en  somme \n",
      "d’organiser  l’état  de  veille  permanente  de  nos  sociétés \n",
      "à  l’égard  de  ces  objets  socio-techniques  complexes  et \n",
      "mouvants  que  sont  les  algorithmes  ou,  à  proprement \n",
      "parler, les systèmes ou chaînes algorithmiques. Un état \n",
      "de veille, autrement dit un questionnement, un doute mé-\n",
      "thodique. Ceci concerne au premier chef les individus qui \n",
      "composent les maillons des chaînes algorithmiques : il \n",
      "s’agit de leur donner les moyens d’être les veilleurs, lu-\n",
      "cides et actifs, toujours en questionnement, de cette so-\n",
      "ciété numérique. Ceci concerne aussi les autres forces \n",
      "vives de notre société. Les entreprises, bien sûr, pour mo-\n",
      "deler  des  systèmes  algorithmiques  vertueux,  mais  pas \n",
      "seulement.\n",
      "\n",
      "Ces principes, par la démarche universelle dont ils pro-\n",
      "cèdent, pourraient bien s’inscrire dans une nouvelle géné-\n",
      "ration de principes et de droits de l’homme à l’ère numé-\n",
      "rique : cette génération qui après celles des droits-libertés, \n",
      "des  droits  patrimoniaux  et  des  droits  sociaux,  serait \n",
      "celle des droits-système organisant la dimension sous-\n",
      "jacente à notre univers numérique. Ne sont-ils pas sus-\n",
      "ceptibles d’être portés au niveau des principes généraux \n",
      "de  gouvernance  mondiale  de  l’infrastructure  internet  ? \n",
      "À l’heure où se construisent les positions française et eu-\n",
      "ropéenne sur l’intelligence artificielle, la question mérite \n",
      "d’être posée.\n",
      "\n",
      "Les principes de loyauté et de \n",
      "vigilance pourraient s’inscrire \n",
      "dans une nouvelle génération \n",
      "de principes et de droits de \n",
      "l’homme à l’ère numérique : \n",
      "des droits-système organisant \n",
      "la dimension sous-jacente à \n",
      "notre univers numérique \n",
      "\n",
      "\n",
      "62\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "ANNEXES\n",
      "\n",
      "Les applications et les promesses \n",
      "des algorithmes et de l’IA\n",
      "\n",
      "Les pages qui suivent n’ont pas vocation à développer une vision critique. Il s’agit plutôt ici de décrire les grands usages \n",
      "des algorithmes et de l’IA déjà à l’œuvre ainsi que, dans un ordre plus prospectif, certaines promesses aujourd’hui évo-\n",
      "quées principalement par des acteurs dont la posture n’est pas toujours neutre. Il convient de garder à l’esprit qu’une \n",
      "part non négligeable du discours public sur les algorithmes et l’IA – souvent la plus irénique et parfois la plus catastro-\n",
      "phiste – est déterminée par des intérêts commerciaux.\n",
      "\n",
      "Santé\n",
      "\n",
      "L’outil  algorithmique  fait  l’objet  de  larges  promesses. \n",
      "Comme dans chaque secteur, les opportunités dans le \n",
      "champ de la santé doivent cependant être appréhendées \n",
      "avec prudence, notamment du fait des immenses capacités \n",
      "« marketing » des organisations qui les déploient68. Le rôle \n",
      "annoncé et parfois déjà effectif des algorithmes et de l’IA \n",
      "dans le domaine de la santé est indissociable de l’existence \n",
      "de bases de données de plus en plus massives, tant en \n",
      "termes d’individus concernés qu’en terme de quantité de \n",
      "données disponibles sur chacun d’eux. L’algorithme et l’IA \n",
      "permettent justement de tirer parti de cette quantité iné-\n",
      "dite de données disponibles aujourd’hui (données issues \n",
      "des grandes bases médico-administratives rassemblées \n",
      "dans le SNDS69  mais aussi des objets de santé connectée, \n",
      "des dossiers de patients, etc.) pour bâtir des modèles au \n",
      "sein desquels un profil très précis de chaque individu peut \n",
      "être dessiné, ce profil pouvant constituer le soubassement \n",
      "d’une prévision. \n",
      "\n",
      "Ces promesses, qui concernent les grands objectifs de \n",
      "santé publique, concernent d’abord l’idée d’une médecine \n",
      "à la fois prédictive, préventive et personnalisée. L’analyse \n",
      "et la confrontation de mon profil génomique à celui d’indivi-\n",
      "dus similaires et à leurs parcours de santé peuvent aider au \n",
      "diagnostic précoce. Elles peuvent aussi permettre d’évaluer \n",
      "mes chances de développer telle ou telle maladie (cancer, \n",
      "diabète, asthme etc.), de « prédire » en quelque sorte ma \n",
      "santé future et dès lors m’inciter à prendre des mesures \n",
      "\n",
      "en conséquence (grâce à des campagnes de prévention \n",
      "ciblées). L’établissement de profils biologiques affinés per-\n",
      "mettrait également de personnaliser les traitements et \n",
      "stratégies thérapeutiques.\n",
      "\n",
      "L’intelligence artificielle se développe notam-\n",
      "ment en cancérologie. L’un des exemples les \n",
      "plus fréquemment mentionnés à cet égard est \n",
      "celui de Watson, d’IBM. Watson analyse en \n",
      "effet les données génétiques des patients, les \n",
      "informations les concernant recueillies lors de \n",
      "leur admission, leur historique médical et les \n",
      "compare avec 20 millions de données issues \n",
      "d’études d’oncologie clinique pour établir un \n",
      "diagnostic et proposer un traitement. L’école de \n",
      "médecine de l’Université de Caroline du Nord a \n",
      "ainsi conduit en octobre 2016 une expérience \n",
      "montrant que les préconisations de Watson \n",
      "recoupaient les traitements prescrits par les \n",
      "cancérologues dans 99% des 1000 cas de cancer \n",
      "étudiés. Cette expérience a aussi démontré que \n",
      "dans 30% des cas, Watson était à même de pro-\n",
      "poser davantage d’options thérapeutiques que \n",
      "les médecins. Il convient toutefois de consi-\n",
      "dérer avec prudence ces résultats annoncés, \n",
      "par ailleurs promus avec d’importants moyens \n",
      "de communication et de relations publiques.\n",
      "\n",
      "68  Gérard Friedlander, doyen de la faculté de médecine de l’Université Paris Descartes, l’a notamment souligné (événement organisé par l’Hôpital Necker et l’Institut Imagine, \n",
      "\n",
      "le 15 septembre 2017)\n",
      "\n",
      "69 Système national des données de santé.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "63\n",
      "\n",
      "Outre la capacité d’une médecine de plus en plus appuyée \n",
      "sur les algorithmes et sur l’IA à faire fonds sur l’ensemble \n",
      "des variables biologiques, comportementales et environne-\n",
      "mentales, son intérêt réside aussi dans sa capacité à traiter \n",
      "une masse d’informations scientifiques et de recherche \n",
      "qu’aucun médecin n’aurait matériellement la possibilité \n",
      "de maîtriser (à titre d’exemple, on dénombre pas moins \n",
      "de 160 000 publications par an en cancérologie) dans la \n",
      "perspective de formuler un diagnostic.\n",
      "\n",
      "L’intelligence artificielle est aussi susceptible de fournir un \n",
      "appui à la détection de risques sanitaires. Les algorithmes \n",
      "peuvent être utiles pour « repérer l’élévation de l’incidence \n",
      "de maladies ou de comportements à risque, et d’alerter les \n",
      "autorités sanitaires70 ». Par exemple, en France, les liens \n",
      "entre l’utilisation d’une pilule contraceptive de 3ème généra-\n",
      "tion et le risque d’AVC a pu être étudié grâce au traitement \n",
      "algorithmique de la base du Système national des données \n",
      "de santé (SNDS). La mise en œuvre d’un algorithme peut \n",
      "aussi permettre de prédire des risques de maltraitance. Il \n",
      "faut d’ailleurs souligner que ce n’est pas là un fait nouveau. \n",
      "Déjà en 1981, la CNIL avait eu à connaître d’un projet du \n",
      "Ministère de la Santé et des Affaires sociales visant à auto-\n",
      "matiser le signalement d’enfants présentant des risques \n",
      "psycho-sociaux (fichier GAMIN) : sur la base de l’analyse \n",
      "de 70 données différentes, le système devait repérer les \n",
      "cas à examiner en priorité. C’était bien un modèle, maté-\n",
      "rialisé par une série de critères, que l’algorithme permettait \n",
      "d’appliquer automatiquement à de très vastes cohortes.\n",
      "\n",
      "Dans la pratique médicale, les algorithmes sont à certains \n",
      "égards déjà bien implantés pour automatiser des tâches \n",
      "du quotidien. Les logiciels d’aide à la prescription (LAP), \n",
      "une fois une maladie déjà diagnostiquée, sont déjà de \n",
      "précieux outils d’aide à la décision pour les médecins au \n",
      "moment de la saisie d’ordonnances. Ils permettent d’utiliser \n",
      "le dossier d’un patient pour repérer des contre-indications, \n",
      "des allergies ou des interactions médicamenteuses dan-\n",
      "gereuses. Autres applications déjà bien inscrites dans le \n",
      "paysage médical : « l’analyse d’image (imagerie médicale, \n",
      "anatomo-pathologie, dermatologie), l’analyse de signaux \n",
      "physiologiques (électro-cardiogramme, électro-encépha-\n",
      "logramme) ou biologiques (séquençage de génome) »71. \n",
      "L’utilité de l’IA est également mise aujourd’hui en avant pour \n",
      "optimiser la mise en place d’essais cliniques grâce à une \n",
      "automatisation de la sélection des patients.\n",
      "\n",
      "En somme, sous réserve de précautions, l’algorithme en \n",
      "santé permettrait de mieux à répondre à certains besoins \n",
      "« pour les médecins (plus de sécurité), pour les patients \n",
      "(plus de personnalisation), et pour les instances publiques \n",
      "(plus de rationalisation) »72.\n",
      "\n",
      "Éducation\n",
      "\n",
      "L’application désormais la plus connue des algorithmes \n",
      "dans le domaine de l’éducation a trait à l’affectation des \n",
      "immenses effectifs que doit gérer chaque année l’adminis-\n",
      "tration de l’Education nationale et à l’attribution de places \n",
      "en lycée et dans le supérieur en fonction des vœux formulés \n",
      "par les candidats. \n",
      "\n",
      "Le cas de l’algorithme « APB » (Admission post-bac) a été \n",
      "particulièrement évoqué depuis l’été 2016. Déployé depuis \n",
      "2009 afin de faciliter et de fluidifier l’appariement entre \n",
      "les souhaits des élèves émis sous la forme de vœux et \n",
      "les places disponibles dans l’enseignement supérieur, il \n",
      "concernait en 2017 environ 808 000 inscrits dont 607 000 \n",
      "élèves de Terminale ayant candidaté aux 12 000 formations \n",
      "disponibles sur le logiciel. Pour que le système fonctionne, \n",
      "des critères de priorité ont été établis, pour être appliqués à \n",
      "tous. L’objectif poursuivi par APB, et sans évoquer à ce stade \n",
      "les critiques auxquelles il a pu donner lieu, étant double. \n",
      "D’une part, il s’agissait d’automatiser une tâche immense \n",
      "et donc d’optimiser un processus administratif particulière-\n",
      "ment coûteux en temps. D’autre part, APB est aussi crédité \n",
      "d’avoir amélioré un fonctionnement qui laissait auparavant \n",
      "la place à des formes d’arbitraire. Roger-François Gauthier, \n",
      "expert des politiques éducatives, explique ainsi que les algo-\n",
      "rithmes tels qu’APB ou AFELNET (pour la répartition des \n",
      "élèves en lycée) « ont fait quelque chose de remarquable : \n",
      "ils ont mis fin à un fonctionnement mafieux. Auparavant, \n",
      "ces décisions de répartition se prenaient dans le secret \n",
      "des bureaux des proviseurs et des inspecteurs d’académie \n",
      "avec des piles de recommandations ». \n",
      "\n",
      "En  plus  d’être  efficace,  l’algorithme  est  donc  présenté \n",
      "comme assurant l’équité et la non-manipulabilité (chaque \n",
      "lycéen  devant  effectuer  ses  choix  sans  autocensure) \n",
      "puisque la décision est prise de façon automatique, en \n",
      "fonction des données du candidat, de ses vœux d’affec-\n",
      "tation et selon des critères identiques pour tous puisque \n",
      "programmés une fois pour toutes lors du paramétrage de \n",
      "l’algorithme.\n",
      "\n",
      "L’autre grand champ d’application des algorithmes (y com-\n",
      "pris de l’IA) dans l’éducation concerne directement les pra-\n",
      "tiques pédagogiques elles-mêmes. On s’y réfère souvent \n",
      "sous le titre de learning analytics. Ici encore le recours aux \n",
      "algorithmes est indissociable de la capacité inédite à collec-\n",
      "ter des données extrêmement nombreuses et diversifiées : \n",
      "données d’apprentissage (sur les résultats aux exercices \n",
      "mais potentiellement aussi sur la manière dont l’élève s’y \n",
      "confronte, durée de résolution), données sur les interactions \n",
      "avec l’enseignant et avec les pairs, données socio-démo-\n",
      "graphiques, etc.\n",
      "\n",
      "70  INSERM, dossier d’information « Big data en santé » (disponible en ligne)\n",
      "71 Evénement organisé par le Conseil départemental du Rhône de l’Ordre des médecins, le 28 septembre 2017.\n",
      "72 Evénement organisé par le Conseil départemental du Rhône de l’Ordre des médecins, le 28 septembre 2017.\n",
      "\n",
      "\n",
      "64\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "L’analyse des données sur l’apprentissage des élèves à \n",
      "l’aide d’algorithmes et de systèmes d’intelligence artificielle \n",
      "est aujourd’hui conçue comme le moyen de développer \n",
      "des stratégies de personnalisation de l’enseignement. On \n",
      "retrouve ici, comme dans le domaine médical abordé pré-\n",
      "cédemment, la possibilité de la détermination d’un profil \n",
      "très fin de chaque élève mis à profit pour « diagnostiquer » \n",
      "une situation d’apprentissage, pour détecter un éventuel \n",
      "décrochage scolaire mais aussi pour permettre l’élaboration \n",
      "de stratégies individuelles d’apprentissage et de formation, \n",
      "adaptées au profil de chaque élève. La consultation en ligne \n",
      "organisée dans le cadre du débat public par le NumériLab \n",
      "(au sein du Ministère de l’Education Nationale) aborde les \n",
      "intérêts que pourraient revêtir les learning analytics pour \n",
      "la communauté éducative. Dans un contexte français où \n",
      "la différenciation pédagogique par « groupes de besoin » \n",
      "est loin d’être effective, certains contributeurs voient dans \n",
      "l’algorithme la possibilité de « mettre en œuvre des situa-\n",
      "tions individuelles et collectives qui tiennent compte des \n",
      "différentes difficultés rencontrées par les élèves, leur per-\n",
      "mettre d’avoir des parcours individualisés, rendre compte \n",
      "de leur évolution et les faire partager à l’ensemble de la \n",
      "communauté éducative ».\n",
      "\n",
      "Vie de la cité et politique\n",
      "Les algorithmes et l’intelligence artificielle investissent éga-\n",
      "lement le champ de la politique, au double sens du terme, \n",
      "c’est-à-dire tant en ce qui concerne l’organisation de la cité \n",
      "(les politiques publiques) que les pratiques de conquête \n",
      "du pouvoir, la vie électorale.\n",
      "\n",
      "Le cas, précédemment évoqué, de l’algorithme APB en four-\n",
      "nit un exemple. D’autres exemples sont peut-être moins \n",
      "attendus dans la mesure où il peut s’agir d’algorithmes \n",
      "déployés non pas par des administrations mais par des \n",
      "entreprises privées dont l’activité peut avoir un impact \n",
      "direct sur des domaines relevant généralement de l’au-\n",
      "torité publique. Des applications de géolocalisation et de \n",
      "guidage routier mises à disposition des automobilistes \n",
      "peuvent modifier sensiblement les flux de circulation dans \n",
      "une ville et illustrent donc pleinement l’impact des algo-\n",
      "rithmes sur la vie collective. Dans un autre ordre d’idées, \n",
      "la place cruciale que prennent désormais les algorithmes \n",
      "dans la recherche et le filtrage de l’information les situent \n",
      "à un point névralgique de la vie démocratique. Les algo-\n",
      "rithmes de reconnaissance et le machine learning amé-\n",
      "liorent également l’efficacité de la modération automatique \n",
      "de propos déplacés sur les réseaux sociaux ou autres sites \n",
      "hébergeant des contenus : la DGMIC évoque l’ouverture par \n",
      "des sites de presse de leurs articles aux commentaires, \n",
      "l’algorithme permettant ici de favoriser le débat et l’exer-\n",
      "cice du pluralisme.\n",
      "\n",
      "Au cours des dernières années, d’abord aux Etats-Unis, des \n",
      "offres de logiciels d’aide à la stratégie électorale se sont \n",
      "développées. Beaucoup de ces solutions reposent en fait \n",
      "sur la mise en œuvre d’algorithmes prédictifs qui analysent \n",
      "les données électorales. On retrouve ici, une fois encore, \n",
      "l’association entre la capacité des grandes quantités de \n",
      "données et celle – précisément par le biais de l’algorithme – \n",
      "à les exploiter, à les « faire parler » en construisant un \n",
      "modèle à partir de l’analyse des données passées qui est \n",
      "ensuite appliqué aux données actuelles pour élaborer enfin \n",
      "des recommandations, une aide à la décision stratégique. \n",
      "\n",
      "Le logiciel 50+1 déployé depuis 2012 par la société LMP sur \n",
      "le fondement d’une expertise acquise pendant la campagne \n",
      "électorale américaine de 2008 en offre un bon exemple. \n",
      "Son objet est d’accompagner les stratégies électorales des \n",
      "candidats aux élections politiques en leur indiquant les \n",
      "zones à faire cibler en priorité par leurs équipes de militants \n",
      "pour des actions de porte-à-porte. L’algorithme intervient \n",
      "pour analyser les données des élections passées (résultats \n",
      "électoraux bureau de vote par bureau de vote, données \n",
      "socio-démographiques), en inférer un modèle qui, appli-\n",
      "qué à la circonscription faisant l’objet de la campagne du \n",
      "candidat utilisateur du logiciel, permette in fine de formu-\n",
      "ler une prédiction sur la tendance dans l’aire de chaque \n",
      "bureau de vote. Outre l’intérêt que peut présenter ce type \n",
      "de logiciel pour les candidats aux élections, ses promo-\n",
      "teurs le présentent également comme un moyen de lutter \n",
      "contre l’abstention dans le cadre d’une stratégie visant à \n",
      "remobiliser les abstentionnistes. \n",
      "\n",
      "Si la législation française sur la protection des données \n",
      "personnelles ne permet pas le déploiement de logiciels qui \n",
      "cibleraient individuellement les électeurs (à l’exception de \n",
      "ceux y ayant consenti), le terrain électoral américain est un \n",
      "observatoire d’applications des algorithmes et de l’intelli-\n",
      "gence artificielle à des fins de profilage individuel73. Les deux \n",
      "campagnes présidentielles menées par Barack Obama ont \n",
      "vu se déployer de telles campagnes de marketing ciblé. La \n",
      "stratégie électorale de Donald Trump en 2016 semble avoir \n",
      "vu le franchissement d’un nouveau seuil dans le recours \n",
      "à ce type d’outils de communication ciblée74, appuyés sur \n",
      "le recours à des données issues des réseaux sociaux et \n",
      "des courtiers en données. Même si de fortes incertitudes \n",
      "demeurent sur la réalité de ces pratiques, l’envoi de milliers \n",
      "de messages extrêmement individualisés (en fonction des \n",
      "préoccupations et attentes inférées du profil de chaque \n",
      "électeur) au cours d’une même soirée a pu être évoqué75.\n",
      "\n",
      "73  Une autre manière de présenter ces applications est de souligner qu’elles permettent une « prédiction » de ce que pourrait être le comportement d’un électeur ou encore \n",
      "\n",
      "une « recommandation » adressée à l’utilisateur du logiciel quant au type d’action requise en fonction du profil (envoi de tel message, utilisation préférentielle de tel canal de \n",
      "communication).\n",
      "\n",
      "74 En France, les prédictions et recommandations d’un logiciel tel que 50+1 concernent des cohortes de 1000 personnes et ne relèvent donc pas d’outils de ciblage individuel.\n",
      "75 https://www.theguardian.com/politics/2017/feb/26/robert-mercer-breitbart-war-on-media-steve-bannon-donald-trump-nigel-farage \n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "65\n",
      "\n",
      "Culture et médias\n",
      "\n",
      "L’utilisation d’algorithmes et d’intelligence artificielle produit \n",
      "déjà de forts impacts sur la structuration de l’offre de pro-\n",
      "duits culturels et, partant, probablement aussi sur les pra-\n",
      "tiques de consommation culturelle. Différents services de \n",
      "recommandation facilitent la hiérarchisation de l’informa-\n",
      "tion « afin de répondre au besoin de l’utilisateur de s’orien-\n",
      "ter dans la surabondance des contenus accessibles »76. \n",
      "Le recours à ces services de « matching » concerne, à \n",
      "des degrés de développement variables selon la DGMIC, \n",
      "des secteurs très divers au sein de l’industrie culturelle : la \n",
      "vidéo à la demande par abonnement (80 % des contenus \n",
      "visionnés sur Netflix seraient issus de recommandations \n",
      "personnalisées), la musique (la fonctionnalité de recom-\n",
      "mandation apparaît comme un réel enjeu de différenciation \n",
      "pour des services de streaming tels que Spotify ou Deezer), \n",
      "les services gratuits (pour Facebook, Youtube ou encore \n",
      "Google, l’algorithme participe à la maximisation du nombre \n",
      "d’utilisateurs et ainsi à leur exposition augmentée à la publi-\n",
      "cité) ou encore les sites de commerces en ligne (30% des \n",
      "ventes d’Amazon résulteraient de ses recommandations \n",
      "algorithmiques).\n",
      "\n",
      "L’intérêt de tels services est triple : tout d’abord, ils per-\n",
      "mettent de proposer au client une relation plus indivi-\n",
      "dualisée qui accompagne éventuellement la découverte \n",
      "d’autres offres. Ils peuvent également profiter à l’industrie \n",
      "audiovisuelle ou culturelle dans la mesure où ils facilitent \n",
      "« la découverte d’œuvres audiovisuelles qui ne seraient pas \n",
      "par ailleurs programmées en raison de leur petit budget, ou \n",
      "en raison de l’absence d’un distributeur ou d’un budget de \n",
      "promotion ». En effet, « grâce aux moteurs de recomman-\n",
      "dation, certains films peuvent trouver un public même si ces \n",
      "films ne sont pas programmés par les chaînes de télévision \n",
      "traditionnelles »77. Enfin – et peut-être, surtout – l’enjeu éco-\n",
      "nomique est indéniable pour fournisseurs et plateformes \n",
      "qui, en orientant les usagers, augmentent la satisfaction \n",
      "et ainsi l’utilisation de leur service. \n",
      "\n",
      "Toutefois, il convient de nuancer les implications de l’al-\n",
      "gorithme sur le secteur. La DGMIC, qui s’appuie sur les \n",
      "auditions d’une quinzaine d’acteurs du secteur, indique \n",
      "que « la recommandation personnalisée n’a pas tenu toutes \n",
      "ses promesses et que, bien que cette fonction apparaisse \n",
      "aujourd’hui incontournable à l’utilisateur, ce n’est pas celle qui \n",
      "guide majoritairement la consultation et la consommation \n",
      "des contenus », le travail des équipes éditoriales demeurant \n",
      "fondamental. En fonction du perfectionnement futur des \n",
      "algorithmes, la recommandation pourrait néanmoins occu-\n",
      "per une place encore plus prépondérante dans les industries \n",
      "\n",
      "culturelles. A titre d’exemple, la startup Prizm commercia-\n",
      "lise des enceintes qui, en combinant des informations sur \n",
      "le moment de la journée, l’ambiance ou le nombre de per-\n",
      "sonnes dans la pièce, diffusent la playlist la plus adéquate.\n",
      "\n",
      "Ces algorithmes agissent sur le fondement de trois types \n",
      "de données : des données personnelles attachées aux \n",
      "profils des utilisateurs (l’historique d’usage par exemple), \n",
      "des données attachées aux œuvres (mots-clés indexés \n",
      "tantôt manuellement tantôt, depuis peu, de manière auto-\n",
      "matique) et, plus rarement, des données contextuelles \n",
      "(l’heure  d’écoute  ou  la  météorologie,  par  exemple).  La \n",
      "recommandation peut s’exercer selon trois logiques dif-\n",
      "férentes : tout d’abord, un filtrage sémantique peut viser \n",
      "à « placer l’utilisateur sur la « cartographie » des contenus » \n",
      "(DGMIC) sur la base notamment de son historique ou de \n",
      "questionnaires visant à mieux comprendre ses goûts. Une \n",
      "autre approche plus souvent privilégiée, celle du filtrage \n",
      "collaboratif, consiste à recommander en partant de l’hy-\n",
      "pothèse que deux utilisateurs partageant un avis sur un \n",
      "contenu sont plus susceptibles d’être également en accord \n",
      "sur un autre contenu plutôt que deux utilisateurs choisis \n",
      "aléatoirement. Le filtrage collaboratif peut se fonder autant \n",
      "sur le comportement des utilisateurs, leurs consommations \n",
      "passées (« les utilisateurs ayant aimé le contenu A ont aussi \n",
      "aimé le contenu B ») que sur l’objet directement (« si Alice \n",
      "aime les contenus a, b, c et d, et que Benoit aime a, b et c, \n",
      "il est cohérent de recommander d à ce dernier »). Enfin, un \n",
      "filtrage hybride permet de combiner ces deux méthodes \n",
      "pour optimiser la performance de recommandation. Ainsi, \n",
      "l’algorithme de recommandation de Spotify opère de la \n",
      "façon suivante78 :\n",
      "•  En premier lieu, les contenus écoutés (style, tempo) sont \n",
      "analysés (soit plutôt une approche basée sur les conte-\n",
      "nus) ; \n",
      "•  Ensuite, les genres musicaux les plus appréciés sont \n",
      "regroupés en fonction de ceux des autres utilisateurs \n",
      "ayant consommé les mêmes contenus ; \n",
      "•  Enfin, l’utilisateur est circonscrit par rapport à ses propres \n",
      "comportements et son profil (type de consommation, \n",
      "fréquence d’écoute etc.).\n",
      "\n",
      "Autre exemple d’algorithmes dans le champ de la culture : \n",
      "bien qu’embryonnaire, la génération automatique de conte-\n",
      "nus culturels, afin de produire et imiter les contenus qui \n",
      "plaisent, constitue une idée qui séduit. La DGMIC précise \n",
      "néanmoins que « les nombreuses tentatives de prédiction \n",
      "du succès d’un livre ou d’un scénario déjà écrit grâce à des \n",
      "algorithmes n’ont pour l’instant pas permis de découvrir le \n",
      "secret le plus convoité des industries culturelles, industries \n",
      "de prototypes et de risques ».\n",
      "\n",
      "76  DGMIC (Ministère de la Culture), « Les algorithmes dans les médias et les industries culturelles »\n",
      "77   Rapport du CSA Lab, p.14\n",
      "78   CNIL, « Les données, muses et frontières de la création », Cahier IP n°03, octobre 2015\n",
      "\n",
      "\n",
      "66\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "Justice\n",
      "\n",
      "Des évolutions majeures sont à l’œuvre dans l’exercice \n",
      "des métiers du droit et de la justice. Si la plupart n’en sont \n",
      "qu’à un stade de développement anticipé, l’intérêt suscité \n",
      "par les outils technologiques recourant aux algorithmes \n",
      "est grand. L’algorithme peut tout d’abord permettre pour \n",
      "l’avocat ou le juge d’obtenir un appui pour des tâches très \n",
      "variées désormais automatisables, souvent répétitives \n",
      "voire laborieuses : « l’évaluation des éléments de preuve \n",
      "selon différentes méthodes (fiabilité des témoins oculaires, \n",
      "distinction des rumeurs et des témoignages, procédures \n",
      "de discovery, constructions d’explications alternatives), la \n",
      "modélisation du travail des jurys, l’extraction d’informations \n",
      "contenues dans des documents (data mining), l’interpréta-\n",
      "tion des informations (mise en lumière de modèles ou d’as-\n",
      "sociations possibles, hiérarchisation des informations...), la \n",
      "recherche d’informations, la construction d’une argumenta-\n",
      "tion (modélisation de structures d’argumentations, utilisation \n",
      "d’arbres de raisonnements permettant de lier une demande, \n",
      "aux justifications et objections dont elle peut faire l’objet), \n",
      "l’élaboration de documents, de formulaires juridiques et \n",
      "de contrats, ou encore la résolution de différends »79. C’est \n",
      "cependant les promesses de la justice dite « prédictive » ou \n",
      "« prévisionnelle » qui méritent le plus d’attention tant elles \n",
      "pourraient bouleverser la conception « humaniste » de la \n",
      "justice. Elle peut être définie comme l’« outil informatique, \n",
      "reposant sur une base de données jurisprudentielles, qui, \n",
      "à l’aide d’algorithmes de tri et (pour les plus perfectionnés) \n",
      "de « réseaux neuronaux », va permettre d’anticiper quelles \n",
      "seront les statistiques de succès de tel ou tel argument \n",
      "juridique »80.\n",
      "\n",
      "La possibilité d’une justice prévisionnelle a été conditionnée \n",
      "par la présence de bases de données jurisprudentielles tou-\n",
      "jours plus fournies. Si elles n’étaient auparavant pas mises \n",
      "à la disposition de tous, la loi dite « République Numérique » \n",
      "a favorisé la diffusion des décisions de justice administra-\n",
      "tive et judiciaire par le mouvement d’ouverture des données \n",
      "publiques (open data) qu’elle consacre. De nombreuses \n",
      "start-ups81  se saisissent ainsi depuis plusieurs mois de \n",
      "cette nouvelle masse de données pour développer leurs \n",
      "outils de « justice prévisionnelle » dont l’objectif principal \n",
      "est de repérer des récurrences à des fins de prédiction. \n",
      "Les intérêts et exploitations potentiels sont multiformes et \n",
      "recouvre différents champs des métiers du droit, du juriste \n",
      "à l’avocat en passant par le juge. \n",
      "\n",
      "Pour le justiciable et les professionnels du droit, les logi-\n",
      "ciels algorithmiques peuvent être d’une utilité stratégique \n",
      "en optimisant l’identification des solutions statistiquement \n",
      "les plus probables pour un contentieux donné ou le mon-\n",
      "tant prévisible des dommages-intérêts. Cette méthode est \n",
      "notamment adaptée aux contentieux particulièrement pro-\n",
      "pices aux récurrences, tels que le licenciement sans cause \n",
      "\n",
      "réelle et sérieuse ou les prestations compensatoires en cas \n",
      "de divorce. Si ces outils se généralisent au sein des diffé-\n",
      "rentes professions du droit, ils contribueraient au dessein \n",
      "plus général d’une « smartjustice », à savoir une justice \n",
      "animée par des impératifs de meilleure rentabilité avec \n",
      "le minimum de moyens, grâce aux technologies. L’avocat \n",
      "pourrait bénéficier d’un gain significatif de temps – et ainsi \n",
      "se consacrer à des tâches plus gratifiantes d’analyse juri-\n",
      "dique et de contact humain –, tandis que le justiciable pour-\n",
      "rait éviter certains coûts, en faisant le choix de s’entendre \n",
      "à l’amiable plutôt que de saisir le juge dans des cas où \n",
      "les chances du succès d’un procès sont réduites. Pour le \n",
      "fonctionnement du système de justice français dans son \n",
      "ensemble de surcroît, un recours grandissant à ces solu-\n",
      "tions annoncerait une diminution du nombre de saisines \n",
      "et un certain désengorgement des juridictions, éventualité \n",
      "plus qu’attrayante dans le contexte actuel.\n",
      "\n",
      "Parallèlement, les algorithmes prédictifs peuvent être une \n",
      "ressource utile au juge : s’inspirer des recommandations de \n",
      "la « machine », fondées sur les jurisprudences précédentes, \n",
      "lui permettrait d’éclairer ses décisions. C’est l’ambition d’une \n",
      "qualité de la justice augmentée et de l’harmonisation des \n",
      "décisions qui serait au cœur de ce modèle. En d’autres \n",
      "termes, dans la continuité de mesures récentes telles que \n",
      "les barèmes, la « justice prévisionnelle » réduirait l’horizon \n",
      "d’incertitude et participerait à l’évaluation interne des juri-\n",
      "dictions et magistrats.\n",
      "\n",
      "L’aide à la décision fondée sur des algorithmes \n",
      "au service du juge a fait l’objet d’une expéri-\n",
      "mentation cette année par les cours d’appel de \n",
      "Rennes et Douai en partenariat avec le minis-\n",
      "tère de la Justice. Par un communiqué du 9 \n",
      "octobre 2017, le ministère a annoncé que l’outil \n",
      "développé par la start-up Predictice ne s’était \n",
      "pas avéré satisfaisant. De futures expérimenta-\n",
      "tions sont néanmoins prévues, aux prochains \n",
      "stades du développement de l’outil.\n",
      "\n",
      "Le mouvement d’open data n’en est qu’à ses premiers fré-\n",
      "missements : toutes les conditions sont ainsi réunies pour \n",
      "que la justice prévisionnelle prolifère, dans un contexte où \n",
      "1,5 million de décisions seront désormais « anonymisables » \n",
      "chaque année et ainsi mises à disposition sur Jurinet (base \n",
      "interne de la Cour de cassation) et Légifrance.\n",
      "\n",
      "79  Contribution au débat public d’un groupe de travail du Conseil National des Barreaux.\n",
      "80  BOUCQ Romain, « La justice prédictive en question », Dalloz Actualité, 14 juin 2017.\n",
      "81  Predictice, Case Law Analytics ou encore Doctrine.fr constituent des exemples de telles legaltech.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "67\n",
      "\n",
      "Banque, Finance\n",
      "\n",
      "Plusieurs événements récents ont contribué à accroître \n",
      "l’attention publique accordée à l’utilisation d’algorithmes \n",
      "dans le champ financier. Même si le rôle effectif joué par \n",
      "l’algorithme dans le flash crash du 6 mai 2010 pose débat, \n",
      "la chute historique du Dow Jones (environ 9%) a largement \n",
      "interpellé quant aux risques d’emballement, de manipula-\n",
      "tion et de comportements moutonniers associés à ce qui \n",
      "est aujourd’hui désigné sous l’appellation « trading haute \n",
      "fréquence » (THF). Un autre exemple est celui du piratage \n",
      "du compte Twitter de l’agence Associated Press en avril \n",
      "2013 : en surveillant les mots-clefs figurant sur le réseau \n",
      "social, les algorithmes ont conclu à un attentat à la Maison \n",
      "blanche, précipitant ainsi le retrait de milliards d’ordres sur \n",
      "les marchés en quelques secondes.\n",
      "\n",
      "Aussi appelé speed trading ou trading algorithmique, le THF \n",
      "désigne l’automatisation d’arbitrages boursiers qui connaît \n",
      "une ascension fulgurante depuis la fin des années 1990. \n",
      "La directive dite « MIF II »82, qui encadre cette tendance \n",
      "et qui entrera pleinement en application en janvier 2018, \n",
      "définit le THF comme « la négociation d’instruments finan-\n",
      "ciers dans laquelle un algorithme informatique détermine \n",
      "automatiquement les différents paramètres des ordres [...] \n",
      "avec une intervention humaine limitée ou sans intervention \n",
      "humaine » (article 4, paragraphe 39). Ce négoce financier \n",
      "d’un genre nouveau voit ainsi des robots traders d’une rapi-\n",
      "dité remarquable se substituer aux traditionnels « teneurs \n",
      "de marchés ». Prendre des décisions d’investissement et \n",
      "organiser les liquidités ne constituent désormais plus l’apa-\n",
      "nage de l’humain : le robot serait impliqué dans près de \n",
      "70 % des transactions aux Etats-Unis et environ 40 % de \n",
      "celles en Europe. L’algorithme jalonne désormais le proces-\n",
      "sus d’investissement, d’abord en amont par l’identification \n",
      "des opportunités, puis en aval par les règles opératoires \n",
      "d’exécution qui prennent position à l’achat ou à la vente83. \n",
      "Peu de problématiques inédites semblent finalement avoir \n",
      "émergé depuis une quinzaine d’années, et le THF a déjà fait \n",
      "l’objet d’un important effort de régulation et de responsa-\n",
      "bilisation des acteurs84.\n",
      "\n",
      "Si un tel intérêt pour l’automatisation s’est manifesté depuis \n",
      "1995, année de création du THF, c’est parce qu’il redéfinit \n",
      "radicalement la temporalité de la bourse : dans ce sec-\n",
      "teur, l’ampleur de l’écart entre performance humaine et \n",
      "performance technologique est incontestable. Cette vélo-\n",
      "cité implique un second intérêt de taille pour les acteurs \n",
      "du THF (gestionnaires de fonds, institutions bancaires)85  \n",
      "qui, en mettant en œuvre des stratégies d’investissement \n",
      "irréalisables manuellement, voient leurs profits et leur com-\n",
      "pétitivité croître de manière substantielle.\n",
      "\n",
      "L’algorithme dans le champ de la finance, c’est également \n",
      "l’émergence de « robo-advisors » visant à automatiser les \n",
      "services financiers fournis aux clients et la gestion de leurs \n",
      "portefeuilles. Leur niveau de maturité semble néanmoins \n",
      "à ce stade assez faible selon l’Autorité des marchés finan-\n",
      "ciers. Plus facilement mobilisables aujourd’hui, des outils \n",
      "basés sur des algorithmes visent à automatiser la ges-\n",
      "tion des risques et le contrôle de la conformité (la lutte \n",
      "anti-blanchiment, par exemple). Enfin, la personnalisation \n",
      "permise par l’algorithme pourrait mener à des mutations \n",
      "importantes des services financiers proposés aux clients : \n",
      "et si, à terme, une segmentation s’opérait entre une clientèle \n",
      "réduite qui aurait accès à des produits très sophistiqués \n",
      "comparativement à une autre qui se verrait proposer un \n",
      "éventail très réduit de produits simples ?\n",
      "\n",
      "Sécurité, défense\n",
      "Le recours aux algorithmes dans le domaine de la sécu-\n",
      "rité et de la défense a pour finalités principales annoncées \n",
      "l’identification de suspects, la prédiction de commission \n",
      "d’infractions et l’automatisation d’opérations de maintien de \n",
      "l’ordre voire de guerre, jusqu’à l’acte de tuer, cette dernière \n",
      "finalité faisant l’objet d’un vif débat international.\n",
      "\n",
      "Les années 2000 ont vu converger accroissement de la \n",
      "menace terroriste dans le sillage du 11 septembre 2001 et \n",
      "de l’explosion du nombre de données disponibles (liée à la \n",
      "numérisation globale des sociétés). Le problème, classique \n",
      "pour le renseignement, de l’analyse et de l’exploitation des \n",
      "données disponibles s’en trouve accru. Dans un contexte \n",
      "d’exigence politique très forte à l’égard des services de \n",
      "renseignement, les algorithmes sont présentés – à tort \n",
      "ou à raison – comme une solution permettant d’identi-\n",
      "fier les suspects en tirant pleinement partie des données \n",
      "disponibles. Le système API-PNR ou les « boîtes noires » \n",
      "évoquées lors de la discussion de la loi sur le renseigne-\n",
      "ment de 2015 relèvent de cette logique. Les données des \n",
      "passagers aériens, dans un cas, celles de l’ensemble de la \n",
      "population, dans l’autre, sont filtrées par des algorithmes \n",
      "à la recherche de « signaux faibles », de profils considérés \n",
      "comme suspects en fonction de critères tenus secrets. \n",
      "\n",
      "L’essor de l’idée de « police prédictive » correspond à l’idée \n",
      "de prédire la commission d’infractions au moyen de l’ana-\n",
      "lyse massive de données concernant la commission passée \n",
      "de crimes et de délits afin de répartir plus efficacement les \n",
      "patrouilles. La promesse portée par exemple par le logiciel \n",
      "américain « Predpol » est d’adosser les méthodes policières \n",
      "traditionnelles jugées trop subjectives par des méthodes \n",
      "considérées comme « objectives ». \n",
      "\n",
      "82  Directive 2014/65/UE du Parlement européen et du Conseil du 15 mai 2014 concernant les marchés d’instruments financiers.\n",
      "83 Benghozi P.-J., Bergadaà M., Gueroui F., Les temporalités du web, 2014, chapitre 3 «Trading haute fréquence : l’arbitre sans sifflet ».\n",
      "84 Directive 2014/65/UE du Parlement européen et du Conseil du 15 mai 2014 ; loi n° 2013-672 du 26 juillet 2013 de séparation et de régulation des activités bancaires.\n",
      "85 Getco, Flow traders, IMC, Quantlab, Optiver...\n",
      "\n",
      "\n",
      "68\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "Ces initiatives soulèvent pourtant d’importantes critiques. \n",
      "Le sociologue Bilel Benbouzid conteste ainsi à propos du \n",
      "logiciel « PredPol » la pertinence de l’application à la cri-\n",
      "minalité de logiques empruntées à la sismologie. L’attrait \n",
      "présenté par « Predpol » aux yeux de décideurs tiendrait en \n",
      "revanche à ce que ce type d’outils permet de « gérer, selon \n",
      "des critères gestionnaires, l’offre publique de vigilance quo-\n",
      "tidienne »86. Par ailleurs, leurs résultats concrets semblent \n",
      "pour l’heure décevants aux praticiens eux-mêmes. Par \n",
      "exemple, l’expérimentation « PredVol » visant la prédiction \n",
      "des actes de délinquance commis sur les véhicules aboutit \n",
      "« à faire ressortir toujours les mêmes spots, les mêmes \n",
      "points chauds aux mêmes endroits » selon le Colonel \n",
      "Philippe Mirabaud. Aussi, l’étude des vols avec violence \n",
      "sans arme contre les femmes sur la voie publique à Paris87  \n",
      "révèle la forte régularité de ces actes – aussi bien en termes \n",
      "de localisation que d’horaires – mais les possibilités pré-\n",
      "dictives restent limitées. Ce constat repose en partie sur \n",
      "les difficultés à « faire parler » des jeux de données encore \n",
      "disparates. La plupart des outils dits « prédictifs » s’appuient \n",
      "sur les données des préfectures de police – plaintes des \n",
      "victimes et/ou arrestations notamment – dont l’utilisation à \n",
      "des fins de prédiction est loin d’être naturelle. Le perfection-\n",
      "nement de ces logiciels implique de les compléter par des \n",
      "données externes concernant autant le terrain des actes \n",
      "(densité de bars ou commerces, présence d’une station de \n",
      "métro etc.) que les conditions météorologiques ou encore \n",
      "les événements organisés au sein d’une ville par exemple.\n",
      "\n",
      "Les experts invitent à ne pas sombrer dans le fétichisme \n",
      "technologique en pensant que l’algorithme aurait la capacité \n",
      "d’apporter une solution magique aux enjeux de sécurité. \n",
      "Gilles Dowek explique ainsi que « même avec un système \n",
      "d’une performance extrêmement élevée, il y aura toujours \n",
      "beaucoup plus d’innocents que de coupables accusés. \n",
      "Supposons un algorithme d’une super-qualité qui n’a qu’une \n",
      "chance sur 100 de se tromper. Sur 60 millions de personnes, \n",
      "ça fait 600 000 personnes détectées à tort, plus les 1 000 \n",
      "« vrais positifs » qu’on a bien détectés. Donc l’algorithme \n",
      "détecte 601 000 personnes, parmi lesquelles en réalité 1 \n",
      "000 seulement sont de vrais terroristes  ». Le risque est donc \n",
      "de démultiplier la suspicion et de confronter les services de \n",
      "renseignement à une masse de cibles impossible à traiter.\n",
      "\n",
      "Au-delà de l’identification de zones à risque, l’algorithme \n",
      "peut servir d’aide à la résolution des enquêtes. En s’ap-\n",
      "puyant sur les connexions entre l’ensemble des pièces d’une \n",
      "enquête – dont celles au caractère très technique comme \n",
      "procès-verbaux, appels téléphoniques ou encore informa-\n",
      "tions bancaires –, des logiciels offriraient aux gendarmes \n",
      "la possibilité d’identifier des relations que l’humain n’était \n",
      "jusqu’ici pas parvenu à effectuer89.\n",
      "\n",
      "Si tout invite à modérer l’enthousiasme des promoteurs de \n",
      "la police prédictive, des perspectives intéressantes résident \n",
      "dans l’appui à la contextualisation, à l’interprétation et ainsi \n",
      "à l’organisation. Hunchlab, projet de l’entreprise Azavea, \n",
      "œuvre ainsi en ce sens en accentuant l’effort d’intelligibilité \n",
      "quant à ce que la prédiction permet ou ne permet pas, par \n",
      "une rétroaction plus solide et une interaction plus forte \n",
      "entre l’humain et l’outil. Dans tous les cas, s’il est difficile \n",
      "de préciser les contours des futures solutions privilégiées \n",
      "et malgré des réserves au sein de la communauté scienti-\n",
      "fique, les pouvoirs publics n’excluent pas d’y avoir recours \n",
      "pour « la constitution d’une aide à la décision (« analyse \n",
      "décisionnelle »), au profit du commandant d’unité territoriale, \n",
      "notamment à des fins de prévention de la délinquance »90.\n",
      "\n",
      "Extrêmement sensible est enfin la question posée par le \n",
      "développement d’armes létales autonomes (robots tueurs) \n",
      "qui pourraient prendre elles-mêmes la décision de tuer sur \n",
      "le champ de bataille ou à des fins de maintien de l’ordre. \n",
      "De tels systèmes sont déjà déployés à la frontière entre \n",
      "les deux Corée et les armées de divers pays réfléchissent \n",
      "actuellement à la mise en service de drones tueurs capables \n",
      "d’engager et d’éliminer une cible sans intervention humaine. \n",
      "En 2015, une pétition signée par plus d’un millier de per-\n",
      "sonnalités, dont une majorité de chercheurs en IA et en \n",
      "robotique, ont réclamé l’interdiction des armes autonomes, \n",
      "capables « de sélectionner et de combattre des cibles sans \n",
      "intervention humaine ». Cette initiative a donné de la visibilité \n",
      "à un débat international déjà engagé à l’ONU.\n",
      "\n",
      "Assurance\n",
      "Les algorithmes offrent tout d’abord au secteur assuran-\n",
      "tiel la possibilité d’accélérer et de fluidifier des pratiques \n",
      "quotidiennes telles que la gestion des sinistres, le suivi du \n",
      "comportement des assurés, leur indemnisation ou encore la \n",
      "lutte contre la fraude. La reconnaissance d’images permise \n",
      "par l’IA pourrait mener à systématiser, grâce à l’analyse des \n",
      "images de sinistres, les processus d’indemnisation « auto » \n",
      "et habitation . Autre exemple : l’intelligence artificielle, en \n",
      "révélant des liens insoupçonnés, peut se révéler utile pour \n",
      "retrouver les titulaires de contrats d’assurances-vie en \n",
      "déshérence (non réclamés) ou leurs héritiers. Mais, plus \n",
      "qu’un instrument d’automatisation au service de pratiques \n",
      "déjà bien implantées, l’algorithme annonce un nouveau \n",
      "paradigme de l’assurance et du mutualisme au sens où il \n",
      "pourrait « modifier la manière d’appréhender les risques et \n",
      "de les valoriser, transformer les techniques et les pratiques \n",
      "de mutualisation » (François Ewald92).\n",
      "\n",
      "Certes la donnée a toujours constitué la matière première \n",
      "pour l’assureur pour prévenir les risques. Assurer, c’est pro-\n",
      "\n",
      "86  Bilel Benbouzid, « A qui profite le crime ? », La Vie des Idées. « PredPol » prétend s’inspirer des méthodes de prédiction des tremblements de terre pour offrir \n",
      "\n",
      "une « analyse du crime en temps réel qui prend la forme d’un tableau de bord ».\n",
      "\n",
      "87 Le géostaticien Jean-Luc Besson l’a exposée lors du même événement organisé par l’INHESJ.\n",
      "88 http://tempsreel.nouvelobs.com/rue89/rue89-internet/20150415.RUE8669/l-algorithme-du-gouvernement-sera-intrusif-et-inefficace-on-vous-le-prouve.html \n",
      "89 Le loigiciel AnaCrime a ainsi permis il y a quelques mois de relancer l’ « affaire Gregory ».\n",
      "90 Réponse du Ministère de l’Intérieur à la question n°16562, publiée dans le JO Sénat du 29 décembre 2016.\n",
      "91 Evénement organisé par la Fédération Française de l’Assurance, le 5 juillet 2017.\n",
      "92 François Ewald, « After Risk, vers un nouveau paradigme de l’assurance. L’Assurance à l’âge du Big Data », septembre 2013.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "69\n",
      "\n",
      "poser des services financiers de protection différents selon \n",
      "des profils de risque, grâce au traitement de données à \n",
      "caractère prédictif. Florence Picard (Institut des actuaires)93 \n",
      "explique ainsi comment l’actuaire a toujours eu pour rôle de \n",
      "de calculer la probabilité et l’impact financier des risques. \n",
      "Loin de l’appréciation globale fondée sur les déclarations \n",
      "des clients, l’algorithme annonce une évaluation plus fine \n",
      "s’appuyant sur des données comportementales en masse.\n",
      "\n",
      "Objets connectés, réseaux sociaux, données de santé : de \n",
      "nouveaux horizons s’ouvrent vers une personnalisation sans \n",
      "précédent. Ce sont des corrélations inédites et individua-\n",
      "lisées qui sont ici recherchées. A titre d’exemple, certains \n",
      "assureurs auraient constaté que les clients achetant des \n",
      "feutres à placer sous les pieds de table et de chaise, pour \n",
      "la préservation du bon état de leur parquet, ont un com-\n",
      "portement automobile bien plus prudent que la moyenne, \n",
      "et qu’une réduction de prime apparaîtrait ainsi comme jus-\n",
      "tifiée94. Le risque peut dès lors être bien plus subjectivisé, \n",
      "individualisé. C’est, selon François Ewald, le passage de la \n",
      "notion de risque comme événement à celle de risque de \n",
      "comportement : « les risques [...] étaient d’abord appréhen-\n",
      "dés par leurs caractéristiques objectives, à partir des événe-\n",
      "ments qui en marquent la réalisation [...] on peut désormais \n",
      "les observer comme caractéristiques du comportement des \n",
      "agents ». L’assurance comportementale concerne déjà les \n",
      "comportements des automobilistes à travers les coefficients \n",
      "de réduction-majoration (plus connus sous le nom de bonus \n",
      "ou malus) fondement du « pay as you drive » (qui se fonde \n",
      "sur les antécédents des conducteurs notamment en termes \n",
      "de vitesse moyenne). Plus encore, l’adaptation du coût des \n",
      "offres selon le style de conduite (accélérations, freinages \n",
      "brusques) est également possible grâce aux capteurs dont \n",
      "certains véhicules sont équipés (« pay how you drive »).\n",
      "\n",
      "En santé, l’individualisation ne mène pas encore à une seg-\n",
      "mentation tarifaire explicite, mais le programme Vitality \n",
      "de la société Generali révèle comment un système de \n",
      "récompenses peut indirectement permettre de s’adapter \n",
      "aux comportements des clients. Vitality se présente comme \n",
      "un programme visant à améliorer le bien-être en mettant à \n",
      "disposition « des recommandations et des outils pour [...] \n",
      "encourager à mener une vie plus saine » et en récompensant \n",
      "ceux qui atteignent leurs objectifs – plutôt qu’en pénalisant \n",
      "ceux qui ne les atteignent pas – « grâce à des réductions et \n",
      "des offres avantageuses » chez des partenaires95. « Likes » \n",
      "émis sur les réseaux sociaux et données de profil sur \n",
      "Facebook,  par  exemple,  pourraient  également  servir  à \n",
      "proposer des tarifs automobile avantageux.\n",
      "\n",
      "Qui dit risque individualisé dit possibilité de services de \n",
      "prévention augmentés qui vont « agir directement sur la \n",
      "\n",
      "source du risque pour tenter d’éviter qu’il survienne » (par \n",
      "des incitations relatives à l’activité physique, la nutrition \n",
      "etc.), comme l’explique Fabrice Faivre (MACIF)96. Argument \n",
      "de santé publique en faveur des assurés, l’individualisa-\n",
      "tion annonce aussi des modèles renégociés en assurance, \n",
      "fondés sur la détection des profils à haut risque et sur une \n",
      "nouvelle relation possible des assureurs au client.\n",
      "\n",
      "La portée de cette personnalisation mérite toutefois d’être \n",
      "nuancée : une segmentation tarifaire trop fine ne serait pas \n",
      "nécessairement dans l’intérêt d’un assureur, du fait des \n",
      "conséquences potentielles qu’impliquerait une erreur en \n",
      "absence de volumes significatifs. Il reste encore à savoir si \n",
      "le cadre légal actuel est adapté à un tel mouvement. Celui-ci \n",
      "tend à restreindre l’utilisation de données par les assureurs \n",
      "au nom de principes tels que la protection des données à \n",
      "caractère personnel (le SNDS créé par la loi de « modernisa-\n",
      "tion de notre système de santé » limite l’accès des assureurs \n",
      "aux données de santé) ou la lutte contre les discriminations. \n",
      "A titre d’exemple, la Cour de justice de l’Union européenne \n",
      "interdit l’utilisation du genre comme variable au sein d’un \n",
      "modèle statistique en assurance au nom du principe d’égalité \n",
      "de traitement entre les hommes et les femmes97. Florence \n",
      "Picard (Institut des Actuaires)98  émet des réserves quant à la \n",
      "pertinence d’écarter un tel critère qui pourrait trouver toute sa \n",
      "place dans certains modèles. Cécile Wendling (AXA)99 men-\n",
      "tionne comment cette obligation du droit européen pourrait \n",
      "toutefois être mise à mal si les algorithmes de machine lear-\n",
      "ning venaient à se déployer, inférant ainsi par eux-mêmes les \n",
      "critères permettant d’identifier le genre (couleur d’un véhicule \n",
      "etc.). En somme, l’avenir de ces pratiques semble aujourd’hui \n",
      "dépendre, d’une part, du degré de développement futur des \n",
      "objets connectés et, d’autre part, de la volonté qu’auront \n",
      "les citoyens de transmettre volontairement et consentir à \n",
      "l’utilisation de certaines des données les concernant pour \n",
      "améliorer leur santé par exemple. \n",
      "\n",
      "Emploi, RH, recrutement\n",
      "Alors que chômage et conditions de travail sont au centre \n",
      "des préoccupations sociétales, les initiatives convoquant \n",
      "des algorithmes foisonnent pour répondre aux grands \n",
      "enjeux du marché de l’emploi.\n",
      "\n",
      "Les particuliers, d’une part, peuvent recourir à des agré-\n",
      "gateurs d’offres d’emploi qui se perfectionnent. L’APEC \n",
      "(Association pour l’emploi des cadres) dispose par exemple \n",
      "d’un algorithme sémantique permettant non seulement de \n",
      "rechercher les offres d’emploi selon des mots-clés, mais \n",
      "également d’induire automatiquement d’un CV le référentiel \n",
      "de compétences et de talents qui permettra de suggérer \n",
      "ensuite les offres d’emploi le plus finement possible100. Pôle \n",
      "\n",
      "   93  Evénement organisé par la Ligue des Droits de l’Homme, le 15 septembre 2017.\n",
      "   94  Dominique Cardon, A quoi rêvent les algorithmes, Paris, 2015, p.52\n",
      "   95  Site officiel de Vitali.\n",
      "   96  Evénement organisé par la Ligue des Droits de l’Homme, le 15 septembre 2017.\n",
      "   97  CJUE, 1er mars 2011, affaire C-236/09 dite « Test-Achats »\n",
      "   98  Evénement organisé par Fotonower, le 22 septembre 2017.\n",
      "   99  Evénement organisé par la Chaire IoT de l’ESCP Europe, le 20 septembre 2017.\n",
      "100 Le Directeur des systèmes d’information de l’APEC a présenté cet outil lors de l’événement organisé par FO-Cadres, le 18 avril 2017.\n",
      "\n",
      "\n",
      "70\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ANNEXES\n",
      "\n",
      "Emploi dispose également de sa propre solution algorith-\n",
      "mique d’agrégation des offres d’emploi.\n",
      "Dans le cadre d’une réflexion éthique, c’est surtout l’appro-\n",
      "priation par les entreprises – et notamment les directions \n",
      "des  ressources  humaines  (DRH)  –  qui  interpelle.  Sans \n",
      "impliquer une réelle rupture des missions traditionnelles \n",
      "du DRH, l’algorithme faciliterait l’atteinte des objectifs de \n",
      "recrutement et de gestion des ressources humaines, à \n",
      "savoir : répondre aux attentes de rapidité dans la mobilité \n",
      "et le recrutement, accentuer l’emprise des collaborateurs \n",
      "sur leur propre parcours et, enfin, mettre à la disposition des \n",
      "managers la ressource adéquate pour l’atteinte des objec-\n",
      "tifs101. C’est notamment le coût de la « mauvaise embauche » \n",
      "qui pourrait être évité, voire la réduction à une échelle plus \n",
      "large du chômage. Prédire pour mieux satisfaire collabo-\n",
      "rateur et manager, en tirant profit d’une masse de données \n",
      "pertinentes : telle est la promesse de l’algorithme.\n",
      "\n",
      "Recrutement : L’algorithme peut constituer un \n",
      "instrument de « matching » affinitaire, basé \n",
      "sur la sémantique, mobilisé par le DRH pour \n",
      "préqualifier le volume parfois conséquent de \n",
      "CV reçus pour une offre d’emploi donnée. Au \n",
      "vu de la durée moyenne très réduite de qualifi-\n",
      "cation d’un CV par un humain, nombreux sont \n",
      "ceux qui invoquent la plus grande « rigueur » \n",
      "de l’algorithme. La Harvard Business Review \n",
      "publiait ainsi une étude en 2014 affirmant qu’un \n",
      "algorithme peut surpasser le recruteur humain \n",
      "et éviter des présupposés fréquents chez ce \n",
      "dernier, tels que la tendance à corréler sys-\n",
      "tématiquement prestige d’une université et \n",
      "performance future.\n",
      "Gestion des RH : L’algorithme pourrait identi-\n",
      "fier les collaborateurs les plus à même d’être \n",
      "performants dans un rôle déterminé, en allant \n",
      "chercher ceux qui n’auraient pas candidaté à \n",
      "une offre de poste donnée. La mobilité interne \n",
      "serait également optimisée par le ciblage de \n",
      "formations appropriées pour un collaborateur \n",
      "afin d’esquisser pour lui un nouveau chemine-\n",
      "ment de carrière.\n",
      "Qualité de vie : D’autres applications, pour les-\n",
      "quelles la réflexion éthique est plus que de rigueur, \n",
      "concernent  la  compréhension  de  certains \n",
      "phénomènes sociaux au sein de l’entreprise : \n",
      "analyse des facteurs justifiant l’absentéisme, \n",
      "prédiction des risques psychosociaux, calcul \n",
      "du risque de départ d’une organisation etc.\n",
      "\n",
      "C’est bien la donnée qui constitue ici le matériau à faire \n",
      "fructifier  pour  résoudre  certains  défis  du  marché  de \n",
      "l’emploi, à commencer par l’insuffisance de méthodes \n",
      "traditionnelles de recrutement (CV, entretiens) considé-\n",
      "rées lacunaires pour « atteindre » l’intimité de l’individu. \n",
      "Aptitudes comportementales et cognitives (« soft skills ») \n",
      "sont désormais plus activement recherchées : l’algorithme \n",
      "capitalise sur la donnée répartie au sein voire à l’extérieur \n",
      "de l’entreprise pour œuvrer en ce sens.\n",
      "\n",
      "Ce sont d’abord les données internes à une organisation \n",
      "qui peuvent alimenter l’algorithme, à condition qu’elles \n",
      "puissent être rassemblées et fiabilisées. Si ces données \n",
      "existent, elles sont « détenues pour partie par les colla-\n",
      "borateurs, pour partie par les fonctions RH et pour partie \n",
      "pour les managers »102  et elles s’inscrivent plus dans une \n",
      "« logique de “rendre compte” que d’exploitation pour des \n",
      "motifs précis »103.\n",
      "\n",
      "Parfois  jugées  insuffisantes,  la  collecte  de  données \n",
      "externes (telles que les informations relatives aux par-\n",
      "cours professionnels publiées sur les réseaux sociaux) est \n",
      "également attrayante pour de nombreuses organisations.\n",
      "\n",
      "Les  traitements  algorithmiques  semblent  encore \n",
      "aujourd’hui limités104, les quelques exemples existants \n",
      "aujourd’hui ne recourant pas à l’intelligence artificielle \n",
      "et au machine learning. Le frémissement est cependant \n",
      "tangible : le nombre de start-ups ayant pour objet les \n",
      "RH est passé de 200 à 600 en l’espace de deux ans105. \n",
      "Il est trop tôt pour évaluer de manière certaine l’impact \n",
      "qu’auront ces technologies sur les pratiques de recru-\n",
      "tement  et  la  gestion  des  talents106.  N’est-il  pas,  par \n",
      "exemple,  trop  ambitieux  d’affirmer  qu’un  algorithme \n",
      "pourrait se substituer à l’homme pour effectuer le tra-\n",
      "vail conséquent qu’implique l’évaluation annuelle des \n",
      "collaborateurs ? En matière de recrutement, l’abandon \n",
      "par Google de son système de tri automatisé des candi-\n",
      "datures semble révéler certaines limites de l’algorithme. \n",
      "Le perfectionnement des outils pourrait émaner de nou-\n",
      "veaux développements en intelligence artificielle – des \n",
      "algorithmes qui construiraient leurs propres référentiels – \n",
      "ou  encore  d’un  recours  grandissant  à  la  robotique \n",
      "(l’analyse de l’expressivité émotionnelle lors d’un entre-\n",
      "tien  de  recrutement  en  constitue  une  illustration107). \n",
      "Ces nouveaux outils pourraient engendrer de nouveaux \n",
      "risques : comment distinguer en RH les décisions simples \n",
      "facilement automatisables des décisions complexes pour \n",
      "lesquelles la dimension « humaine » de la profession devra \n",
      "être préservée ?\n",
      "\n",
      "101  Analyse de Jean-Cristophe Sciberras, directeur des RH France et directeur des relations sociales corporate chez Solvay, lors de l’événement organisé par la CFE-CGC.\n",
      "102 Sabine Frantz lors de l’événement de FO-Cadres.\n",
      "103 Béatrice Ravache lors de l’événement de la CFE-CGC.\n",
      "104  Le service des « questions sociales et RH » de la CNIL ne recense aujourd’hui aucune demande d’autorisation pour de tels traitements à dimension prédictive \n",
      "\n",
      "et n’est consulté qu’à titre informationnel afin de connaître l’avis de la Commission.\n",
      "\n",
      "105 Jérémy Lamri, fondateur du LabRH, lors de l’événement de la CFE-CGC.\n",
      "106  Béatrice Ravache, lors de l’événement de la CFE-CGC, évoque au sujet de la fonction de DRH que « le savoir n’est plus la mémoire, n’est plus l’organisation des données, \n",
      "\n",
      "ni aller les chercher, c’est encore autre chose qui n’est pas forcément évident pour le RH aujourd’hui ».\n",
      "\n",
      "107 Laurence Devillers, événement CFE-CGC.\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "REMERCIEMENTS\n",
      "\n",
      "71\n",
      "\n",
      "REMERCIEMENTS\n",
      "\n",
      "La CNIL adresse ses plus vifs remerciements aux personnes et aux institutions qui ont apporté leur participation \n",
      "à cette réflexion collective.\n",
      "\n",
      "Les partenaires du débat public\n",
      "\n",
      "•  Académie des technologies\n",
      "•  Agence Française de Développement (AFD)\n",
      "•   Association française de droit du travail et de la sécurité \n",
      "sociale (AFDTSS)\n",
      "•   Association française pour l’intelligence artificielle (AFIA)\n",
      "•   Caisse des dépôts et consignations (CDC)\n",
      "•   Centre de recherche de l’école des officiers \n",
      "de la gendarmerie nationale (CREOGN)\n",
      "•   Collège des Bernardins\n",
      "•   Comité consultatif national d’éthique (CCNE)\n",
      "•   Comité d’éthique du CNRS (COMETS)\n",
      "•   Commission de réflexion sur l’Éthique de la Recherche en \n",
      "sciences et technologies du Numérique (CERNA) d’Allistene\n",
      "•   Communication Publique\n",
      "•   Confédération française de l’encadrement – Confédération \n",
      "générale des cadres (CFE-CGC)\n",
      "•   Conseil départemental du Rhône de l’Ordre des Médecins\n",
      "•   Conseil National des Barreaux (CNB)\n",
      "•   Conseil Supérieur de l’Audiovisuel (CSA)\n",
      "•   Conservatoire National des Arts et Métiers (CNAM)\n",
      "•   Cour administrative d’appel de Lyon\n",
      "•   Cour d’appel de Douai\n",
      "•   École des Hautes Etudes en Sciences Sociales (EHESS)\n",
      "•   École Nationale Supérieure de Cognitique (ENSC)\n",
      "•   ESCP Europe, Chaire IoT\n",
      "•   Etalab\n",
      "•   Faculté de Droit de l’Université Catholique de Lille, Centre \n",
      "de recherche sur les relations entre le risque et le droit\n",
      "•   Faculté de Droit de l’Université Catholique de Lyon\n",
      "•   Familles rurales\n",
      "•   Fédération Française de l’Assurance (FFA)\n",
      "•   FO-Cadres\n",
      "•   Fondation Internet Nouvelle Génération (FING)\n",
      "•   Fotonower\n",
      "•   Génotoul societal\n",
      "\n",
      "Les autres contributeurs\n",
      "•   Arbre des connaissances\n",
      "•   Autorité de contrôle prudentiel et de résolution (ACPR)\n",
      "•   Autorité des marchés financiers (AMF)\n",
      "•   Montpellier Méditerranée Métropole et son président, \n",
      "M. Philippe Saurel\n",
      "•   Ville de Montpellier\n",
      "\n",
      "Les 37 citoyens ayant pris part à la concertation citoyenne \n",
      "organisée à Montpellier le 14 octobre 2017.\n",
      "\n",
      "•   Groupe VYV (MGEN – ISTYA – Harmonie)\n",
      "•   Hôpital Necker\n",
      "•   INNOvation Ouverte par Ordinateur (INNOOO)\n",
      "•   Institut des Hautes Etudes de Défense Nationale (IHEDN)\n",
      "•   Institut des Systèmes Complexes de Paris Ile-de-France \n",
      "(ISC-PIF)\n",
      "•   Institut Imagine\n",
      "•   Institut Mines-Télécom (IMT), Chaire de recherche Valeurs \n",
      "et Politiques des Informations Personnelles\n",
      "•   Institut National des Hautes études de la Sécurité \n",
      "et de la Justice (INHESJ)\n",
      "•   Institut National des Sciences Appliquées (INSA)\n",
      "•   Laboratoire pour l’Intelligence Collective et Artificielle (LICA)\n",
      "•   Le Club des Juristes\n",
      "•   Ligue de l’Enseignement\n",
      "•   Ligue des Droits de l’Homme (LDH)\n",
      "•   Microsoft\n",
      "•   Ministère de l’éducation nationale, via la direction \n",
      "du numérique pour l’éducation (DNE) et son Numéri’lab\n",
      "•   Ministère de la Culture, via la direction générale des médias \n",
      "et des industries culturelles (DGMIC)\n",
      "•   OpenLaw\n",
      "•   Ordre des avocats de Lille\n",
      "•   Randstad\n",
      "•   Renaissance Numérique\n",
      "•   Sciences Po Lille\n",
      "•   Sciences Po Paris\n",
      "•   Société informatique de France (SIF)\n",
      "•   The Future Society at Harvard Kennedy School, AI Initiative\n",
      "•   Universcience\n",
      "•   Université de Bordeaux\n",
      "•   Université de Lille 2\n",
      "•   Université Fédérale de Toulouse\n",
      "•   Université Paris II\n",
      "•   Visions d’Europe\n",
      "\n",
      "Jérôme BERANGER •  Nozha BOUJEMAA •  \n",
      "Dominique CARDON • Jean-Philippe DESBIOLLES •   \n",
      "Paul DUAN •   Flora FISCHER • Antoine GARAPON • \n",
      "  Roger-François GAUTHIER •   Hubert GUILLAUD •\n",
      "Rand HINDI •   Jacques LUCAS •   \n",
      "Camille PALOQUE-BERGES •   Bruno PATINO •   \n",
      "Antoinette ROUVROY •   Cécile WENDLING\n",
      "\n",
      "\n",
      "72\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ÉVÉNEMENT\n",
      "\n",
      "LISTE DES MANIFESTATIONS ORGANISÉES \n",
      "DANS LE CADRE DU DÉBAT PUBLIC\n",
      "\n",
      "De fin mars à début octobre, la CNIL a assuré l’animation et la coordination de 45 événements sur les algorithmes et \n",
      "l’intelligence artificielle. Certaines initiatives ont été imaginées spécifiquement à l’occasion du lancement du débat public, \n",
      "d’autres s’inscrivaient déjà dans les projets d’acteurs – institutions publiques, associations, centres de recherche – \n",
      "déjà préoccupés par ces enjeux.\n",
      "\n",
      "De nombreux acteurs ont fait le choix d’appréhender les algorithmes dans un secteur spécifique (santé, emploi ou \n",
      "éducation par exemple) alors que d’autres ont abordé l’objet technologique dans sa globalité. Enfin, ce sont autant des \n",
      "ateliers d’experts à public restreint que des manifestations orientées vers l’appropriation du grand public (citoyens, \n",
      "étudiants etc.) qui ont jalonné ce processus.\n",
      "\n",
      "Plus d’informations sur ces manifestations sont disponibles sur le site de la CNIL.\n",
      "\n",
      "23/01/2017\n",
      "\n",
      "23/03/2017 \n",
      "25/03/2017\n",
      "\n",
      "31/03/2017\n",
      "\n",
      "06/04/2017\n",
      "\n",
      "08/04/2017\n",
      "\n",
      "18/04/2017\n",
      "\n",
      "18/04/2017\n",
      "\n",
      "04/05/2017\n",
      "\n",
      "16/05/2017\n",
      "\n",
      "19/05/2017\n",
      "\n",
      "02/06/2017\n",
      "\n",
      "EVÉNEMENT DE LANCEMENT : \n",
      "TABLES-RONDES « Des algorithmes et des hommes » \n",
      "et « Loyauté, transparence et pluralité des algorithmes »\n",
      "> CNIL\n",
      "\n",
      "COLLOQUE « Vers de nouvelles humanités ? »\n",
      "> Universcience\n",
      "\n",
      "CONFÉRENCE « Les algorithmes et le droit »\n",
      "> Université de Lille II\n",
      "\n",
      "CONFÉRENCE « Le choix à l’heure du Big Data »\n",
      "> Sciences Po Lille et Visions d’Europe\n",
      "\n",
      "DÉBAT « The governance of emerging technosciences »\n",
      "> German American Conference at Harvard University\n",
      "\n",
      "DÉBAT « Transatlantic perspectives on: AI in the age of social media; \n",
      "privacy, security and the future of political campaigning »\n",
      "> The Future Society at Harvard Kennedy School\n",
      "\n",
      "TABLES-RONDES « Big Data, ressources humaines : les algorithmes en débat »\n",
      "> FO-Cadres\n",
      "\n",
      "CONFÉRENCE « Loyauté des décisions algorithmiques »\n",
      "> Université Toulouse III – Paul Sabatier\n",
      "\n",
      "DÉBAT « Le numérique tuera-t-il l’Etat de droit ? »\n",
      "> Collège des Bernadins\n",
      "\n",
      "COLLOQUE « La justice prédictive »\n",
      ">   Cour d’Appel de Douai, Ordre des Avocats de Lille et Faculté de Droit de l’Université Catholique de Lille\n",
      "\n",
      "ATELIERS « Loyauté des traitements et décision algorithmiques »\n",
      "> LabEx Centre International de Mathématiques et Informatique de Toulouse\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ÉVÉNEMENT\n",
      "\n",
      "73\n",
      "\n",
      "08/06/2017\n",
      "\n",
      "14/06/2017\n",
      "\n",
      "16/06/2017\n",
      "\n",
      "19/06/2017\n",
      "\n",
      "19/06/2017\n",
      "\n",
      "21/06/2017\n",
      "\n",
      "22/06/2017\n",
      "\n",
      "22/06/2017\n",
      "\n",
      "22/06/2017\n",
      "23/06/2017\n",
      "\n",
      "27/06/2017\n",
      "\n",
      "28/06/2017\n",
      "\n",
      "28/06/2017\n",
      "\n",
      "03/07/2017\n",
      "\n",
      "05/07/2017\n",
      "\n",
      "22/08/2017\n",
      "24/08/2017\n",
      "\n",
      "05/09/2017\n",
      "\n",
      "11/09/2017\n",
      "13/09/2017\n",
      "\n",
      "14/09/2017\n",
      "\n",
      "DÉBAT « Algorithmes en santé : quelle éthique ? »\n",
      "> Groupe VYV (MGEN – ISTYA – Harmonie)\n",
      "\n",
      "TABLE-RONDE « Intelligence artificielle : l’éthique, à la croisée des RH et du Big Data »\n",
      "> Confédération française de l’encadrement – Confédération générale des cadres (CFE-CGC)\n",
      "\n",
      "DÉBAT « Algorithmes, emploi et éthique »\n",
      "> Association française de droit du travail et de la sécurité sociale (AFDT)\n",
      "\n",
      "JOURNÉE « Les algorithmes éthiques, une exigence morale et un avantage concurrentiel »\n",
      "> CERNA d’Allistene et Société Informatique de France (SIF)\n",
      "\n",
      "COLLOQUE « Humain, non-humain à l’ère de l’intelligence artificielle »\n",
      "> Université Paris II\n",
      "\n",
      "COLLOQUE « Intelligence artificielle : autonomie, délégation et responsabilité »\n",
      "> Ecole Nationale Supérieure de Cognitique (ENSC)\n",
      "\n",
      "ATELIER « Ethique des algorithmes : enjeux pour la santé »\n",
      "> Genotoul (plateforme éthique et bioscience)\n",
      "\n",
      "ATELIER DE CROWDSOURCING « Intelligence artificielle et droit »\n",
      "> OpenLaw\n",
      "\n",
      "COLLOQUE « The many dimensions of data »\n",
      "> Institut Mines-Télécom, Chaire de recherche Valeurs et Politiques des Informations Personnelles\n",
      "\n",
      "COLLOQUE « Sécurité et justice, le défi de l’algorithme »\n",
      ">   Institut national des hautes études de la Sécurité et de la Justice (INHESJ)\n",
      "\n",
      "PROCÈS FICTIF ET TABLE-RONDE « Ethique, algorithmes et justice »\n",
      "> Faculté de Droit de l’Université Catholique de Lyon et Cour administrative d’appel de Lyon\n",
      "\n",
      "JOURNÉE D’ÉTUDES « Admission Post-bac, cas d’école des algorithmes publics »\n",
      "> Fondation Internet Nouvelle Génération (FING) et Etalab\n",
      "\n",
      "JOURNÉE « Algorithmes et souveraineté numérique »\n",
      "> CERNA d’Allistene\n",
      "\n",
      "JOURNÉE « Ethique et intelligence artificielle »\n",
      "> Comité d’éthique du CNRS (COMETS) et Association française pour l’IA (AFIA)\n",
      "\n",
      "DÉBATS sur les algorithmes dans le champ de l’éducation.\n",
      "> Ligue de l’Enseignement\n",
      "\n",
      "MATINÉE-DÉBAT « Le travail à l’ère des algorithmes : quelle éthique pour l’emploi ? »\n",
      "> Renaissance Numérique et Randstad\n",
      "\n",
      "COLLOQUE « Convergences du droit et du numérique »\n",
      "> Université de Bordeaux\n",
      "\n",
      "JOURNÉE « Algorithmes et Politiques. Les enjeux éthiques des formes \n",
      "de calcul numérique vus par les sciences sociales »\n",
      "> Ecole des Hautes Etudes en Sciences Sociales (EHESS) et Institut des Systèmes Complexes Ile-de-France\n",
      "\n",
      "\n",
      "74\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "ÉVÉNEMENT\n",
      "\n",
      "15/09/2017\n",
      "\n",
      "15/09/2017\n",
      "\n",
      "20/09/2017\n",
      "\n",
      "20/09/2017\n",
      "\n",
      "20/09/2017\n",
      "\n",
      "21/09/2017\n",
      "\n",
      "21/09/2017\n",
      "\n",
      "22/09/2017\n",
      "\n",
      "26/09/2017\n",
      "\n",
      "28/09/2017\n",
      "\n",
      "29/09/2017\n",
      "\n",
      "04/10/2017\n",
      "\n",
      "06/10/2017\n",
      "\n",
      "12/10/2017\n",
      "\n",
      "14/10/2017\n",
      "\n",
      "JOURNÉE sur la recherche en santé dans ses aspects éthiques et réglementaires  \n",
      "(données, algorithmes)\n",
      "> Hôpital Necker et Institut Imagine\n",
      "\n",
      "TABLES-RONDES « Algorithmes et risques de discriminations dans le secteur de l’assurance »\n",
      "> Ligue des Droits de l’Homme\n",
      "\n",
      "COLLOQUE « Enjeux éthiques des algorithmes »\n",
      "> INNOvation Ouverte par Ordinateur (INNOOO)\n",
      "\n",
      "MATINÉE-DÉBAT « L’éthique des algorithmes et de l’IA est-elle compatible avec la création \n",
      "de valeur dans l’IoT ? : Internet of Things et/ou Internet of Trust ? »\n",
      "> ESCP Europe (Chaire IoT)\n",
      "\n",
      "COLLOQUE « Ethique et numérique »\n",
      "> Collège des Bernardins\n",
      "\n",
      "DÉBAT « Opportunities and challenges of advanced machine learning algorithms »\n",
      "> The John F. Kennedy Jr. Forum at Harvard Kennedy School\n",
      "\n",
      "COLLOQUE « Lex Robotica (à la frontière de la robotique et du Droit :  \n",
      "penser l’humanoïde de 2017) »\n",
      "> Conservatoire National des Arts et Métiers (CNAM)\n",
      "\n",
      "TABLE-RONDE « IA et éthique des algorithmes »\n",
      "> Fotonower\n",
      "\n",
      "COLLOQUE « Algorithmes prédictifs : quels enjeux éthiques et juridiques ? »\n",
      "> Centre de recherche de l’école des officiers de la gendarmerie nationale (CREOGN)\n",
      "\n",
      "CONSULTATION « Quel avenir pour la médecine à l’heure de l’intelligence artificielle ? »\n",
      "> Conseil départemental du Rhône de l’Ordre des Médecins\n",
      "\n",
      "TABLES-RONDES « Ethique des algorithmes et du big data »\n",
      "> Agence française de développement (AFD) et Caisse des dépôts et consignations (CDC)\n",
      "\n",
      "COLLOQUE « Algorithmes et champ de bataille »\n",
      "Forum-débat « Vers une Intelligence Artificielle bienveillante ? »\n",
      "> Institut des hautes études de défense nationale (IHEDN)\n",
      "\n",
      "FORUM-DÉBAT « Vers une Intelligence Artificielle bienveillante ? »\n",
      "> Laboratoire d’intelligence collective et artificielle (LICA)\n",
      "\n",
      "TABLE-RONDE  « Droit et intelligence artificielle : quelle(s) responsabilité(s) ? »\n",
      "> Club des Juristes et Microsoft\n",
      "\n",
      "CONCERTATION CITOYENNE sur les enjeux éthiques des algorithmes\n",
      "> CNIL\n",
      "\n",
      "07/09/2017\n",
      "31/03/2018\n",
      "\n",
      "CONSULTATION PUBLIQUE sur la gouvernance de l’intelligence artificielle\n",
      "> The Future Society at Harvard Kennedy School\n",
      "\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME DE GARDER LA MAIN ? LES ENJEUX ÉTHIQUES DES ALGORITHMES ET DE L’INTELLIGENCE ARTIFICIELLE\n",
      "GLOSSAIRE\n",
      "\n",
      "75\n",
      "\n",
      "GLOSSAIRE\n",
      "\n",
      "Algorithme\n",
      "Description  d’une  suite  finie  et  non  ambigüe  d’étapes  ou  d’instructions  permettant  d’obtenir  un  résultat  à  partir \n",
      "d’éléments fournis en entrée.\n",
      "\n",
      "Apprentissage machine (ou apprentissage automatique, machine learning)\n",
      "Branche de l’intelligence artificielle, fondée sur des méthodes d’apprentissage et d’acquisition automatique de nou-\n",
      "velles connaissances par les ordinateurs, qui permet de les faire agir sans qu’ils aient à être explicitement program-\n",
      "més.\n",
      "\n",
      "Apprentissage machine supervisé\n",
      "L’algorithme apprend de données d’entrée qualifiées par l’humain et définit ainsi des règles à partir d’exemples qui \n",
      "sont autant de cas validés.\n",
      "\n",
      "Apprentissage machine non supervisé\n",
      "L’algorithme  apprend  à  partir  de  données  brutes  et  élabore  sa  propre  classification  qui  est  libre  d’évoluer  vers \n",
      "n’importe quel état final lorsqu’un motif ou un élément lui est présenté. Pratique qui nécessite que des instructeurs \n",
      "apprennent à la machine comment apprendre.\n",
      "\n",
      "Big data\n",
      "Désigne la conjonction entre, d’une part, d’immenses volumes de données devenus difficilement traitables à l’heure \n",
      "du  numérique  et,  d’autre  part,  les  nouvelles  techniques  permettant  de  traiter  ces  données,  voire  d’en  tirer  par  le \n",
      "repérage de corrélations des informations inattendues.\n",
      "\n",
      "Chatbot\n",
      "Agent  conversationnel  qui  dialogue  avec  son  utilisateur  (par  exemple,  les  robots  empathiques  à  disposition  de \n",
      "malades, ou les services de conversation automatisés dans la relation au client).\n",
      "\n",
      "Intelligence artificielle (IA)\n",
      "Théories et techniques « consistant à faire faire à des machines ce que l’homme ferait moyennant une certaine \n",
      "intelligence » (Marvin Minsky). On distingue IA faible (IA capable de simuler l’intelligence humaine pour une tâche bien \n",
      "déterminée) et IA forte (IA générique et autonome qui pourrait appliquer ses capacités à n’importe quel problème, \n",
      "répliquant en cela une caractéristique forte de l’intelligence humaine, soit une forme de « conscience » de la machine).\n",
      "\n",
      "\n",
      "Conception & réalisation graphique : LINÉAL - 03 20 41 40 76 / www.lineal.fr\n",
      "Crédit illustration : CC BY NC - Geoffrey DORNE - http://geoffreydorne.com/\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "7\n",
      "1\n",
      "0\n",
      "2\n",
      "E\n",
      "R\n",
      "B\n",
      "M\n",
      "E\n",
      "C\n",
      "É\n",
      "D\n",
      "\n",
      "e\n",
      "\n",
      "l\n",
      "l\n",
      "\n",
      "i\n",
      "\n",
      "e\n",
      "c\n",
      "fi\n",
      "i\n",
      "t\n",
      "r\n",
      "a\n",
      "e\n",
      "c\n",
      "n\n",
      "e\n",
      "g\n",
      "\n",
      " \n",
      "\n",
      "i\n",
      "l\n",
      "l\n",
      "\n",
      "e\n",
      "t\n",
      "n\n",
      "\n",
      "i\n",
      "’\n",
      "l\n",
      " \n",
      "\n",
      "j\n",
      "\n",
      "l\n",
      "\n",
      "i\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "I\n",
      "\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "e\n",
      "m\n",
      "h\n",
      "t\n",
      "i\n",
      "r\n",
      "o\n",
      "g\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      "s\n",
      "e\n",
      "u\n",
      "q\n",
      "h\n",
      "t\n",
      "é\n",
      "x\n",
      "u\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "e\n",
      "L\n",
      "?\n",
      "N\n",
      "A\n",
      "M\n",
      "A\n",
      "L\n",
      "R\n",
      "E\n",
      "D\n",
      "R\n",
      "A\n",
      "G\n",
      "E\n",
      "D\n",
      "E\n",
      "M\n",
      "M\n",
      "O\n",
      "H\n",
      "L’\n",
      "À\n",
      "E\n",
      "R\n",
      "T\n",
      "T\n",
      "E\n",
      "M\n",
      "R\n",
      "E\n",
      "P\n",
      "T\n",
      "N\n",
      "E\n",
      "M\n",
      "M\n",
      "O\n",
      "C\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Commission Nationale de l’Informatique et des Libertés\n",
      "\n",
      "3 place de Fontenoy\n",
      "\n",
      "TSA 80715\n",
      "\n",
      "75334 PARIS CEDEX 07\n",
      "\n",
      "Tél. 01 53 73 22 22\n",
      "Fax 01 53 73 22 00\n",
      "\n",
      "www.cnil.fr\n",
      "\n",
      "COMMENT PERMETTRE À L’HOMME \n",
      "\n",
      "DE GARDER LA MAIN ?\n",
      "\n",
      " Les enjeux éthiques des algorithmes et de l’intelligence artificielle\n",
      "\n",
      "SYNTHÈSE DU DÉBAT PUBLIC ANIMÉ PAR LA CNIL DANS LE CADRE DE LA MISSION \n",
      "DE RÉFLEXION ÉTHIQUE CONFIÉE PAR LA LOI POUR UNE RÉPUBLIQUE NUMÉRIQUE\n",
      "\n",
      "DÉCEMBRE 2017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    if item['data']['itemType'] != \"attachment\":\n",
    "        if item['meta']['numChildren'] > 0:\n",
    "            attachment = zot.children(item['data']['key'])\n",
    "            if len(attachment[0]['data']['url']) > 0:\n",
    "                pdf_url = attachment[0]['data']['url']\n",
    "                r = requests.get(pdf_url)\n",
    "                f = io.BytesIO(r.content)\n",
    "            else:\n",
    "                zot.dump(attachment[0]['key'], path ='./pdfs')\n",
    "                f = open('./pdfs/'+attachment[0][\"data\"][\"filename\"], 'rb')\n",
    "            p = MyParser(f)\n",
    "            print('\\n'.join(p.records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-HumanRights",
   "language": "python",
   "name": "ai-humanrights"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
